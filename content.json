{"meta":{"title":"Hellow World","subtitle":"","description":"","author":"John Doe","url":"https://park128.github.io","root":"/"},"pages":[],"posts":[{"title":"Python 기초문법","slug":"day_0707","date":"2022-07-07T00:00:00.000Z","updated":"2022-07-07T07:30:53.806Z","comments":true,"path":"2022/07/07/day_0707/","link":"","permalink":"https://park128.github.io/2022/07/07/day_0707/","excerpt":"","text":"1234567891011121314151617# This Python 3 environment comes with many helpful analytics libraries installed# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python# For example, here&#x27;s several helpful packages to loadimport numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)# Input data files are available in the read-only &quot;../input/&quot; directory# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directoryimport osfor dirname, _, filenames in os.walk(&#x27;/kaggle/input&#x27;): for filename in filenames: print(os.path.join(dirname, filename))# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; # You can also write temporary files to /kaggle/temp/, but they won&#x27;t be saved outside of the current session /kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv /kaggle/input/house-prices-advanced-regression-techniques/data_description.txt /kaggle/input/house-prices-advanced-regression-techniques/train.csv /kaggle/input/house-prices-advanced-regression-techniques/test.csv 1 라이브러리 불러오기 주요 라이브러리 버전을 확인한다. 123456789101112131415import pandas as pd import numpy as np import matplotlib as mpl import seaborn as sns import sklearnimport xgboost as xgb import lightgbm as lgbprint(&quot;pandas version :&quot;, pd.__version__)print(&quot;numpy version :&quot;, np.__version__)print(&quot;matplotlib version :&quot;, mpl.__version__)print(&quot;seaborn version :&quot;, sns.__version__)print(&quot;scikit-learn version :&quot;, sklearn.__version__)print(&quot;xgboost version :&quot;, xgb.__version__)print(&quot;lightgbm version :&quot;, lgb.__version__) .datatable table.frame { margin-bottom: 0; } .datatable table.frame thead { border-bottom: none; } .datatable table.frame tr.coltypes td { color: #FFFFFF; line-height: 6px; padding: 0 0.5em;} .datatable .bool { background: #DDDD99; } .datatable .object { background: #565656; } .datatable .int { background: #5D9E5D; } .datatable .float { background: #4040CC; } .datatable .str { background: #CC4040; } .datatable .time { background: #40CC40; } .datatable .row_index { background: var(--jp-border-color3); border-right: 1px solid var(--jp-border-color0); color: var(--jp-ui-font-color3); font-size: 9px;} .datatable .frame tbody td { text-align: left; } .datatable .frame tr.coltypes .row_index { background: var(--jp-border-color0);} .datatable th:nth-child(2) { padding-left: 12px; } .datatable .hellipsis { color: var(--jp-cell-editor-border-color);} .datatable .vellipsis { background: var(--jp-layout-color0); color: var(--jp-cell-editor-border-color);} .datatable .na { color: var(--jp-cell-editor-border-color); font-size: 80%;} .datatable .sp { opacity: 0.25;} .datatable .footer { font-size: 9px; } .datatable .frame_dimensions { background: var(--jp-border-color3); border-top: 1px solid var(--jp-border-color0); color: var(--jp-ui-font-color3); display: inline-block; opacity: 0.6; padding: 1px 10px 1px 5px;} pandas version : 1.3.5 numpy version : 1.21.6 matplotlib version : 3.5.2 seaborn version : 0.11.2 scikit-learn version : 1.0.2 xgboost version : 1.6.1 lightgbm version : 3.3.2 데이터 불러오기 pandas 활용 12345DATA_PATH = &#x27;/kaggle/input/house-prices-advanced-regression-techniques/&#x27;train = pd.read_csv(DATA_PATH + &quot;train.csv&quot;)test = pd.read_csv(DATA_PATH + &quot;test.csv&quot;)print(&quot;데이터 불러오기 완료!&quot;) 데이터 불러오기 완료! 데이터 둘러보기 데이터를 둘러봅니다. train : 행 갯수 1460 열 갯수 81 (SalePrice 존재) test : 행 갯수 1459, 열 갯수 80 (SalePrice 컬럼 미 존재) 1train.shape, test.shape ((1460, 81), (1459, 80)) 1train.info() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1460 entries, 0 to 1459 Data columns (total 81 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Id 1460 non-null int64 1 MSSubClass 1460 non-null int64 2 MSZoning 1460 non-null object 3 LotFrontage 1201 non-null float64 4 LotArea 1460 non-null int64 5 Street 1460 non-null object 6 Alley 91 non-null object 7 LotShape 1460 non-null object 8 LandContour 1460 non-null object 9 Utilities 1460 non-null object 10 LotConfig 1460 non-null object 11 LandSlope 1460 non-null object 12 Neighborhood 1460 non-null object 13 Condition1 1460 non-null object 14 Condition2 1460 non-null object 15 BldgType 1460 non-null object 16 HouseStyle 1460 non-null object 17 OverallQual 1460 non-null int64 18 OverallCond 1460 non-null int64 19 YearBuilt 1460 non-null int64 20 YearRemodAdd 1460 non-null int64 21 RoofStyle 1460 non-null object 22 RoofMatl 1460 non-null object 23 Exterior1st 1460 non-null object 24 Exterior2nd 1460 non-null object 25 MasVnrType 1452 non-null object 26 MasVnrArea 1452 non-null float64 27 ExterQual 1460 non-null object 28 ExterCond 1460 non-null object 29 Foundation 1460 non-null object 30 BsmtQual 1423 non-null object 31 BsmtCond 1423 non-null object 32 BsmtExposure 1422 non-null object 33 BsmtFinType1 1423 non-null object 34 BsmtFinSF1 1460 non-null int64 35 BsmtFinType2 1422 non-null object 36 BsmtFinSF2 1460 non-null int64 37 BsmtUnfSF 1460 non-null int64 38 TotalBsmtSF 1460 non-null int64 39 Heating 1460 non-null object 40 HeatingQC 1460 non-null object 41 CentralAir 1460 non-null object 42 Electrical 1459 non-null object 43 1stFlrSF 1460 non-null int64 44 2ndFlrSF 1460 non-null int64 45 LowQualFinSF 1460 non-null int64 46 GrLivArea 1460 non-null int64 47 BsmtFullBath 1460 non-null int64 48 BsmtHalfBath 1460 non-null int64 49 FullBath 1460 non-null int64 50 HalfBath 1460 non-null int64 51 BedroomAbvGr 1460 non-null int64 52 KitchenAbvGr 1460 non-null int64 53 KitchenQual 1460 non-null object 54 TotRmsAbvGrd 1460 non-null int64 55 Functional 1460 non-null object 56 Fireplaces 1460 non-null int64 57 FireplaceQu 770 non-null object 58 GarageType 1379 non-null object 59 GarageYrBlt 1379 non-null float64 60 GarageFinish 1379 non-null object 61 GarageCars 1460 non-null int64 62 GarageArea 1460 non-null int64 63 GarageQual 1379 non-null object 64 GarageCond 1379 non-null object 65 PavedDrive 1460 non-null object 66 WoodDeckSF 1460 non-null int64 67 OpenPorchSF 1460 non-null int64 68 EnclosedPorch 1460 non-null int64 69 3SsnPorch 1460 non-null int64 70 ScreenPorch 1460 non-null int64 71 PoolArea 1460 non-null int64 72 PoolQC 7 non-null object 73 Fence 281 non-null object 74 MiscFeature 54 non-null object 75 MiscVal 1460 non-null int64 76 MoSold 1460 non-null int64 77 YrSold 1460 non-null int64 78 SaleType 1460 non-null object 79 SaleCondition 1460 non-null object 80 SalePrice 1460 non-null int64 dtypes: float64(3), int64(35), object(43) memory usage: 924.0+ KB 1test.info() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1459 entries, 0 to 1458 Data columns (total 80 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Id 1459 non-null int64 1 MSSubClass 1459 non-null int64 2 MSZoning 1455 non-null object 3 LotFrontage 1232 non-null float64 4 LotArea 1459 non-null int64 5 Street 1459 non-null object 6 Alley 107 non-null object 7 LotShape 1459 non-null object 8 LandContour 1459 non-null object 9 Utilities 1457 non-null object 10 LotConfig 1459 non-null object 11 LandSlope 1459 non-null object 12 Neighborhood 1459 non-null object 13 Condition1 1459 non-null object 14 Condition2 1459 non-null object 15 BldgType 1459 non-null object 16 HouseStyle 1459 non-null object 17 OverallQual 1459 non-null int64 18 OverallCond 1459 non-null int64 19 YearBuilt 1459 non-null int64 20 YearRemodAdd 1459 non-null int64 21 RoofStyle 1459 non-null object 22 RoofMatl 1459 non-null object 23 Exterior1st 1458 non-null object 24 Exterior2nd 1458 non-null object 25 MasVnrType 1443 non-null object 26 MasVnrArea 1444 non-null float64 27 ExterQual 1459 non-null object 28 ExterCond 1459 non-null object 29 Foundation 1459 non-null object 30 BsmtQual 1415 non-null object 31 BsmtCond 1414 non-null object 32 BsmtExposure 1415 non-null object 33 BsmtFinType1 1417 non-null object 34 BsmtFinSF1 1458 non-null float64 35 BsmtFinType2 1417 non-null object 36 BsmtFinSF2 1458 non-null float64 37 BsmtUnfSF 1458 non-null float64 38 TotalBsmtSF 1458 non-null float64 39 Heating 1459 non-null object 40 HeatingQC 1459 non-null object 41 CentralAir 1459 non-null object 42 Electrical 1459 non-null object 43 1stFlrSF 1459 non-null int64 44 2ndFlrSF 1459 non-null int64 45 LowQualFinSF 1459 non-null int64 46 GrLivArea 1459 non-null int64 47 BsmtFullBath 1457 non-null float64 48 BsmtHalfBath 1457 non-null float64 49 FullBath 1459 non-null int64 50 HalfBath 1459 non-null int64 51 BedroomAbvGr 1459 non-null int64 52 KitchenAbvGr 1459 non-null int64 53 KitchenQual 1458 non-null object 54 TotRmsAbvGrd 1459 non-null int64 55 Functional 1457 non-null object 56 Fireplaces 1459 non-null int64 57 FireplaceQu 729 non-null object 58 GarageType 1383 non-null object 59 GarageYrBlt 1381 non-null float64 60 GarageFinish 1381 non-null object 61 GarageCars 1458 non-null float64 62 GarageArea 1458 non-null float64 63 GarageQual 1381 non-null object 64 GarageCond 1381 non-null object 65 PavedDrive 1459 non-null object 66 WoodDeckSF 1459 non-null int64 67 OpenPorchSF 1459 non-null int64 68 EnclosedPorch 1459 non-null int64 69 3SsnPorch 1459 non-null int64 70 ScreenPorch 1459 non-null int64 71 PoolArea 1459 non-null int64 72 PoolQC 3 non-null object 73 Fence 290 non-null object 74 MiscFeature 51 non-null object 75 MiscVal 1459 non-null int64 76 MoSold 1459 non-null int64 77 YrSold 1459 non-null int64 78 SaleType 1458 non-null object 79 SaleCondition 1459 non-null object dtypes: float64(11), int64(26), object(43) memory usage: 912.0+ KB 데이터 시각화 여기에서는 생략 종속변수 분포 확인 샤피로 검정 정규분포인가요? 정규분포가 아님! –&gt; 로그변환, 박스콕스 변환 등등 정규분포로 만들어 줘야 함. 선형모델의 성능을 올리기 위해서는 123456789101112import matplotlib.pyplot as plt from scipy.stats import norm (mu, sigma) = norm.fit(train[&#x27;SalePrice&#x27;])print(&quot;평균:&quot;, mu)print(&quot;표준편차:&quot;, sigma)fig, ax = plt.subplots(figsize=(10, 6))sns.histplot(train[&#x27;SalePrice&#x27;])ax.set(title=&quot;SalePrice Distribution&quot;)ax.axvline(mu, color = &#x27;r&#x27;, linestyle = &#x27;--&#x27;)ax.text(mu + 10000, 160, &#x27;Mean of SalePrice&#x27;, color = &#x27;r&#x27;)plt.show() 평균: 180921.19589041095 표준편차: 79415.29188606751 로그변환을 해서 정규분포로 변환해준다. 1234567891011121314# 로그변환을 함. train[&#x27;SalePrice&#x27;] = np.log1p(train[&#x27;SalePrice&#x27;])(mu, sigma) = norm.fit(train[&#x27;SalePrice&#x27;])print(&quot;평균:&quot;, mu)print(&quot;표준편차:&quot;, sigma)fig, ax = plt.subplots(figsize=(10, 6))sns.histplot(train[&#x27;SalePrice&#x27;])ax.set(title=&quot;SalePrice Distribution&quot;)ax.axvline(mu, color = &#x27;r&#x27;, linestyle = &#x27;--&#x27;)ax.text(mu + 0.0001, 160, &#x27;Mean of SalePrice&#x27;, color = &#x27;r&#x27;)ax.set_ylim(0, 170)plt.show() 평균: 12.024057394918406 표준편차: 0.39931245219387496 데이터 전처리 컬럼 갯수가 많다?, 어떤 컬럼을 없앨 것인가? 머신러닝 연산 속도부터 높여야 함. 데이터 ID값 제거12345train_ID = train[&#x27;Id&#x27;]test_ID = test[&#x27;Id&#x27;]train = train.drop([&#x27;Id&#x27;], axis = 1)train.shape (1460, 80) 12test = test.drop([&#x27;Id&#x27;], axis = 1)test.shape (1459, 79) Y값 추출 train데이터에 SalePrice만 따로 저장한다. 123y = train[&#x27;SalePrice&#x27;]train = train.drop(&#x27;SalePrice&#x27;, axis = 1)train.shape (1460, 79) 1test.shape (1459, 79) 데이터 합치기 강의 목적 원칙 train, 따로 정리 test, 따로 정리 Data Leakage 오류를 범할 가능성이 높음. 12all_df = pd.concat([train, test]).reset_index(drop=True)all_df.shape (2919, 79) 결측치 확인 결측치의 비율 확인하는 사용자 정의 함수 작성 1train.info() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1460 entries, 0 to 1459 Data columns (total 79 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 MSSubClass 1460 non-null int64 1 MSZoning 1460 non-null object 2 LotFrontage 1201 non-null float64 3 LotArea 1460 non-null int64 4 Street 1460 non-null object 5 Alley 91 non-null object 6 LotShape 1460 non-null object 7 LandContour 1460 non-null object 8 Utilities 1460 non-null object 9 LotConfig 1460 non-null object 10 LandSlope 1460 non-null object 11 Neighborhood 1460 non-null object 12 Condition1 1460 non-null object 13 Condition2 1460 non-null object 14 BldgType 1460 non-null object 15 HouseStyle 1460 non-null object 16 OverallQual 1460 non-null int64 17 OverallCond 1460 non-null int64 18 YearBuilt 1460 non-null int64 19 YearRemodAdd 1460 non-null int64 20 RoofStyle 1460 non-null object 21 RoofMatl 1460 non-null object 22 Exterior1st 1460 non-null object 23 Exterior2nd 1460 non-null object 24 MasVnrType 1452 non-null object 25 MasVnrArea 1452 non-null float64 26 ExterQual 1460 non-null object 27 ExterCond 1460 non-null object 28 Foundation 1460 non-null object 29 BsmtQual 1423 non-null object 30 BsmtCond 1423 non-null object 31 BsmtExposure 1422 non-null object 32 BsmtFinType1 1423 non-null object 33 BsmtFinSF1 1460 non-null int64 34 BsmtFinType2 1422 non-null object 35 BsmtFinSF2 1460 non-null int64 36 BsmtUnfSF 1460 non-null int64 37 TotalBsmtSF 1460 non-null int64 38 Heating 1460 non-null object 39 HeatingQC 1460 non-null object 40 CentralAir 1460 non-null object 41 Electrical 1459 non-null object 42 1stFlrSF 1460 non-null int64 43 2ndFlrSF 1460 non-null int64 44 LowQualFinSF 1460 non-null int64 45 GrLivArea 1460 non-null int64 46 BsmtFullBath 1460 non-null int64 47 BsmtHalfBath 1460 non-null int64 48 FullBath 1460 non-null int64 49 HalfBath 1460 non-null int64 50 BedroomAbvGr 1460 non-null int64 51 KitchenAbvGr 1460 non-null int64 52 KitchenQual 1460 non-null object 53 TotRmsAbvGrd 1460 non-null int64 54 Functional 1460 non-null object 55 Fireplaces 1460 non-null int64 56 FireplaceQu 770 non-null object 57 GarageType 1379 non-null object 58 GarageYrBlt 1379 non-null float64 59 GarageFinish 1379 non-null object 60 GarageCars 1460 non-null int64 61 GarageArea 1460 non-null int64 62 GarageQual 1379 non-null object 63 GarageCond 1379 non-null object 64 PavedDrive 1460 non-null object 65 WoodDeckSF 1460 non-null int64 66 OpenPorchSF 1460 non-null int64 67 EnclosedPorch 1460 non-null int64 68 3SsnPorch 1460 non-null int64 69 ScreenPorch 1460 non-null int64 70 PoolArea 1460 non-null int64 71 PoolQC 7 non-null object 72 Fence 281 non-null object 73 MiscFeature 54 non-null object 74 MiscVal 1460 non-null int64 75 MoSold 1460 non-null int64 76 YrSold 1460 non-null int64 77 SaleType 1460 non-null object 78 SaleCondition 1460 non-null object dtypes: float64(3), int64(33), object(43) memory usage: 901.2+ KB 12345678def check_na(data, head_num = 6): isnull_na = (data.isnull().sum() / len(data)) * 100 data_na = isnull_na.drop(isnull_na[isnull_na == 0].index).sort_values(ascending=False) missing_data = pd.DataFrame(&#123;&#x27;Missing Ratio&#x27; :data_na, &#x27;Data Type&#x27;: data.dtypes[data_na.index]&#125;) print(&quot;결측치 데이터 컬럼과 건수:\\n&quot;, missing_data.head(head_num))check_na(all_df, 20) 결측치 데이터 컬럼과 건수: Missing Ratio Data Type PoolQC 99.657417 object MiscFeature 96.402878 object Alley 93.216855 object Fence 80.438506 object FireplaceQu 48.646797 object LotFrontage 16.649538 float64 GarageFinish 5.447071 object GarageQual 5.447071 object GarageCond 5.447071 object GarageYrBlt 5.447071 float64 GarageType 5.378554 object BsmtExposure 2.809181 object BsmtCond 2.809181 object BsmtQual 2.774923 object BsmtFinType2 2.740665 object BsmtFinType1 2.706406 object MasVnrType 0.822199 object MasVnrArea 0.787941 float64 MSZoning 0.137033 object BsmtFullBath 0.068517 float64 결측치 제거 결측치 비율이 높은 변수들을 모두 제거하기로 했다. 123all_df = all_df.drop([&#x27;PoolQC&#x27;, &#x27;MiscFeature&#x27;, &#x27;Alley&#x27;, &#x27;Fence&#x27;, &#x27;FireplaceQu&#x27;, &#x27;LotFrontage&#x27;], axis = 1)print(all_df.shape)check_na(all_df, 40) (2919, 73) 결측치 데이터 컬럼과 건수: Missing Ratio Data Type GarageCond 5.447071 object GarageQual 5.447071 object GarageYrBlt 5.447071 float64 GarageFinish 5.447071 object GarageType 5.378554 object BsmtCond 2.809181 object BsmtExposure 2.809181 object BsmtQual 2.774923 object BsmtFinType2 2.740665 object BsmtFinType1 2.706406 object MasVnrType 0.822199 object MasVnrArea 0.787941 float64 MSZoning 0.137033 object Functional 0.068517 object Utilities 0.068517 object BsmtFullBath 0.068517 float64 BsmtHalfBath 0.068517 float64 GarageArea 0.034258 float64 GarageCars 0.034258 float64 TotalBsmtSF 0.034258 float64 KitchenQual 0.034258 object Electrical 0.034258 object BsmtUnfSF 0.034258 float64 BsmtFinSF2 0.034258 float64 BsmtFinSF1 0.034258 float64 Exterior2nd 0.034258 object Exterior1st 0.034258 object SaleType 0.034258 object 결측치 채우기 train 데이터와 test 데이터가 섞이면 안됨. train &#x2F; test 분리해서 진행해야 함. 문자데이터 : 자주 등장하는 빈도 값으로 채움 숫자데이터 : 평균이 아니라, 중간값으로 채울 예정 12# all_df[&#x27;SaleType&#x27;].value_counts()all_df[&#x27;SaleType&#x27;].mode()[0] &#39;WD&#39; 1check_na(all_df, 40) 결측치 데이터 컬럼과 건수: Missing Ratio Data Type GarageCond 5.447071 object GarageQual 5.447071 object GarageYrBlt 5.447071 float64 GarageFinish 5.447071 object GarageType 5.378554 object BsmtCond 2.809181 object BsmtExposure 2.809181 object BsmtQual 2.774923 object BsmtFinType2 2.740665 object BsmtFinType1 2.706406 object MasVnrType 0.822199 object MasVnrArea 0.787941 float64 MSZoning 0.137033 object Functional 0.068517 object Utilities 0.068517 object BsmtFullBath 0.068517 float64 BsmtHalfBath 0.068517 float64 GarageArea 0.034258 float64 GarageCars 0.034258 float64 TotalBsmtSF 0.034258 float64 KitchenQual 0.034258 object Electrical 0.034258 object BsmtUnfSF 0.034258 float64 BsmtFinSF2 0.034258 float64 BsmtFinSF1 0.034258 float64 Exterior2nd 0.034258 object Exterior1st 0.034258 object SaleType 0.034258 object 12345678910111213141516171819202122import numpy as np# 문자열 데이터만 추출cat_all_vars = train.select_dtypes(exclude=[np.number])print(&quot;The whole number of all_vars&quot;, len(list(cat_all_vars)))# 문자열 데이터 중에서 이미 기 삭제했던 Feature들이 있었기 때문에, # 한번 더 Feature를 정리하는 코드를 작성한다. # 따라서 38개의 Feature만 추출했다. final_cat_vars = []for v in cat_all_vars: if v not in [&#x27;PoolQC&#x27;, &#x27;MiscFeature&#x27;, &#x27;Alley&#x27;, &#x27;Fence&#x27;, &#x27;FireplaceQu&#x27;]: final_cat_vars.append(v)print(&quot;The whole number of final_cat_vars&quot;, len(final_cat_vars))# 이제 각 Feature 마다 빈도수가 가장 많이 나타나는 값을 추가하는 코드를 작성한다. for i in final_cat_vars: all_df[i] = all_df[i].fillna(all_df[i].mode()[0])# 이제 수치형 데이터만 남은 것을 확인한다. check_na(all_df, 20) The whole number of all_vars 43 The whole number of final_cat_vars 38 결측치 데이터 컬럼과 건수: Missing Ratio Data Type GarageYrBlt 5.447071 float64 MasVnrArea 0.787941 float64 BsmtFullBath 0.068517 float64 BsmtHalfBath 0.068517 float64 BsmtFinSF1 0.034258 float64 BsmtFinSF2 0.034258 float64 BsmtUnfSF 0.034258 float64 TotalBsmtSF 0.034258 float64 GarageCars 0.034258 float64 GarageArea 0.034258 float64 수치형 데이터의 결측치를 추가할 수 있다. 평균이 아닌 중간값으로 진행한다. 12345678910111213141516import numpy as np# 방법은 기존과 동일하다. # 이번에는 수치형 데이터만 추출한다. num_all_vars = list(train.select_dtypes(include=[np.number]))print(&quot;The whole number of all_vars&quot;, len(num_all_vars))# 수치형 데이터 중, 결측치가 많았던 `LotFrontage`만 처리한다. num_all_vars.remove(&#x27;LotFrontage&#x27;)print(&quot;The whole number of final_cat_vars&quot;, len(num_all_vars))# 이번에는 수치형 데이터의 평균이 아닌 중간값을 지정했다. for i in num_all_vars: all_df[i].fillna(value=all_df[i].median(), inplace=True)check_na(all_df, 20) The whole number of all_vars 36 The whole number of final_cat_vars 35 결측치 데이터 컬럼과 건수: Empty DataFrame Columns: [Missing Ratio, Data Type] Index: [] 도출 변수 새로운 도출 변수를 작성 (기존 변수 활용) 기존 변수 제거 각 층의 면적으로 모두 더해 전체 면적으로 계산한 새로운 변수를 작성한다. 123all_df[&#x27;TotalSF&#x27;] = all_df[&#x27;TotalBsmtSF&#x27;] + all_df[&#x27;1stFlrSF&#x27;] + all_df[&#x27;2ndFlrSF&#x27;]all_df = all_df.drop([&#x27;TotalBsmtSF&#x27;, &#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;], axis=1)print(all_df.shape) (2919, 71) 1234all_df[&#x27;Total_Bathrooms&#x27;] = (all_df[&#x27;FullBath&#x27;] + (0.5 * all_df[&#x27;HalfBath&#x27;]) + all_df[&#x27;BsmtFullBath&#x27;] + (0.5 * all_df[&#x27;BsmtHalfBath&#x27;]))all_df[&#x27;Total_porch_sf&#x27;] = (all_df[&#x27;OpenPorchSF&#x27;] + all_df[&#x27;3SsnPorch&#x27;] + all_df[&#x27;EnclosedPorch&#x27;] + all_df[&#x27;ScreenPorch&#x27;])all_df = all_df.drop([&#x27;FullBath&#x27;, &#x27;HalfBath&#x27;, &#x27;BsmtFullBath&#x27;, &#x27;BsmtHalfBath&#x27;, &#x27;OpenPorchSF&#x27;, &#x27;3SsnPorch&#x27;, &#x27;EnclosedPorch&#x27;, &#x27;ScreenPorch&#x27;], axis=1)print(all_df.shape) (2919, 65) 연도와 관련된 변수를 추출하는 코드 작성. 12345678910num_all_vars = list(train.select_dtypes(include=[np.number]))year_feature = []for var in num_all_vars: if &#x27;Yr&#x27; in var: year_feature.append(var) elif &#x27;Year&#x27; in var: year_feature.append(var) else: print(var, &quot;is not related with Year&quot;)print(year_feature) MSSubClass is not related with Year LotFrontage is not related with Year LotArea is not related with Year OverallQual is not related with Year OverallCond is not related with Year MasVnrArea is not related with Year BsmtFinSF1 is not related with Year BsmtFinSF2 is not related with Year BsmtUnfSF is not related with Year TotalBsmtSF is not related with Year 1stFlrSF is not related with Year 2ndFlrSF is not related with Year LowQualFinSF is not related with Year GrLivArea is not related with Year BsmtFullBath is not related with Year BsmtHalfBath is not related with Year FullBath is not related with Year HalfBath is not related with Year BedroomAbvGr is not related with Year KitchenAbvGr is not related with Year TotRmsAbvGrd is not related with Year Fireplaces is not related with Year GarageCars is not related with Year GarageArea is not related with Year WoodDeckSF is not related with Year OpenPorchSF is not related with Year EnclosedPorch is not related with Year 3SsnPorch is not related with Year ScreenPorch is not related with Year PoolArea is not related with Year MiscVal is not related with Year MoSold is not related with Year [&#39;YearBuilt&#39;, &#39;YearRemodAdd&#39;, &#39;GarageYrBlt&#39;, &#39;YrSold&#39;] 12345678fig, ax = plt.subplots(3, 1, figsize=(10, 6), sharex=True, sharey=True)for i, var in enumerate(year_feature): if var != &#x27;YrSold&#x27;: ax[i].scatter(train[var], y, alpha=0.3) ax[i].set_title(&#x27;&#123;&#125;&#x27;.format(var), size=15) ax[i].set_ylabel(&#x27;SalePrice&#x27;, size=15, labelpad=12.5)plt.tight_layout()plt.show() 12all_df = all_df.drop([&#x27;YearBuilt&#x27;, &#x27;GarageYrBlt&#x27;], axis=1)print(all_df.shape) (2919, 63) 12345YearsSinceRemodel = train[&#x27;YrSold&#x27;].astype(int) - train[&#x27;YearRemodAdd&#x27;].astype(int)fig, ax = plt.subplots(figsize=(10, 6))ax.scatter(YearsSinceRemodel, y, alpha=0.3)plt.show() 123all_df[&#x27;YearsSinceRemodel&#x27;] = all_df[&#x27;YrSold&#x27;].astype(int) - all_df[&#x27;YearRemodAdd&#x27;].astype(int)all_df = all_df.drop([&#x27;YrSold&#x27;, &#x27;YearRemodAdd&#x27;], axis=1)print(all_df.shape) (2919, 62) 더미변수 더미변수란 원 데이터 독립변수를 0과 1로 변환하는 변수를 말함. 1all_df[&#x27;PoolArea&#x27;].value_counts() 0 2906 512 1 648 1 576 1 555 1 480 1 519 1 738 1 144 1 368 1 444 1 228 1 561 1 800 1 Name: PoolArea, dtype: int64 사용자 정의 함수 만들기 12345def count_dummy(x): if x &gt; 0: return 1 else: return 0 12all_df[&#x27;PoolArea&#x27;] = all_df[&#x27;PoolArea&#x27;].apply(count_dummy) all_df[&#x27;PoolArea&#x27;].value_counts() 0 2906 1 13 Name: PoolArea, dtype: int64 12all_df[&#x27;GarageArea&#x27;] = all_df[&#x27;GarageArea&#x27;].apply(count_dummy)all_df[&#x27;GarageArea&#x27;].value_counts() 1 2762 0 157 Name: GarageArea, dtype: int64 12all_df[&#x27;Fireplaces&#x27;] = all_df[&#x27;Fireplaces&#x27;].apply(count_dummy)all_df[&#x27;Fireplaces&#x27;].value_counts() 1 1499 0 1420 Name: Fireplaces, dtype: int64 인코딩 문자를 숫자로 변환해주는 코드를 인코딩 변환 1all_df.shape (2919, 62) Label Encoding, Ordinal Encoding, One-Hot Encoding 인코딩은 문자 데이터를 수치로 변환하는 방법론 중의 하나이다. 12345678910111213# 분류모형# 종속변수 (양성, 음성)# Label Encoder는 종속변수에만 적용from sklearn.preprocessing import LabelEncoderimport pandas as pdtemp = pd.DataFrame(&#123;&#x27;Food_Name&#x27;: [&#x27;Apple&#x27;, &#x27;Chicken&#x27;, &#x27;Broccoli&#x27;], &#x27;Calories&#x27;: [95, 231, 50]&#125;)encoder = LabelEncoder()encoder.fit(temp[&#x27;Food_Name&#x27;])labels = encoder.transform(temp[&#x27;Food_Name&#x27;])print(list(temp[&#x27;Food_Name&#x27;]), &quot;==&gt;&quot;, labels) [&#39;Apple&#39;, &#39;Chicken&#39;, &#39;Broccoli&#39;] ==&gt; [0 2 1] OrdinalEncoder는 독립변수에만 쓴다. 123456789from sklearn.preprocessing import OrdinalEncoderimport pandas as pdtemp = pd.DataFrame(&#123;&#x27;Food_Name&#x27;: [&#x27;Apple&#x27;, &#x27;Chicken&#x27;, &#x27;Broccoli&#x27;], &#x27;Calories&#x27;: [95, 231, 50]&#125;)encoder = OrdinalEncoder()labels = encoder.fit_transform(temp[[&#x27;Food_Name&#x27;]])print(list(temp[&#x27;Food_Name&#x27;]), &quot;==&gt;&quot;, labels.tolist()) [&#39;Apple&#39;, &#39;Chicken&#39;, &#39;Broccoli&#39;] ==&gt; [[0.0], [2.0], [1.0]] pandas 메서드 통해서 직접 숫자로 변환 12345temp = pd.DataFrame(&#123;&#x27;Food_Name&#x27;: [&#x27;Apple&#x27;, &#x27;Chicken&#x27;, &#x27;Broccoli&#x27;], &#x27;Calories&#x27;: [95, 231, 50]&#125;)temp[&#x27;Food_No&#x27;] = temp[&#x27;Food_Name&#x27;].replace(to_replace = [&#x27;Apple&#x27;, &#x27;Chicken&#x27;, &#x27;Broccoli&#x27;], value = [1, 2, 3])print(temp[[&#x27;Food_Name&#x27;, &#x27;Food_No&#x27;]]) Food_Name Food_No 0 Apple 1 1 Chicken 2 2 Broccoli 3 원핫 인코딩 scikit-learn 방식이 조금 복잡함. 그래서 보통은 pandas get_dummies() 함수를 활 1234567891011121314import pandas as pdfrom sklearn.preprocessing import LabelBinarizertemp = pd.DataFrame(&#123;&#x27;Food_Name&#x27;: [&#x27;Apple&#x27;, &#x27;Chicken&#x27;, &#x27;Broccoli&#x27;], &#x27;Calories&#x27;: [95, 231, 50]&#125;)encoder = LabelBinarizer()encoder.fit(temp[&#x27;Food_Name&#x27;])transformed = encoder.transform(temp[&#x27;Food_Name&#x27;])ohe_df = pd.DataFrame(transformed)temp = pd.concat([temp, ohe_df], axis=1).drop([&#x27;Food_Name&#x27;], axis=1)temp.columns = [&#x27;Calories&#x27;, &#x27;Food_Name_Apple&#x27;, &#x27;Food_Name_Broccoli&#x27;, &#x27;Food_Name_Chicken&#x27;]print(temp)print(temp.shape) Calories Food_Name_Apple Food_Name_Broccoli Food_Name_Chicken 0 95 1 0 0 1 231 0 0 1 2 50 0 1 0 (3, 4) 12345678import pandas as pdtemp = pd.DataFrame(&#123;&#x27;Food_Name&#x27;: [&#x27;Apple&#x27;, &#x27;Chicken&#x27;, &#x27;Broccoli&#x27;], &#x27;Calories&#x27;: [95, 231, 50]&#125;)temp = pd.get_dummies(temp)print(temp)print(temp.shape) Calories Food_Name_Apple Food_Name_Broccoli Food_Name_Chicken 0 95 1 0 0 1 231 0 0 1 2 50 0 1 0 (3, 4) 본 데이터 적용 여기서는 Ordinal Encoding 적용 안함. (단, 실전에서는 꼭 찾아서 해야함). 원핫 인코딩 적용 12all_df = pd.get_dummies(all_df).reset_index(drop=True)all_df.shape (2919, 258) 1all_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; MSSubClass LotArea OverallQual OverallCond MasVnrArea BsmtFinSF1 BsmtFinSF2 BsmtUnfSF LowQualFinSF GrLivArea ... SaleType_ConLw SaleType_New SaleType_Oth SaleType_WD SaleCondition_Abnorml SaleCondition_AdjLand SaleCondition_Alloca SaleCondition_Family SaleCondition_Normal SaleCondition_Partial 0 60 8450 7 5 196.0 706.0 0.0 150.0 0 1710 ... 0 0 0 1 0 0 0 0 1 0 1 20 9600 6 8 0.0 978.0 0.0 284.0 0 1262 ... 0 0 0 1 0 0 0 0 1 0 2 60 11250 7 5 162.0 486.0 0.0 434.0 0 1786 ... 0 0 0 1 0 0 0 0 1 0 3 70 9550 7 5 0.0 216.0 0.0 540.0 0 1717 ... 0 0 0 1 1 0 0 0 0 0 4 60 14260 8 5 350.0 655.0 0.0 490.0 0 2198 ... 0 0 0 1 0 0 0 0 1 0 5 rows × 258 columns train, test 데이터 합쳐서 진행. train, test 데이터 재분리 1234X = all_df.iloc[:len(y), :]test = all_df.iloc[len(y):, :]X.shape, y.shape, test.shape ((1460, 258), (1460,), (1459, 258)) 머신러닝을 위한 데이터 전처리가 끝이 남. 과제 남은 시간동안 교제를 보고 머신러닝 학습 및 RMSE 구하세요. 데이터셋 분리 X 데이터를 X_train, X_test, y_train, y_test로 분리 1234567from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split( # 독립변수, 종속변수 X, y, test_size = 0.3, random_state=0)X_train.shape, X_test.shape, y_train.shape, y_test.shape ((1022, 258), (438, 258), (1022,), (438,)) 평가지표 MAE, MSE, RMSE MAE 실젯값과 예측값의 차이, 오차, 오차들의 절댓값 평균을 말함. 1234567891011121314151617181920212223242526272829303132333435363738394041import numpy as np def mean_absolute_error(y_true, y_pred): error = 0 for yt, yp in zip(y_true, y_pred): # yt : 실젯값 # yp : 예측값 error = error + np.abs(yt - yp) # 절댓값 오차의 평균 mae = error / len(y_true) return maedef mean_squared_error(y_true, y_pred): error = 0 for yt, yp in zip(y_true, y_pred): # yt : 실젯값 # yp : 예측값 error = error + (yt - yp) ** 2 # 제곱값 오차의 평균 mse = error / len(y_true) return msedef root_mean_squared_error(y_true, y_pred): error = 0 for yt, yp in zip(y_true, y_pred): # yt : 실젯값 # yp : 예측값 error = error + (yt - yp) ** 2 # 제곱값 오차의 평균 mse = error / len(y_true) # 제곱근 추가 rmse = np.round(np.sqrt(mse), 3) return rmsey_true = [400, 300, 800]y_pred = [380, 320, 777]print(&quot;MAE:&quot;, mean_absolute_error(y_true, y_pred))print(&quot;MSE:&quot;, mean_squared_error(y_true, y_pred))print(&quot;RMSE:&quot;, root_mean_squared_error(y_true, y_pred)) MAE: 21.0 MSE: 443.0 RMSE: 21.048 sklearn 참고 자료 URL : https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html 123from sklearn.metrics import mean_squared_errordef rmse(y_true, y_pred): return np.sqrt(mean_squared_error(y_true, y_pred)) 머신러닝 모형 정의, 검증 평가 교차 검증 함수 만들기 123456789101112131415161718from sklearn.metrics import mean_squared_errorfrom sklearn.model_selection import KFold, cross_val_scorefrom sklearn.linear_model import LinearRegressionfrom sklearn.ensemble import RandomForestRegressor from lightgbm import LGBMRegressorfrom xgboost import XGBRegressordef cv_rmse(model, n_folds=5): cv = KFold(n_splits=n_folds, random_state=42, shuffle=True) rmse_list = np.sqrt(-cross_val_score(model, X, y, scoring=&#x27;neg_mean_squared_error&#x27;, cv=cv)) print(&#x27;CV RMSE value list:&#x27;, np.round(rmse_list, 4)) print(&#x27;CV RMSE mean value:&#x27;, np.round(np.mean(rmse_list), 4)) return (rmse_list)n_folds = 5rmse_scores = &#123;&#125;# lr_model = LinearRegression()lgb_model = LGBMRegressor() 123score = cv_rmse(lgb_model, n_folds)print(&quot;linear regression - mean: &#123;:.4f&#125; (std: &#123;:.4f&#125;)&quot;.format(score.mean(), score.std()))rmse_scores[&#x27;linear regression&#x27;] = (score.mean(), score.std()) CV RMSE value list: [0.1397 0.118 0.1636 0.1305 0.1114] CV RMSE mean value: 0.1326 linear regression - mean: 0.1326 (std: 0.0183) 제출 방법- 123456789from sklearn.model_selection import cross_val_predict# X = all_df.iloc[:len(y), :]# X_test = all_df.iloc[len(y):, :]# X.shape, y.shape, X_test.shapelr_model_fit = lgb_model.fit(X_train, y_train)final_preds = np.floor(np.expm1(lr_model_fit.predict(test)))print(final_preds) [123542. 165729. 180878. ... 152513. 114195. 211430.] 선형회귀 : 0.17437 랜덤포레스트 : 0.1429 LightGBM : 0.1353 XGBoost : 0.1473 1234submission = pd.read_csv(DATA_PATH + &quot;sample_submission.csv&quot;)submission.iloc[:,1] = final_predsprint(submission.head())submission.to_csv(&quot;submission.csv&quot;, index=False) Id SalePrice 0 1461 123542.0 1 1462 165729.0 2 1463 180878.0 3 1464 191337.0 4 1465 155431.0 모형 만들기123456# from sklearn.linear_model import LinearRegression# lr_model = LinearRegression()# lr_model.fit(X_train, y_train) # print(lr_model.score(X_train, y_train))# print(lr_model.score(X_test, y_test))","categories":[],"tags":[]},{"title":"Python 기초문법","slug":"day_0706","date":"2022-07-06T00:00:00.000Z","updated":"2022-07-07T07:39:21.830Z","comments":true,"path":"2022/07/06/day_0706/","link":"","permalink":"https://park128.github.io/2022/07/06/day_0706/","excerpt":"","text":"데이터 분석 (머신러닝, 딥러닝) 프로세스 데이터 불러오기 CSV, 오라클, MySQL, PostgreSQL, 클라우드 DB 연동 탐색적 자료 분석 데이터 전처리 및 가공 잠정적인 컬럼의 갯수를 지정해야 함 머신러닝 모델 (&#x3D;통계 모델링, t.test, 분산분석, 교차분석) 머신러닝 모델의 경우 배포 (현재는 다루지 않음 X) JSP-스프링 웹개발 시, 배우게 됨 통계 모델링 경우, p-value 값 기준으로, 귀무가설 및 대립가설 검정 (공통) 결과 보고서를 작성해야함 PPT 만들어야 함. 그래프 복습 수치형 데이터 시각화 범주형 데이터 시각화 데이터 관계 시각화 matplotlib 라이브러리 방법 (복잡) seaborn 라이브러리 방법 (단순) 복잡한 그래프 그려아지! –&gt; matpltoltib 1줄 그래프 –&gt; seaborn 수치형 데이터 시각화123import seaborn as sns titanic = sns.load_dataset(&#x27;titanic&#x27;)titanic.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; survived pclass sex age sibsp parch fare embarked class who adult_male deck embark_town alive alone 0 0 3 male 22.0 1 0 7.2500 S Third man True NaN Southampton no False 1 1 1 female 38.0 1 0 71.2833 C First woman False C Cherbourg yes False 2 1 3 female 26.0 0 0 7.9250 S Third woman False NaN Southampton yes True 3 1 1 female 35.0 1 0 53.1000 S First woman False C Southampton yes False 4 0 3 male 35.0 0 0 8.0500 S Third man True NaN Southampton no True &lt;svg xmlns&#x3D;”http://www.w3.org/2000/svg&quot; height&#x3D;”24px”viewBox&#x3D;”0 0 24 24” width&#x3D;”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-6177c8bd-39db-4db4-9f39-fc2406fa350a button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-6177c8bd-39db-4db4-9f39-fc2406fa350a&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 12# 히스토그램sns.histplot(data = titanic, x = &#x27;age&#x27;, bins = 10, hue = &#x27;alive&#x27;, multiple = &#x27;stack&#x27;) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd6a5bda710&gt; 위 그래프를 보아하니 주저리주저리 123# 커널밀도추정 함수 그래프# 연속형 데이터 1개만 쓸 때 사용sns.kdeplot(data = titanic, x = &#x27;age&#x27;, hue = &#x27;alive&#x27;, multiple=&#x27;stack&#x27;) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd6a3a196d0&gt; 분포도 수치형 데이터 한개 컬럼의 분포를 나타내는 그래프 정규분포인가? 1sns.displot(data = titanic, x = &#x27;age&#x27;) &lt;seaborn.axisgrid.FacetGrid at 0x7fd6a3999850&gt; 1sns.displot(data = titanic, x = &#x27;age&#x27;, kde = True) &lt;seaborn.axisgrid.FacetGrid at 0x7fd6a1072c90&gt; 범주형 데이터 시각화 x축 범주형, y축 수치 데이터 12# 막대 그래프sns.barplot(x = &#x27;class&#x27;, y = &#x27;fare&#x27;, data = titanic) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd6a0ed3a10&gt; 12# 포인트 플롯sns.pointplot(x = &#x27;class&#x27;, y=&#x27;fare&#x27;, data = titanic) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd6a0e23e90&gt; 박스플롯 제 1사분위 : 전체 데이터 중 하위 25% 사분위 범위 수(IQR) : 제 3사분위 - 제 1사분위 최댓값 : 제 3사분위 + (1.5 * IQ) 12# boxplotsns.boxplot(x = &#x27;class&#x27;, y=&#x27;age&#x27;, data = titanic) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd6a0e113d0&gt; 12# 바이올린 플롯sns.violinplot(x = &#x27;class&#x27;, y = &#x27;age&#x27;, hue = &#x27;sex&#x27;, data = titanic, split = True); 카운트 플롯 범주형 데이터의 갯수 확인 할 때 사용 1sns.countplot(x = &#x27;alive&#x27;, data = titanic) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd6a0c32350&gt; 데이터 관계 시각화 여러 데이터 사이의 관계도 파악 위한 그래프 히트맵12flights = sns.load_dataset(&#x27;flights&#x27;)flights.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; year month passengers 0 1949 Jan 112 1 1949 Feb 118 2 1949 Mar 132 3 1949 Apr 129 4 1949 May 121 &lt;svg xmlns&#x3D;”http://www.w3.org/2000/svg&quot; height&#x3D;”24px”viewBox&#x3D;”0 0 24 24” width&#x3D;”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-8de0dbaa-7fa5-4e4a-86e0-b45a28335c00 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-8de0dbaa-7fa5-4e4a-86e0-b45a28335c00&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 각 연도별, 월별 승객수 구하기 12345678import pandas as pddf = pd.DataFrame(&#123;&#x27;foo&#x27;: [&#x27;one&#x27;, &#x27;one&#x27;, &#x27;one&#x27;, &#x27;two&#x27;, &#x27;two&#x27;, &#x27;two&#x27;], &#x27;bar&#x27;: [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;], &#x27;baz&#x27;: [1, 2, 3, 4, 5, 6], &#x27;zoo&#x27;: [&#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;, &#x27;q&#x27;, &#x27;w&#x27;, &#x27;t&#x27;]&#125;)df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; foo bar baz zoo 0 one A 1 x 1 one B 2 y 2 one C 3 z 3 two A 4 q 4 two B 5 w 5 two C 6 t &lt;svg xmlns&#x3D;”http://www.w3.org/2000/svg&quot; height&#x3D;”24px”viewBox&#x3D;”0 0 24 24” width&#x3D;”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-80b0f574-8430-40f0-9770-1e17dfde6e90 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-80b0f574-8430-40f0-9770-1e17dfde6e90&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 1df.pivot(index = &#x27;foo&#x27;, columns = &#x27;bar&#x27;, values = &#x27;baz&#x27;) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; bar A B C foo one 1 2 3 two 4 5 6 &lt;svg xmlns&#x3D;”http://www.w3.org/2000/svg&quot; height&#x3D;”24px”viewBox&#x3D;”0 0 24 24” width&#x3D;”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-c958c8f1-707a-4f41-9795-66ef57863481 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-c958c8f1-707a-4f41-9795-66ef57863481&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 1flights .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; year month passengers 0 1949 Jan 112 1 1949 Feb 118 2 1949 Mar 132 3 1949 Apr 129 4 1949 May 121 ... ... ... ... 139 1960 Aug 606 140 1960 Sep 508 141 1960 Oct 461 142 1960 Nov 390 143 1960 Dec 432 144 rows × 3 columns &lt;svg xmlns&#x3D;”http://www.w3.org/2000/svg&quot; height&#x3D;”24px”viewBox&#x3D;”0 0 24 24” width&#x3D;”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-5eb1578e-97aa-476f-aa6f-ce955869e387 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-5eb1578e-97aa-476f-aa6f-ce955869e387&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 123# flights[&#x27;year&#x27;].value_counts()flights_pivot = flights.pivot(index = &#x27;month&#x27;, columns = &#x27;year&#x27;, values = &#x27;passengers&#x27;)flights_pivot .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; year 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 month Jan 112 115 145 171 196 204 242 284 315 340 360 417 Feb 118 126 150 180 196 188 233 277 301 318 342 391 Mar 132 141 178 193 236 235 267 317 356 362 406 419 Apr 129 135 163 181 235 227 269 313 348 348 396 461 May 121 125 172 183 229 234 270 318 355 363 420 472 Jun 135 149 178 218 243 264 315 374 422 435 472 535 Jul 148 170 199 230 264 302 364 413 465 491 548 622 Aug 148 170 199 242 272 293 347 405 467 505 559 606 Sep 136 158 184 209 237 259 312 355 404 404 463 508 Oct 119 133 162 191 211 229 274 306 347 359 407 461 Nov 104 114 146 172 180 203 237 271 305 310 362 390 Dec 118 140 166 194 201 229 278 306 336 337 405 432 &lt;svg xmlns&#x3D;”http://www.w3.org/2000/svg&quot; height&#x3D;”24px”viewBox&#x3D;”0 0 24 24” width&#x3D;”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-5ba8f5cb-7c6e-4bee-9a11-9ff5ca0e5f50 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-5ba8f5cb-7c6e-4bee-9a11-9ff5ca0e5f50&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 1sns.heatmap(data = flights_pivot) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd6a5c5ca50&gt; 12# 라인플롯sns.lineplot(x = &#x27;year&#x27;, y = &#x27;passengers&#x27;, data = flights) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd6a0d0e890&gt; 123# 산점도tips = sns.load_dataset(&#x27;tips&#x27;)tips.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 &lt;svg xmlns&#x3D;”http://www.w3.org/2000/svg&quot; height&#x3D;”24px”viewBox&#x3D;”0 0 24 24” width&#x3D;”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-50af68bc-5468-436d-b90b-9d2c60168a5d button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-50af68bc-5468-436d-b90b-9d2c60168a5d&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 두개의 연속형 데이터 1sns.scatterplot(x = &#x27;total_bill&#x27;, y = &#x27;tip&#x27;, hue = &#x27;sex&#x27;, data = tips) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd6a0a59310&gt; 12# 회귀선sns.regplot(x = &#x27;total_bill&#x27;, y = &#x27;tip&#x27;, data = tips) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd6a09d0990&gt; 머신러닝 리뷰 가장 인기 있는 모델 LightGBM,. XGboost 선형 회귀 선형 회귀식을 찾는 것이 중요 $y &#x3D; 3x + 4$에 근사한 데이터 50개 생성 12345678910111213141516import numpy as np import pandas as pd# 시드값 고정 np.random.seed(0)intercept = 4 # 절편, 상수slope = 3 # 기울기# 변동성 주기 위해 노이즈 생성noise = np.random.randn(50, 1)x = 5 * np.random.rand(50, 1) # 0과 5사이의 실숫값 50개 생성y = slope * x + intercept + noise# 데이터 프레임 생성data = pd.DataFrame(&#123;&#x27;X&#x27; : x[:, 0], &#x27;Y&#x27; : y[:, 0]&#125;)print(data) X Y 0 0.794848 8.148596 1 0.551876 6.055784 2 3.281648 14.823682 3 0.690915 8.313637 4 0.982912 8.816293 5 1.843626 8.553600 6 4.104966 17.264987 7 0.485506 5.305162 8 4.189725 16.465955 9 0.480492 5.852075 10 4.882297 18.790936 11 2.343256 12.484042 12 4.883805 19.412454 13 3.024228 13.194358 14 3.696318 15.532817 15 0.195939 4.921491 16 1.414035 9.736184 17 0.600983 5.597790 18 1.480701 8.755171 19 0.593639 4.926820 20 1.589916 6.216758 21 2.071315 10.867564 22 0.320737 5.826649 23 3.462361 13.644917 24 2.833007 14.768776 25 1.326947 6.526477 26 2.616240 11.894479 27 0.469703 5.221924 28 2.879732 14.171977 29 4.646481 19.408802 30 1.592845 8.933482 31 3.337052 14.389318 32 0.658989 5.089182 33 3.581636 12.764112 34 1.447030 7.993179 35 0.915957 6.904219 36 2.932565 14.027985 37 0.100538 5.503993 38 4.144700 16.046774 39 0.023477 3.768129 40 3.389083 13.118695 41 1.350040 6.630102 42 3.675970 13.321640 43 4.810943 20.383604 44 1.243766 7.221645 45 2.880787 12.204286 46 2.960210 11.627834 47 2.861260 13.361269 48 1.115408 5.732327 49 4.763745 18.078495 1234import matplotlib.pyplot as pltfig, ax = plt.subplots()ax.scatter(data[&#x27;X&#x27;], data[&#x27;Y&#x27;])plt.show() 12import seaborn as sns sns.scatterplot(x = &#x27;X&#x27;, y = &#x27;Y&#x27;, data = data) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd6a0949f90&gt; 선형회귀 모형 훈련 모형 생성 후, 회귀계수 3과 y절편 4에 근사한 값이 나와야 함 123456from sklearn.linear_model import LinearRegression lr_model = LinearRegression() # 선형 회귀 모델 lr_model.fit(x, y) # 모델 훈련print(&#x27;y절편:&#x27;, lr_model.intercept_)print(&#x27;회귀계수:&#x27;, lr_model.coef_) y절편: [4.05757639] 회귀계수: [[3.03754061]] 1234567891011# 예측값y_pred = lr_model.predict(x)fig, ax = plt.subplots()ax.scatter(x, y)ax.plot(x, y_pred, color=&#x27;green&#x27;)# slope, intercept label = &#x27;slope: &#123;&#125;\\nintercept: &#123;&#125;&#x27;.format(round(lr_model.coef_[0][0], 2), round(lr_model.intercept_[0], 2))ax.text(3.5, 4, label, style =&#x27;italic&#x27;, fontsize = 10, color =&quot;green&quot;)plt.show() 로지스틱 회귀- 1234567891011121314151617181920import numpy as npimport matplotlib.pyplot as pltdef sigmoid(arr, scale=1): arr = np.asarray(arr) result = 1/(1 + np.exp(-arr*scale)) return resultx = np.linspace(-6, 6)y = sigmoid(x)fig, ax = plt.subplots()ax.plot(x, y)ax.grid(which=&#x27;major&#x27;, axis=&#x27;y&#x27;, linestyle=&#x27;--&#x27;)ax.axvline(x=0, color=&#x27;r&#x27;, linestyle=&#x27;--&#x27;, linewidth=1)ax.set_ylim(0,1)ax.set_yticks([0, 1, 0.5])ax.text(0-0.1, 0.5, &#x27;0.5&#x27;, ha=&#x27;right&#x27;)ax.set_title(&#x27;Sigmoid Graph&#x27;)plt.show() 12345678910111213# 라이브러리 불러오기import matplotlib.pyplot as pltimport numpy as npfrom sklearn.linear_model import LogisticRegressionfrom sklearn.metrics import classification_report, confusion_matrix# 데이터 가져오기x = np.arange(10).reshape(-1, 1)y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])# 모델 생성 및 학습model = LogisticRegression(solver=&#x27;liblinear&#x27;, C=10.0, random_state=0)model.fit(x, y) LogisticRegression(C=10.0, random_state=0, solver=&#39;liblinear&#39;) 123# 모형 평가p_pred = model.predict_proba(x)print(&#x27;p_pred&#x27;, p_pred, sep = &#x27;\\n&#x27;) p_pred [[0.97979027 0.02020973] [0.94958202 0.05041798] [0.87976149 0.12023851] [0.73975066 0.26024934] [0.52477284 0.47522716] [0.30020373 0.69979627] [0.1428487 0.8571513 ] [0.06080627 0.93919373] [0.02453462 0.97546538] [0.00967652 0.99032348]] 12y_pred = model.predict(x)print(&#x27;y_pred&#x27;, y_pred) y_pred [0 0 0 0 0 1 1 1 1 1] 12345678910fig, ax = plt.subplots()ax.scatter(x, y)ax.plot(x, p_pred[:, 1], color = &#x27;black&#x27;, marker=&#x27;o&#x27;, markersize=6)ax.plot()ax.set_xticks(x)ax.set_yticks(np.arange(0, 1.1, 0.1))ax.grid(which=&#x27;major&#x27;, alpha=0.5)plt.show() 12conf_m = confusion_matrix(y, y_pred)print(conf_m) [[5 0] [0 5]] 123456789101112cm = confusion_matrix(y, y_pred)fig, ax = plt.subplots(figsize=(8, 8))ax.imshow(cm, cmap = &#x27;GnBu&#x27;)ax.grid(False)ax.xaxis.set(ticks=(0, 1), ticklabels=(&#x27;Predicted 0&#x27;, &#x27;Predicted 1&#x27;))ax.yaxis.set(ticks=(0, 1), ticklabels=(&#x27;Actual 0&#x27;, &#x27;Actual 1&#x27;))ax.set_ylim(1.5, -0.5)for i in range(2): for j in range(2): ax.text(j, i, cm[i, j], ha=&#x27;center&#x27;, va=&#x27;center&#x27;, color=&#x27;black&#x27;, fontsize=20)plt.show() 결정 트리 분류와 회귀 문제에 모두 사용 가능 주요 개념 작동 원리 데이터를 가장 잘 구분하는 조건을 정함. 조건을 기준으로 데이터를 두 범주로 나눔 나뉜 각 범주의 데이터를 구분하는 조건을 정함 각 조건을 기준으로 데이터를 두 범주로 나눔 언제까지 계속 분할할지 정한 후, 최종 결정 값을 구함. 불순도(Impurity) 한 범주 안에 서로 다른 데이터가 얼마나 섞여 있는지 나타냄 흰색과 검은색이 50:50으로 섞여 있다. (불순도 최대) 흰색과 검은색으로 완전 분리 되었다. (불순도 최소) 엔트로피(Entropy) 불확실한 정도를 의미함. 0 ~ 1로 정함. 흰색과 검은색이 50:50으로 섞여 있다. 엔트로피 1 흰색과 검은색으로 완전 분리 되었다. 엔트로피 0 정보이득(Information Gain) 1에서 엔트로피를 뺀 수치 정보 이득을 최대화하는 방향(엔트로피를 최소화 하는 방향)으로 노드를 분할함 지니 불순도(Gini Impurity) 지니 불순도 값이 클수록 불순도도 높고, 작을수록 불순도도 낮음. 엔트로피와 마찬가지로 지니 불순도가 낮아지는 방향으로 노드 분할함. 1234567from sklearn.tree import DecisionTreeClassifierfrom sklearn.model_selection import train_test_split import seaborn as sns # tips 데이터셋 titanic = sns.load_dataset(&#x27;titanic&#x27;)titanic.info() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 15 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 survived 891 non-null int64 1 pclass 891 non-null int64 2 sex 891 non-null object 3 age 714 non-null float64 4 sibsp 891 non-null int64 5 parch 891 non-null int64 6 fare 891 non-null float64 7 embarked 889 non-null object 8 class 891 non-null category 9 who 891 non-null object 10 adult_male 891 non-null bool 11 deck 203 non-null category 12 embark_town 889 non-null object 13 alive 891 non-null object 14 alone 891 non-null bool dtypes: bool(2), category(2), float64(2), int64(4), object(5) memory usage: 80.7+ KB survived의 비율을 구한다. 0: 사망자 1: 생존자 1titanic[&#x27;survived&#x27;].value_counts() 0 549 1 342 Name: survived, dtype: int64 1234567# 데이터 추출X = titanic[[&#x27;pclass&#x27;, &#x27;parch&#x27;, &#x27;fare&#x27;]]y = titanic[&#x27;survived&#x27;]# 훈련데이터, 테스트 데이터 분리X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.3, random_state=42)X_train.shape, X_test.shape, y_train.shape, y_test.shape ((623, 3), (268, 3), (623,), (268,)) 12345tree_model = DecisionTreeClassifier()tree_model.fit(X_train, y_train)acc = tree_model.score(X_test, y_test)print(f&#x27;모형 정확도 : &#123;acc:.3f&#125;&#x27;) # 정확도 측정 모형 정확도 : 0.675 랜덤 포레스트12345678910111213141516171819from sklearn.ensemble import RandomForestClassifierfrom sklearn.model_selection import train_test_split import seaborn as sns # tips 데이터셋 titanic = sns.load_dataset(&#x27;titanic&#x27;)X = titanic[[&#x27;pclass&#x27;, &#x27;parch&#x27;, &#x27;fare&#x27;]]y = titanic[&#x27;survived&#x27;]# 훈련데이터, 테스트 데이터 분리X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.3, random_state=42)# 모델 훈련rf_model = RandomForestClassifier(random_state=42) # 랜덤 포레스트 정의rf_model.fit(X_train, y_train)acc = rf_model.score(X_test, y_test)print(f&#x27;모형 정확도 : &#123;acc:.3f&#125;&#x27;) # 정확도 측정 모형 정확도 : 0.675 XGBoost &amp; LightGBM (2016 ~ 2017) 전통적인 머선러닝 알고리즘의 융합 선형회귀 릿지 라쏘, 과적합 방지 위한 규제 결정 트리의 핵심적인 알고리즘 경사 하강법 부스팅 기법 문제점 : 파라미터의 개수가 매우 많음. 왜 많이 쓸까요? 모델 학습 속도 성능 가장 좋은 모델이란, 학습 속도는 빠르면서 성능은 좋은 것 (지금까지 나온 알고리즘 보다) Python JAVA, C, C++ C, C++ &#x2F; r data.table 패키지 큰 회사들 개발 첫번째 옵션, 우리가 자체적으로 배포하자. –&gt; Python Wrapper API R, 머신러닝 프레임워크 종류 다양 두번째 옵션 파이썬 머신러닝 &#x3D; Scikit-Learn에서 쉽게 쓸 수 있도록 개발, Scikit-Learn Wrapper API XGBoost Python Wrapper 방식 X_train, y_train 각 모듈에 맞도록 행렬을 재변환 해야 함. 1234567891011121314151617181920import xgboost as xgb from sklearn.model_selection import train_test_splitimport seaborn as sns # 데이터 분리titanic = sns.load_dataset(&#x27;titanic&#x27;)# titanic.info()# X, 독립변수, y 종속변수X = titanic[[&#x27;pclass&#x27;, &#x27;parch&#x27;, &#x27;fare&#x27;]]y = titanic[&#x27;survived&#x27;]# 훈련데이터, 테스트 데이터 분리X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.3, random_state=42)X_train.shape, X_test.shape, y_train.shape, y_test.shape &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 15 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 survived 891 non-null int64 1 pclass 891 non-null int64 2 sex 891 non-null object 3 age 714 non-null float64 4 sibsp 891 non-null int64 5 parch 891 non-null int64 6 fare 891 non-null float64 7 embarked 889 non-null object 8 class 891 non-null category 9 who 891 non-null object 10 adult_male 891 non-null bool 11 deck 203 non-null category 12 embark_town 889 non-null object 13 alive 891 non-null object 14 alone 891 non-null bool dtypes: bool(2), category(2), float64(2), int64(4), object(5) memory usage: 80.7+ KB ((623, 3), (268, 3), (623,), (268,)) 여기가 핵심 1234dtrain = xgb.DMatrix(data = X_train, label = y_train)dtest = xgb.DMatrix(data = X_test, label = y_test)print(dtrain) &lt;xgboost.core.DMatrix object at 0x7f179de8fb10&gt; 머신러닝 코드 1234567891011121314params = &#123; &#x27;max_depth&#x27; : 3, &#x27;n_estimators&#x27; : 100, &#x27;eta&#x27; : 0.1, &#x27;objective&#x27; : &#x27;binary:logistic&#x27;&#125;num_rounds = 400w_list = [(dtrain, &#x27;train&#x27;), (dtest, &#x27;test&#x27;)]xgb_ml = xgb.train(params = params, dtrain = dtrain, num_boost_round = 400, early_stopping_rounds = 100, evals = w_list) [0] train-error:0.260032 test-error:0.302239 Multiple eval metrics have been passed: &#39;test-error&#39; will be used for early stopping. Will train until test-error hasn&#39;t improved in 100 rounds. [1] train-error:0.260032 test-error:0.302239 [2] train-error:0.260032 test-error:0.302239 [3] train-error:0.260032 test-error:0.302239 [4] train-error:0.260032 test-error:0.302239 [5] train-error:0.260032 test-error:0.302239 [6] train-error:0.260032 test-error:0.302239 [7] train-error:0.260032 test-error:0.302239 [8] train-error:0.260032 test-error:0.302239 [9] train-error:0.260032 test-error:0.302239 [10] train-error:0.260032 test-error:0.302239 [11] train-error:0.260032 test-error:0.302239 [12] train-error:0.260032 test-error:0.302239 [13] train-error:0.247191 test-error:0.298507 [14] train-error:0.247191 test-error:0.298507 [15] train-error:0.248796 test-error:0.302239 [16] train-error:0.248796 test-error:0.302239 [17] train-error:0.248796 test-error:0.302239 [18] train-error:0.248796 test-error:0.302239 [19] train-error:0.248796 test-error:0.302239 [20] train-error:0.248796 test-error:0.302239 [21] train-error:0.248796 test-error:0.302239 [22] train-error:0.248796 test-error:0.302239 [23] train-error:0.248796 test-error:0.302239 [24] train-error:0.248796 test-error:0.302239 [25] train-error:0.248796 test-error:0.302239 [26] train-error:0.248796 test-error:0.302239 [27] train-error:0.248796 test-error:0.302239 [28] train-error:0.247191 test-error:0.302239 [29] train-error:0.247191 test-error:0.302239 [30] train-error:0.247191 test-error:0.302239 [31] train-error:0.243981 test-error:0.298507 [32] train-error:0.247191 test-error:0.302239 [33] train-error:0.243981 test-error:0.298507 [34] train-error:0.243981 test-error:0.298507 [35] train-error:0.242376 test-error:0.294776 [36] train-error:0.24077 test-error:0.294776 [37] train-error:0.24077 test-error:0.294776 [38] train-error:0.24077 test-error:0.294776 [39] train-error:0.24077 test-error:0.294776 [40] train-error:0.24077 test-error:0.294776 [41] train-error:0.24077 test-error:0.294776 [42] train-error:0.24077 test-error:0.294776 [43] train-error:0.24077 test-error:0.294776 [44] train-error:0.24077 test-error:0.302239 [45] train-error:0.24077 test-error:0.302239 [46] train-error:0.24077 test-error:0.302239 [47] train-error:0.24077 test-error:0.302239 [48] train-error:0.24077 test-error:0.302239 [49] train-error:0.24077 test-error:0.302239 [50] train-error:0.24077 test-error:0.302239 [51] train-error:0.24077 test-error:0.302239 [52] train-error:0.23435 test-error:0.302239 [53] train-error:0.23435 test-error:0.302239 [54] train-error:0.232745 test-error:0.298507 [55] train-error:0.229535 test-error:0.298507 [56] train-error:0.229535 test-error:0.298507 [57] train-error:0.229535 test-error:0.298507 [58] train-error:0.229535 test-error:0.298507 [59] train-error:0.227929 test-error:0.294776 [60] train-error:0.227929 test-error:0.298507 [61] train-error:0.227929 test-error:0.298507 [62] train-error:0.227929 test-error:0.298507 [63] train-error:0.227929 test-error:0.298507 [64] train-error:0.227929 test-error:0.298507 [65] train-error:0.227929 test-error:0.298507 [66] train-error:0.227929 test-error:0.298507 [67] train-error:0.227929 test-error:0.298507 [68] train-error:0.227929 test-error:0.298507 [69] train-error:0.227929 test-error:0.298507 [70] train-error:0.227929 test-error:0.298507 [71] train-error:0.227929 test-error:0.298507 [72] train-error:0.227929 test-error:0.302239 [73] train-error:0.227929 test-error:0.302239 [74] train-error:0.229535 test-error:0.30597 [75] train-error:0.229535 test-error:0.30597 [76] train-error:0.229535 test-error:0.30597 [77] train-error:0.229535 test-error:0.30597 [78] train-error:0.229535 test-error:0.30597 [79] train-error:0.229535 test-error:0.30597 [80] train-error:0.229535 test-error:0.30597 [81] train-error:0.229535 test-error:0.30597 [82] train-error:0.229535 test-error:0.30597 [83] train-error:0.229535 test-error:0.30597 [84] train-error:0.229535 test-error:0.30597 [85] train-error:0.229535 test-error:0.30597 [86] train-error:0.229535 test-error:0.30597 [87] train-error:0.229535 test-error:0.30597 [88] train-error:0.229535 test-error:0.30597 [89] train-error:0.229535 test-error:0.30597 [90] train-error:0.229535 test-error:0.30597 [91] train-error:0.229535 test-error:0.30597 [92] train-error:0.229535 test-error:0.30597 [93] train-error:0.229535 test-error:0.30597 [94] train-error:0.227929 test-error:0.313433 [95] train-error:0.226324 test-error:0.313433 [96] train-error:0.223114 test-error:0.317164 [97] train-error:0.223114 test-error:0.317164 [98] train-error:0.223114 test-error:0.317164 [99] train-error:0.223114 test-error:0.317164 [100] train-error:0.223114 test-error:0.317164 [101] train-error:0.223114 test-error:0.317164 [102] train-error:0.223114 test-error:0.317164 [103] train-error:0.223114 test-error:0.317164 [104] train-error:0.223114 test-error:0.317164 [105] train-error:0.223114 test-error:0.317164 [106] train-error:0.223114 test-error:0.317164 [107] train-error:0.223114 test-error:0.317164 [108] train-error:0.223114 test-error:0.317164 [109] train-error:0.223114 test-error:0.317164 [110] train-error:0.223114 test-error:0.317164 [111] train-error:0.223114 test-error:0.317164 [112] train-error:0.223114 test-error:0.317164 [113] train-error:0.223114 test-error:0.317164 [114] train-error:0.223114 test-error:0.317164 [115] train-error:0.223114 test-error:0.317164 [116] train-error:0.223114 test-error:0.317164 [117] train-error:0.223114 test-error:0.317164 [118] train-error:0.223114 test-error:0.317164 [119] train-error:0.223114 test-error:0.317164 [120] train-error:0.223114 test-error:0.317164 [121] train-error:0.223114 test-error:0.317164 [122] train-error:0.223114 test-error:0.317164 [123] train-error:0.223114 test-error:0.317164 [124] train-error:0.224719 test-error:0.317164 [125] train-error:0.224719 test-error:0.317164 [126] train-error:0.224719 test-error:0.317164 [127] train-error:0.221509 test-error:0.317164 [128] train-error:0.223114 test-error:0.317164 [129] train-error:0.219904 test-error:0.313433 [130] train-error:0.215088 test-error:0.313433 [131] train-error:0.215088 test-error:0.313433 [132] train-error:0.215088 test-error:0.313433 [133] train-error:0.215088 test-error:0.313433 [134] train-error:0.215088 test-error:0.313433 [135] train-error:0.215088 test-error:0.313433 Stopping. Best iteration: [35] train-error:0.242376 test-error:0.294776 1234567# 평가from sklearn.metrics import accuracy_scorepred_probs = xgb_ml.predict(dtest) y_pred = [1 if x &gt; 0.5 else 0 for x in pred_probs]# 예측 라벨과 실제 라벨 사이의 정확도 측정accuracy_score(y_pred, y_test) 0.6977611940298507 XGBoost Scikit-Learn API 방식1234567891011121314151617181920from sklearn.tree import DecisionTreeClassifierfrom xgboost import XGBClassifier # API # dt = DecisionTreeClassifier()xgb_model = XGBClassifier(objective = &#x27;binary:logistic&#x27;, n_estimators=100, max_depth=3, learning_rate = 0.1, num_rounds = 400, random_state=42)w_list = [(X_train, y_train), (X_test, y_test)]xgb_model.fit(X_train, y_train, eval_set = w_list, eval_metric=&#x27;error&#x27;, verbose=True)y_probas = xgb_model.predict_proba(X_test)y_pred = [1 if x &gt; 0.5 else 0 for x in pred_probs]# 예측 라벨과 실제 라벨 사이의 정확도 측정accuracy_score(y_pred, y_test) [0] validation_0-error:0.260032 validation_1-error:0.302239 [1] validation_0-error:0.260032 validation_1-error:0.302239 [2] validation_0-error:0.260032 validation_1-error:0.302239 [3] validation_0-error:0.260032 validation_1-error:0.302239 [4] validation_0-error:0.260032 validation_1-error:0.302239 [5] validation_0-error:0.260032 validation_1-error:0.302239 [6] validation_0-error:0.260032 validation_1-error:0.302239 [7] validation_0-error:0.260032 validation_1-error:0.302239 [8] validation_0-error:0.260032 validation_1-error:0.302239 [9] validation_0-error:0.260032 validation_1-error:0.302239 [10] validation_0-error:0.260032 validation_1-error:0.302239 [11] validation_0-error:0.260032 validation_1-error:0.302239 [12] validation_0-error:0.260032 validation_1-error:0.302239 [13] validation_0-error:0.247191 validation_1-error:0.298507 [14] validation_0-error:0.247191 validation_1-error:0.298507 [15] validation_0-error:0.248796 validation_1-error:0.302239 [16] validation_0-error:0.248796 validation_1-error:0.302239 [17] validation_0-error:0.248796 validation_1-error:0.302239 [18] validation_0-error:0.248796 validation_1-error:0.302239 [19] validation_0-error:0.248796 validation_1-error:0.302239 [20] validation_0-error:0.248796 validation_1-error:0.302239 [21] validation_0-error:0.248796 validation_1-error:0.302239 [22] validation_0-error:0.248796 validation_1-error:0.302239 [23] validation_0-error:0.248796 validation_1-error:0.302239 [24] validation_0-error:0.248796 validation_1-error:0.302239 [25] validation_0-error:0.248796 validation_1-error:0.302239 [26] validation_0-error:0.248796 validation_1-error:0.302239 [27] validation_0-error:0.248796 validation_1-error:0.302239 [28] validation_0-error:0.247191 validation_1-error:0.302239 [29] validation_0-error:0.247191 validation_1-error:0.302239 [30] validation_0-error:0.247191 validation_1-error:0.302239 [31] validation_0-error:0.243981 validation_1-error:0.298507 [32] validation_0-error:0.247191 validation_1-error:0.302239 [33] validation_0-error:0.243981 validation_1-error:0.298507 [34] validation_0-error:0.243981 validation_1-error:0.298507 [35] validation_0-error:0.242376 validation_1-error:0.294776 [36] validation_0-error:0.24077 validation_1-error:0.294776 [37] validation_0-error:0.24077 validation_1-error:0.294776 [38] validation_0-error:0.24077 validation_1-error:0.294776 [39] validation_0-error:0.24077 validation_1-error:0.294776 [40] validation_0-error:0.24077 validation_1-error:0.294776 [41] validation_0-error:0.24077 validation_1-error:0.294776 [42] validation_0-error:0.24077 validation_1-error:0.294776 [43] validation_0-error:0.24077 validation_1-error:0.294776 [44] validation_0-error:0.24077 validation_1-error:0.302239 [45] validation_0-error:0.24077 validation_1-error:0.302239 [46] validation_0-error:0.24077 validation_1-error:0.302239 [47] validation_0-error:0.24077 validation_1-error:0.302239 [48] validation_0-error:0.24077 validation_1-error:0.302239 [49] validation_0-error:0.24077 validation_1-error:0.302239 [50] validation_0-error:0.24077 validation_1-error:0.302239 [51] validation_0-error:0.24077 validation_1-error:0.302239 [52] validation_0-error:0.23435 validation_1-error:0.302239 [53] validation_0-error:0.23435 validation_1-error:0.302239 [54] validation_0-error:0.232745 validation_1-error:0.298507 [55] validation_0-error:0.229535 validation_1-error:0.298507 [56] validation_0-error:0.229535 validation_1-error:0.298507 [57] validation_0-error:0.229535 validation_1-error:0.298507 [58] validation_0-error:0.229535 validation_1-error:0.298507 [59] validation_0-error:0.227929 validation_1-error:0.294776 [60] validation_0-error:0.227929 validation_1-error:0.298507 [61] validation_0-error:0.227929 validation_1-error:0.298507 [62] validation_0-error:0.227929 validation_1-error:0.298507 [63] validation_0-error:0.227929 validation_1-error:0.298507 [64] validation_0-error:0.227929 validation_1-error:0.298507 [65] validation_0-error:0.227929 validation_1-error:0.298507 [66] validation_0-error:0.227929 validation_1-error:0.298507 [67] validation_0-error:0.227929 validation_1-error:0.298507 [68] validation_0-error:0.227929 validation_1-error:0.298507 [69] validation_0-error:0.227929 validation_1-error:0.298507 [70] validation_0-error:0.227929 validation_1-error:0.298507 [71] validation_0-error:0.227929 validation_1-error:0.298507 [72] validation_0-error:0.227929 validation_1-error:0.302239 [73] validation_0-error:0.227929 validation_1-error:0.302239 [74] validation_0-error:0.229535 validation_1-error:0.30597 [75] validation_0-error:0.229535 validation_1-error:0.30597 [76] validation_0-error:0.229535 validation_1-error:0.30597 [77] validation_0-error:0.229535 validation_1-error:0.30597 [78] validation_0-error:0.229535 validation_1-error:0.30597 [79] validation_0-error:0.229535 validation_1-error:0.30597 [80] validation_0-error:0.229535 validation_1-error:0.30597 [81] validation_0-error:0.229535 validation_1-error:0.30597 [82] validation_0-error:0.229535 validation_1-error:0.30597 [83] validation_0-error:0.229535 validation_1-error:0.30597 [84] validation_0-error:0.229535 validation_1-error:0.30597 [85] validation_0-error:0.229535 validation_1-error:0.30597 [86] validation_0-error:0.229535 validation_1-error:0.30597 [87] validation_0-error:0.229535 validation_1-error:0.30597 [88] validation_0-error:0.229535 validation_1-error:0.30597 [89] validation_0-error:0.229535 validation_1-error:0.30597 [90] validation_0-error:0.229535 validation_1-error:0.30597 [91] validation_0-error:0.229535 validation_1-error:0.30597 [92] validation_0-error:0.229535 validation_1-error:0.30597 [93] validation_0-error:0.229535 validation_1-error:0.30597 [94] validation_0-error:0.227929 validation_1-error:0.313433 [95] validation_0-error:0.226324 validation_1-error:0.313433 [96] validation_0-error:0.223114 validation_1-error:0.317164 [97] validation_0-error:0.223114 validation_1-error:0.317164 [98] validation_0-error:0.223114 validation_1-error:0.317164 [99] validation_0-error:0.223114 validation_1-error:0.317164 0.6977611940298507 LightGBM Python Wrapper 방식1234567891011121314151617181920212223242526272829303132333435import lightgbm as lgb from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_scoreimport seaborn as sns # tips 데이터셋 titanic = sns.load_dataset(&#x27;titanic&#x27;)X = titanic[[&#x27;pclass&#x27;, &#x27;parch&#x27;, &#x27;fare&#x27;]]y = titanic[&#x27;survived&#x27;]# 훈련데이터, 테스트 데이터 분리X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.3, random_state=42)# XGBoost 코드와 유사하다. dtrain = lgb.Dataset(data = X_train, label = y_train)dtest = lgb.Dataset(data = X_test, label = y_test)params = &#123;&#x27;max_depth&#x27;:3, &#x27;n_estimators&#x27;:100, &#x27;learning_rate&#x27;: 0.1, # xgboost eta &#x27;objective&#x27;:&#x27;binary&#x27;, # xgboost binary:logistic &#x27;metric&#x27; : &#x27;binary_error&#x27;, &#x27;num_boost_round&#x27; : 400, &#x27;verbose&#x27; : 1&#125; w_list = [dtrain, dtest]lgb_ml = lgb.train(params=params, train_set = dtrain,\\ early_stopping_rounds=100, valid_sets= w_list)pred_probs = lgb_ml.predict(X_test)y_pred=[1 if x &gt; 0.5 else 0 for x in pred_probs]# 예측 라벨과 실제 라벨 사이의 정확도 측정accuracy_score(y_pred, y_test) /usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument warnings.warn(&quot;Found `&#123;&#125;` in params. Will use it instead of argument&quot;.format(alias)) [1] training&#39;s binary_error: 0.383628 valid_1&#39;s binary_error: 0.384328 Training until validation scores don&#39;t improve for 100 rounds. [2] training&#39;s binary_error: 0.383628 valid_1&#39;s binary_error: 0.384328 [3] training&#39;s binary_error: 0.354735 valid_1&#39;s binary_error: 0.369403 [4] training&#39;s binary_error: 0.29695 valid_1&#39;s binary_error: 0.354478 [5] training&#39;s binary_error: 0.272873 valid_1&#39;s binary_error: 0.33209 [6] training&#39;s binary_error: 0.272873 valid_1&#39;s binary_error: 0.33209 [7] training&#39;s binary_error: 0.269663 valid_1&#39;s binary_error: 0.317164 [8] training&#39;s binary_error: 0.269663 valid_1&#39;s binary_error: 0.317164 [9] training&#39;s binary_error: 0.264848 valid_1&#39;s binary_error: 0.309701 [10] training&#39;s binary_error: 0.269663 valid_1&#39;s binary_error: 0.309701 [11] training&#39;s binary_error: 0.264848 valid_1&#39;s binary_error: 0.309701 [12] training&#39;s binary_error: 0.264848 valid_1&#39;s binary_error: 0.309701 [13] training&#39;s binary_error: 0.264848 valid_1&#39;s binary_error: 0.309701 [14] training&#39;s binary_error: 0.264848 valid_1&#39;s binary_error: 0.309701 [15] training&#39;s binary_error: 0.264848 valid_1&#39;s binary_error: 0.309701 [16] training&#39;s binary_error: 0.266453 valid_1&#39;s binary_error: 0.313433 [17] training&#39;s binary_error: 0.266453 valid_1&#39;s binary_error: 0.313433 [18] training&#39;s binary_error: 0.266453 valid_1&#39;s binary_error: 0.313433 [19] training&#39;s binary_error: 0.266453 valid_1&#39;s binary_error: 0.313433 [20] training&#39;s binary_error: 0.266453 valid_1&#39;s binary_error: 0.313433 [21] training&#39;s binary_error: 0.266453 valid_1&#39;s binary_error: 0.313433 [22] training&#39;s binary_error: 0.266453 valid_1&#39;s binary_error: 0.313433 [23] training&#39;s binary_error: 0.271268 valid_1&#39;s binary_error: 0.313433 [24] training&#39;s binary_error: 0.258427 valid_1&#39;s binary_error: 0.309701 [25] training&#39;s binary_error: 0.258427 valid_1&#39;s binary_error: 0.309701 [26] training&#39;s binary_error: 0.258427 valid_1&#39;s binary_error: 0.309701 [27] training&#39;s binary_error: 0.258427 valid_1&#39;s binary_error: 0.309701 [28] training&#39;s binary_error: 0.258427 valid_1&#39;s binary_error: 0.309701 [29] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.309701 [30] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.309701 [31] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.309701 [32] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.309701 [33] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.317164 [34] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.317164 [35] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.317164 [36] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.309701 [37] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.317164 [38] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.317164 [39] training&#39;s binary_error: 0.248796 valid_1&#39;s binary_error: 0.309701 [40] training&#39;s binary_error: 0.248796 valid_1&#39;s binary_error: 0.313433 [41] training&#39;s binary_error: 0.248796 valid_1&#39;s binary_error: 0.313433 [42] training&#39;s binary_error: 0.248796 valid_1&#39;s binary_error: 0.313433 [43] training&#39;s binary_error: 0.248796 valid_1&#39;s binary_error: 0.313433 [44] training&#39;s binary_error: 0.248796 valid_1&#39;s binary_error: 0.313433 [45] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [46] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [47] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [48] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [49] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [50] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [51] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [52] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [53] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [54] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [55] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [56] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [57] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [58] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [59] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [60] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [61] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [62] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [63] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [64] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [65] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [66] training&#39;s binary_error: 0.243981 valid_1&#39;s binary_error: 0.309701 [67] training&#39;s binary_error: 0.23435 valid_1&#39;s binary_error: 0.309701 [68] training&#39;s binary_error: 0.23435 valid_1&#39;s binary_error: 0.309701 [69] training&#39;s binary_error: 0.23435 valid_1&#39;s binary_error: 0.309701 [70] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [71] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [72] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [73] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [74] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [75] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [76] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [77] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [78] training&#39;s binary_error: 0.232745 valid_1&#39;s binary_error: 0.313433 [79] training&#39;s binary_error: 0.232745 valid_1&#39;s binary_error: 0.313433 [80] training&#39;s binary_error: 0.232745 valid_1&#39;s binary_error: 0.313433 [81] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [82] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [83] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [84] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [85] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [86] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [87] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [88] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [89] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [90] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [91] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [92] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [93] training&#39;s binary_error: 0.227929 valid_1&#39;s binary_error: 0.309701 [94] training&#39;s binary_error: 0.227929 valid_1&#39;s binary_error: 0.309701 [95] training&#39;s binary_error: 0.227929 valid_1&#39;s binary_error: 0.309701 [96] training&#39;s binary_error: 0.227929 valid_1&#39;s binary_error: 0.309701 [97] training&#39;s binary_error: 0.227929 valid_1&#39;s binary_error: 0.309701 [98] training&#39;s binary_error: 0.227929 valid_1&#39;s binary_error: 0.309701 [99] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.317164 [100] training&#39;s binary_error: 0.227929 valid_1&#39;s binary_error: 0.309701 [101] training&#39;s binary_error: 0.23114 valid_1&#39;s binary_error: 0.30597 [102] training&#39;s binary_error: 0.23114 valid_1&#39;s binary_error: 0.30597 [103] training&#39;s binary_error: 0.227929 valid_1&#39;s binary_error: 0.309701 [104] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.317164 [105] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.317164 [106] training&#39;s binary_error: 0.224719 valid_1&#39;s binary_error: 0.313433 [107] training&#39;s binary_error: 0.224719 valid_1&#39;s binary_error: 0.317164 [108] training&#39;s binary_error: 0.224719 valid_1&#39;s binary_error: 0.317164 [109] training&#39;s binary_error: 0.224719 valid_1&#39;s binary_error: 0.317164 [110] training&#39;s binary_error: 0.224719 valid_1&#39;s binary_error: 0.317164 [111] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [112] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [113] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [114] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [115] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [116] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [117] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [118] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [119] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [120] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [121] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [122] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [123] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [124] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [125] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [126] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [127] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [128] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [129] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [130] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [131] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [132] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [133] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [134] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [135] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [136] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [137] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.309701 [138] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.309701 [139] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [140] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [141] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [142] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [143] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [144] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.320896 [145] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [146] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.313433 [147] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.313433 [148] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.313433 [149] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.313433 [150] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [151] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [152] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.313433 [153] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [154] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [155] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [156] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [157] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [158] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [159] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [160] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [161] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [162] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [163] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [164] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [165] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [166] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [167] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [168] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [169] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [170] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [171] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [172] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [173] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [174] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [175] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [176] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [177] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.328358 [178] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.328358 [179] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.328358 [180] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.328358 [181] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.328358 [182] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [183] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [184] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [185] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [186] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [187] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [188] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [189] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [190] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [191] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [192] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [193] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [194] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [195] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [196] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [197] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [198] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [199] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [200] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [201] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 Early stopping, best iteration is: [101] training&#39;s binary_error: 0.23114 valid_1&#39;s binary_error: 0.30597 0.6940298507462687 LightGBM Scikit-Learn API 방식12345678910111213141516171819202122from lightgbm import LGBMClassifierfrom sklearn.metrics import accuracy_score# model w_list = [dtrain, dtest]model = LGBMClassifier(objective = &#x27;binary&#x27;, metric = &#x27;binary_error&#x27;, n_estimators=100, learning_rate=0.1, max_depth=3, num_boost_round = 400, random_state = 32)model.fit(X_train, y_train, eval_set = [(X_train, y_train), (X_test, y_test)], verbose=1, early_stopping_rounds = 100)y_probas = model.predict_proba(X_test) y_pred=[1 if x &gt; 0.5 else 0 for x in y_probas[:, 1]] # 예측 라벨(0과 1로 예측)# 예측 라벨과 실제 라벨 사이의 정확도 측정accuracy_score(y_pred, y_test) [1] training&#39;s binary_error: 0.383628 valid_1&#39;s binary_error: 0.384328 Training until validation scores don&#39;t improve for 100 rounds. [2] training&#39;s binary_error: 0.383628 valid_1&#39;s binary_error: 0.384328 [3] training&#39;s binary_error: 0.354735 valid_1&#39;s binary_error: 0.369403 [4] training&#39;s binary_error: 0.29695 valid_1&#39;s binary_error: 0.354478 [5] training&#39;s binary_error: 0.272873 valid_1&#39;s binary_error: 0.33209 [6] training&#39;s binary_error: 0.272873 valid_1&#39;s binary_error: 0.33209 [7] training&#39;s binary_error: 0.269663 valid_1&#39;s binary_error: 0.317164 [8] training&#39;s binary_error: 0.269663 valid_1&#39;s binary_error: 0.317164 [9] training&#39;s binary_error: 0.264848 valid_1&#39;s binary_error: 0.309701 [10] training&#39;s binary_error: 0.269663 valid_1&#39;s binary_error: 0.309701 [11] training&#39;s binary_error: 0.264848 valid_1&#39;s binary_error: 0.309701 [12] training&#39;s binary_error: 0.264848 valid_1&#39;s binary_error: 0.309701 [13] training&#39;s binary_error: 0.264848 valid_1&#39;s binary_error: 0.309701 [14] training&#39;s binary_error: 0.264848 valid_1&#39;s binary_error: 0.309701 [15] training&#39;s binary_error: 0.264848 valid_1&#39;s binary_error: 0.309701 [16] training&#39;s binary_error: 0.266453 valid_1&#39;s binary_error: 0.313433 [17] training&#39;s binary_error: 0.266453 valid_1&#39;s binary_error: 0.313433 [18] training&#39;s binary_error: 0.266453 valid_1&#39;s binary_error: 0.313433 [19] training&#39;s binary_error: 0.266453 valid_1&#39;s binary_error: 0.313433 [20] training&#39;s binary_error: 0.266453 valid_1&#39;s binary_error: 0.313433 [21] training&#39;s binary_error: 0.266453 valid_1&#39;s binary_error: 0.313433 [22] training&#39;s binary_error: 0.266453 valid_1&#39;s binary_error: 0.313433 [23] training&#39;s binary_error: 0.271268 valid_1&#39;s binary_error: 0.313433 [24] training&#39;s binary_error: 0.258427 valid_1&#39;s binary_error: 0.309701 [25] training&#39;s binary_error: 0.258427 valid_1&#39;s binary_error: 0.309701 [26] training&#39;s binary_error: 0.258427 valid_1&#39;s binary_error: 0.309701 [27] training&#39;s binary_error: 0.258427 valid_1&#39;s binary_error: 0.309701 [28] training&#39;s binary_error: 0.258427 valid_1&#39;s binary_error: 0.309701 [29] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.309701 [30] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.309701 [31] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.309701 [32] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.309701 [33] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.317164 [34] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.317164 [35] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.317164 [36] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.309701 [37] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.317164 [38] training&#39;s binary_error: 0.255217 valid_1&#39;s binary_error: 0.317164 [39] training&#39;s binary_error: 0.248796 valid_1&#39;s binary_error: 0.309701 [40] training&#39;s binary_error: 0.248796 valid_1&#39;s binary_error: 0.313433 [41] training&#39;s binary_error: 0.248796 valid_1&#39;s binary_error: 0.313433 [42] training&#39;s binary_error: 0.248796 valid_1&#39;s binary_error: 0.313433 [43] training&#39;s binary_error: 0.248796 valid_1&#39;s binary_error: 0.313433 [44] training&#39;s binary_error: 0.248796 valid_1&#39;s binary_error: 0.313433 [45] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [46] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [47] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [48] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [49] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [50] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [51] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [52] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [53] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [54] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [55] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [56] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [57] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [58] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [59] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [60] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [61] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [62] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [63] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [64] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [65] training&#39;s binary_error: 0.247191 valid_1&#39;s binary_error: 0.313433 [66] training&#39;s binary_error: 0.243981 valid_1&#39;s binary_error: 0.309701 [67] training&#39;s binary_error: 0.23435 valid_1&#39;s binary_error: 0.309701 [68] training&#39;s binary_error: 0.23435 valid_1&#39;s binary_error: 0.309701 [69] training&#39;s binary_error: 0.23435 valid_1&#39;s binary_error: 0.309701 [70] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [71] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [72] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [73] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [74] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [75] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [76] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [77] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [78] training&#39;s binary_error: 0.232745 valid_1&#39;s binary_error: 0.313433 [79] training&#39;s binary_error: 0.232745 valid_1&#39;s binary_error: 0.313433 [80] training&#39;s binary_error: 0.232745 valid_1&#39;s binary_error: 0.313433 [81] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [82] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [83] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [84] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [85] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [86] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [87] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [88] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [89] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [90] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [91] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [92] training&#39;s binary_error: 0.229535 valid_1&#39;s binary_error: 0.309701 [93] training&#39;s binary_error: 0.227929 valid_1&#39;s binary_error: 0.309701 [94] training&#39;s binary_error: 0.227929 valid_1&#39;s binary_error: 0.309701 [95] training&#39;s binary_error: 0.227929 valid_1&#39;s binary_error: 0.309701 [96] training&#39;s binary_error: 0.227929 valid_1&#39;s binary_error: 0.309701 [97] training&#39;s binary_error: 0.227929 valid_1&#39;s binary_error: 0.309701 [98] training&#39;s binary_error: 0.227929 valid_1&#39;s binary_error: 0.309701 [99] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.317164 [100] training&#39;s binary_error: 0.227929 valid_1&#39;s binary_error: 0.309701 [101] training&#39;s binary_error: 0.23114 valid_1&#39;s binary_error: 0.30597 [102] training&#39;s binary_error: 0.23114 valid_1&#39;s binary_error: 0.30597 [103] training&#39;s binary_error: 0.227929 valid_1&#39;s binary_error: 0.309701 [104] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.317164 [105] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.317164 [106] training&#39;s binary_error: 0.224719 valid_1&#39;s binary_error: 0.313433 [107] training&#39;s binary_error: 0.224719 valid_1&#39;s binary_error: 0.317164 [108] training&#39;s binary_error: 0.224719 valid_1&#39;s binary_error: 0.317164 [109] training&#39;s binary_error: 0.224719 valid_1&#39;s binary_error: 0.317164 [110] training&#39;s binary_error: 0.224719 valid_1&#39;s binary_error: 0.317164 [111] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [112] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [113] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [114] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [115] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [116] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [117] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [118] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [119] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [120] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [121] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [122] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [123] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [124] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [125] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [126] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [127] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [128] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [129] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [130] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [131] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [132] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [133] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [134] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [135] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [136] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [137] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.309701 [138] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.309701 [139] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [140] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [141] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [142] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [143] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.309701 [144] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.320896 [145] training&#39;s binary_error: 0.223114 valid_1&#39;s binary_error: 0.313433 [146] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.313433 [147] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.313433 [148] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.313433 [149] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.313433 [150] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [151] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [152] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.313433 [153] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [154] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [155] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [156] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [157] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [158] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [159] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [160] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [161] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [162] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [163] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [164] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [165] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [166] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [167] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [168] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [169] training&#39;s binary_error: 0.219904 valid_1&#39;s binary_error: 0.324627 [170] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [171] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [172] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [173] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [174] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [175] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [176] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [177] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.328358 [178] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.328358 [179] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.328358 [180] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.328358 [181] training&#39;s binary_error: 0.221509 valid_1&#39;s binary_error: 0.328358 [182] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [183] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [184] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [185] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [186] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [187] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [188] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [189] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [190] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [191] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [192] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [193] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [194] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [195] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [196] training&#39;s binary_error: 0.216693 valid_1&#39;s binary_error: 0.320896 [197] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [198] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [199] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [200] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 [201] training&#39;s binary_error: 0.215088 valid_1&#39;s binary_error: 0.317164 Early stopping, best iteration is: [101] training&#39;s binary_error: 0.23114 valid_1&#39;s binary_error: 0.30597 /usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument warnings.warn(&quot;Found `&#123;&#125;` in params. Will use it instead of argument&quot;.format(alias)) 0.6940298507462687","categories":[],"tags":[]},{"title":"Python 기초문법","slug":"day_0705","date":"2022-07-05T00:00:00.000Z","updated":"2022-07-06T08:34:42.126Z","comments":true,"path":"2022/07/05/day_0705/","link":"","permalink":"https://park128.github.io/2022/07/05/day_0705/","excerpt":"","text":"랜덤 포레스트 Decision Tree (나무 1개) 여러개 심음 샘플링 예측해야 할 행의 갯수, 100만개 컬럼의 갯수 200개 –&gt; 100개 나무 100개를 심고 평균을 내자 나무 1개 당 컬럼을 10개로 T1 mae : 20 &#x2F; T2 mae :30 &#x2F; T3 mae 10, …. T1 ~ T100 mae : 20 teature importances 샘플링 : 부트스트랩 샘플 (복원 추출) 12345678910111213141516171819202122232425262728293031323334# 라이브러리 불러오기 import numpy as np import pandas as pd from sklearn.model_selection import train_test_split, cross_validatefrom sklearn.ensemble import RandomForestClassifier# 데이터 불러오기wine = pd.read_csv(&#x27;https://bit.ly/wine_csv_data&#x27;)# input, target 분리 data = wine[[&#x27;alcohol&#x27;, &#x27;sugar&#x27;, &#x27;pH&#x27;]].to_numpy()target = wine[&#x27;class&#x27;].to_numpy()# 훈련데이터, 테스트 데이터 분리train_input, test_input, train_target, test_target = train_test_split( data, target, test_size = 0.2, random_state = 42)# 모델링rf = RandomForestClassifier(n_jobs=-1, random_state = 42)# 모형 평가scores = cross_validate(rf, train_input, train_target, return_train_score = True, n_jobs =-1)print(np.mean(scores[&#x27;train_score&#x27;]), np.mean(scores[&#x27;test_score&#x27;]))# 특성 중요rf.fit(train_input, train_target)# print(rf.feature_importances_)# OOB rf = RandomForestClassifier(oob_score = True, n_jobs = -1, random_state = 42)rf.fit(train_input, train_target)# print(rf.oob_score_) 0.9973541965122431 0.8905151032797809 RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=42) 그레이디언트 부스팅 경사하강법의 원리를 이용함. T1 ~TN 증가하면서 오차를 보정해주며 정확성을 높임 랜덤포레스트와의 차이점 랜덤포레스트는 각 나무간 상호 연관성 없음 부스팅은 각 나무간 상호 연관성 있음 단점 속도가 너무 느려요 대안 XGBoost,LightGBM 1234from sklearn.ensemble import GradientBoostingClassifiergb = GradientBoostingClassifier(random_state=42)scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)print(np.mean(scores[&#x27;train_score&#x27;]), np.mean(scores[&#x27;test_score&#x27;])) 123gb = GradientBoostingClassifier(n_estimators= 500, learning_rate = 0.2, random_state=42)scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)print(np.mean(scores[&#x27;train_score&#x27;]), np.mean(scores[&#x27;test_score&#x27;])) 특성 중요도 12gb.fit(train_input, train_target)# print(gb.feature_importances) GradientBoostingClassifier(learning_rate=0.2, n_estimators=500, random_state=42) 주성분 분석주성분 분석 이론적으로는 어려움 좌표계 공간 개념 직교 + 회전 공분산 등(통계 관련 내용) Feature Engineering 기법 StandardScaler() 현 ML의 문제점 컬럼의 갯수 매우 많음 차원축소 특성이 많으면 훈련 데이터에 쉽게 과대적합 된다. 특성을 줄여서 학습 모델의 성능을 향상시킨다. 대표적인 방법론 중 하나가 PCA, EFA PCA vs EFA EFA(탐색적 요인 분석), Factor Analysis 예) 국어, 수학, 과학, 영어 예) 국어 40, 수학 100, 과학 100, 영어 30 &#x2F; 귀 학생은 언어영역은 수준이 낮은편이나 수리영역은 매우 수준이 높습니다. 예) 범주형 &amp; 수치 데이터 셋 PCA(주성분 분석) 장비1, 장비2,장비3,장비4, … PC1, PC2, PC3, …PCN 원래 가지고 있던 정보를 알 수 없음.(정보 손실) 범주형 데이터셋에는 사용 안됨 무조건 수치형 데이터에서만 사용 PCA 실행 전, 반드시 표준화 처리(스케일링 실행) p.320 1!wget https://bit.ly/fruits_300_data -O fruits_300.npy --2022-07-05 04:55:29-- https://bit.ly/fruits_300_data Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10 Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected. HTTP request sent, awaiting response... 301 Moved Permanently Location: https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy [following] --2022-07-05 04:55:29-- https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy Resolving github.com (github.com)... 140.82.112.3 Connecting to github.com (github.com)|140.82.112.3|:443... connected. HTTP request sent, awaiting response... 302 Found Location: https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy [following] --2022-07-05 04:55:29-- https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 3000128 (2.9M) [application/octet-stream] Saving to: ‘fruits_300.npy’ fruits_300.npy 100%[===================&gt;] 2.86M --.-KB/s in 0.07s 2022-07-05 04:55:29 (43.0 MB/s) - ‘fruits_300.npy’ saved [3000128/3000128] 123456import numpy as npfruits = np.load(&#x27;/content/fruits_300.npy&#x27;)fruits_2d = fruits.reshape(-1, 100 * 100)# 300개 행, 10000개의 열fruits_2d.shape (300, 10000) PCA 123from sklearn.decomposition import PCApca = PCA(n_components=50)pca.fit(fruits_2d) PCA(n_components=50) 1print(pca.components_.shape) 12345678910111213141516import matplotlib.pyplot as pltdef draw_fruits(arr, ratio=1): n = len(arr) # n은 샘플 개수입니다 # 한 줄에 10개씩 이미지를 그립니다. 샘플 개수를 10으로 나누어 전체 행 개수를 계산합니다. rows = int(np.ceil(n/10)) # 행이 1개 이면 열 개수는 샘플 개수입니다. 그렇지 않으면 10개입니다. cols = n if rows &lt; 2 else 10 fig, axs = plt.subplots(rows, cols, figsize=(cols*ratio, rows*ratio), squeeze=False) for i in range(rows): for j in range(cols): if i*10 + j &lt; n: # n 개까지만 그립니다. axs[i, j].imshow(arr[i*10 + j], cmap=&#x27;gray_r&#x27;) axs[i, j].axis(&#x27;off&#x27;) plt.show() 1draw_fruits(pca.components_.reshape(-1, 100, 100)) 123# 머신러닝에서 컬럼의 갯수를 10000개에서 50개로 줄임fruits_pca = pca.transform(fruits_2d)print(fruits_pca.shape) (300, 50) 훈련 데이터, 테스트 데이터 분리 설명된 분산 주성분이 원본 데이터의 분산을 얼마나 잘나타내는지 기록한 값 123# 92%# 원본 이미지 압축print(np.sum(pca.explained_variance_ratio_)) 0.9215810663847064 12plt.plot(pca.explained_variance_ratio_)plt.show() 1print(np.sum(pca.explained_variance_ratio_[:])) 0.9215810663847064","categories":[],"tags":[]},{"title":"Python 기초문법","slug":"day_0704","date":"2022-07-04T00:00:00.000Z","updated":"2022-07-04T08:18:27.888Z","comments":true,"path":"2022/07/04/day_0704/","link":"","permalink":"https://park128.github.io/2022/07/04/day_0704/","excerpt":"","text":"확률적 경사 하강법 점진적 학습 (step, 보폭) 학습률 XGBoost, LightGBM, 딥러닝(이미지 분류, 자연어 처리, 옵티마이저) 신경망 이미지 데이터, 자연어 자율주행 하루 데이터 1TB –&gt; 학습 한꺼번에 다 모델을 학습 어려움 샘플링, 배치, 에포크, 오차(&#x3D;손실&#x3D;loss)가 가장 작은 지점을 찾아야 함. 결론적으로, 확률적 경사 하강법 손실함수 로지스틱 손실 함수 123import pandas as pd fish = pd.read_csv(&quot;https://bit.ly/fish_csv_data&quot;)fish.info() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 159 entries, 0 to 158 Data columns (total 6 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Species 159 non-null object 1 Weight 159 non-null float64 2 Length 159 non-null float64 3 Diagonal 159 non-null float64 4 Height 159 non-null float64 5 Width 159 non-null float64 dtypes: float64(5), object(1) memory usage: 7.6+ KB 입력 데이터와 타깃 데이터 분리 1234fish_input = fish[[&#x27;Weight&#x27;, &#x27;Length&#x27;, &#x27;Diagonal&#x27;, &#x27;Height&#x27;, &#x27;Width&#x27;]].to_numpy()fish_target = fish[&#x27;Species&#x27;].to_numpy()fish_input.shape, fish_target.shape ((159, 5), (159,)) 훈련 세트와 테스트 데이터 분리 12345from sklearn.model_selection import train_test_split train_input, test_input, train_target, test_target = train_test_split( # input, target, 옵션... fish_input, fish_target, random_state=42) 훈련 세트와 테스트 세트의 특성 표준화 무게, 길이, 대각선 길이, 높이, 너비 표준화 처리 진행 12345678from sklearn.preprocessing import StandardScalerss = StandardScaler()ss.fit(train_input)train_scaled = ss.transform(train_input)test_scaled = ss.transform(test_input)# train_scaled[:5] 모델링 확률적 경사 하강법 123456from sklearn.linear_model import SGDClassifier sc = SGDClassifier(loss = &#x27;log&#x27;, max_iter = 10, random_state=42)sc.fit(train_scaled, train_target)print(sc.score(train_scaled, train_target))print(sc.score(test_scaled, test_target)) 0.773109243697479 0.775 /usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit. ConvergenceWarning, partial_fit() 메서드 사용하면 추가 학습. 123sc.partial_fit(train_scaled, train_target) print(sc.score(train_scaled, train_target))print(sc.score(test_scaled, test_target)) 0.8151260504201681 0.85 에포크와 과대&#x2F;과소적합 에포크 숫자가 적으면 –&gt; 덜 학습 early_stopping 에포크 숫자를 1000, 손실 10, 9, 8, , 3 3에 도달한 시점이 150 1234567891011121314import numpy as np sc = SGDClassifier(loss=&#x27;log&#x27;, random_state = 42)train_score = []test_score = []classes = np.unique(train_target)# 300번 에포크 훈련을 반복# 훈련 할 때마다, train_score, test_score 추가를 한다. for _ in range(0, 300): sc.partial_fit(train_scaled, train_target, classes = classes) train_score.append(sc.score(train_scaled, train_target)) test_score.append(sc.score(test_scaled, test_target)) 시각화 12345import matplotlib.pyplot as plt plt.plot(train_score)plt.plot(test_score)plt.legend([&quot;train&quot;, &quot;test&quot;])plt.show() 결정트리 wine 데이터 가져오기 123import pandas as pd wine = pd.read_csv(&#x27;https://bit.ly/wine_csv_data&#x27;)print(wine.head()) alcohol sugar pH class 0 9.4 1.9 3.51 0.0 1 9.8 2.6 3.20 0.0 2 9.8 2.3 3.26 0.0 3 9.8 1.9 3.16 0.0 4 9.4 1.9 3.51 0.0 데이터 가공하기 12data = wine[[&#x27;alcohol&#x27;, &#x27;sugar&#x27;, &#x27;pH&#x27;]].to_numpy()target = wine[&#x27;class&#x27;].to_numpy() 1wine[&#x27;class&#x27;].value_counts() 1.0 4898 0.0 1599 Name: class, dtype: int64 훈련데이터 분리 1234567from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( data, target, test_size = 0.2, random_state=42)train_input.shape, test_input.shape, train_target.shape, test_target.shape ((5197, 3), (1300, 3), (5197,), (1300,)) 표준화 처리 123456from sklearn.preprocessing import StandardScalerss = StandardScaler()ss.fit(train_input)train_scaled = ss.transform(train_input)test_scaled = ss.transform(test_input) 모델 만들기 12345678910111213from sklearn.tree import DecisionTreeClassifierimport matplotlib.pyplot as plt from sklearn.tree import plot_tree # criterion&#123;“gini”, “entropy”, “log_loss”&#125;, default=”gini”dt = DecisionTreeClassifier(criterion = &#x27;entropy&#x27;, max_depth = 8, random_state=42)dt.fit(train_scaled, train_target)print(dt.score(train_scaled, train_target))print(dt.score(test_scaled, test_target))plt.figure(figsize=(10, 7))plot_tree(dt)plt.show() 0.89532422551472 0.8569230769230769 1234567891011# criterion&#123;“gini”, “entropy”, “log_loss”&#125;, default=”gini”dt = DecisionTreeClassifier(criterion = &#x27;entropy&#x27;, max_depth = 1, random_state=42)dt.fit(train_scaled, train_target)print(dt.score(train_scaled, train_target))print(dt.score(test_scaled, test_target))plt.figure(figsize=(10, 7))plot_tree(dt, max_depth = 4, filled=True, feature_names = [&#x27;alcohol&#x27;, &#x27;sugar&#x27;, &#x27;pH&#x27;])plt.show() 0.7579372715027901 0.7376923076923076 훈련 정확도는 99.6% 테스트 정확도는 85.9%–&gt; 과대적합이 일어남 노드란 무엇인가? 0이면 레드 와인 : 1이면 화이트 와인 : 4898 123456plt.figure(figsize=(10, 7))plot_tree(dt, max_depth = 1, filled=True, feature_names = [&#x27;alcohol&#x27;, &#x27;sugar&#x27;, &#x27;pH&#x27;])plt.show() 불순도 한 범주 안에서 서로 다른 데이터가 얼마나 섞여 있는 나타냄 흰색과 검은색이 각각 50개 섞여 있다. 불순도 최대 - 0.5 흰색과 검은색이 완전 100% 분리가 됨 흰색 노드 불순도 최소 - 0 검은색 노드 불순도 최소 - 0 엔드로피(Entropy) 불확실한 정도를 의미함. 0 ~ 1 사이 흰색과 검은색이 각각 50개 섞여 있다. 엔트로피 최대 - 1 흰색과 검은색이 완전 100% 분리가 됨 흰색 노드 엔트로피 최소 - 0 검은색 노드 엔트로피 최소 - 0 특성 중요도 어떤 특성이 결정 트리 모델에 영향을 주었는가? 1print(dt.feature_importances_) [0. 1. 0.] 현업에서의 적용 현업에서 DecisionTreeClassifier (1970년대) 랜덤포레스트, XGBooost 하이퍼파라미터 매우 많음 검증 세트 훈련세트와 테스트세트 훈련 : 교과서 공부하는 것 훈련세트, 모의평가 검증 : 강남대성 모의고사 문제지 테스트 : 6월 &#x2F; 9월 실전 : 수능 1234567891011121314151617import pandas as pd from sklearn.model_selection import train_test_splitwine = pd.read_csv(&#x27;https://bit.ly/wine_csv_data&#x27;)# print(wine.head())data = wine[[&#x27;alcohol&#x27;, &#x27;sugar&#x27;, &#x27;pH&#x27;]].to_numpy()target = wine[&#x27;class&#x27;].to_numpy()# 훈련 80%# 테스트 20% train_input, test_input, train_target, test_target = train_test_split( data, target, test_size = 0.2, random_state=42)train_input.shape, test_input.shape, train_target.shape, test_target.shape ((5197, 3), (1300, 3), (5197,), (1300,)) 1234567# 훈련 80%# 검증 20%sub_input, val_input, sub_target, val_target = train_test_split( train_input, train_target, test_size = 0.2, random_state=42)sub_input.shape, val_input.shape, sub_target.shape, val_target.shape ((4157, 3), (1040, 3), (4157,), (1040,)) 훈련데이터 : sub_input, sub_target 검증데이터 : val_input, val_target 테스트데이터 : test_input, test_target 모형 만들기 123456from sklearn.tree import DecisionTreeClassifierdt = DecisionTreeClassifier(random_state=42)dt.fit(sub_input, sub_target)print(&quot;훈련 성과 : &quot;, dt.score(sub_input, sub_target))print(&quot;검증 성과 : &quot;, dt.score(val_input, val_target))print(&quot;마지막 최종 : &quot;, dt.score(test_input, test_target)) 훈련 성과 : 0.9971133028626413 검증 성과 : 0.864423076923077 마지막 최종 : 0.8569230769230769 훈련 : 87% 검증 : 86% 최종 : 55% 교차 검증 데이터 셋을 반복 분할 For loop 샘플링 편향적일 수 있음 교차검증을 한다고 해서, 정확도가 무조건 올라간다!? (X) 모형을 안정적으로 만들어 준다 과대적합 방지 123456789import numpy as np from sklearn.model_selection import KFolddf = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])# 데이터를 K 폴드로 나눈다. folds = KFold(n_splits=5, shuffle = True)for train_idx, valid_idx in folds.split(df): print(f&#x27;훈련 데이터 : &#123;df[train_idx]&#125;, 검증 데이터 : &#123;df[valid_idx]&#125;&#x27;) 훈련 데이터 : [ 1 2 3 4 5 7 9 10], 검증 데이터 : [6 8] 훈련 데이터 : [ 1 2 3 5 6 8 9 10], 검증 데이터 : [4 7] 훈련 데이터 : [ 1 4 5 6 7 8 9 10], 검증 데이터 : [2 3] 훈련 데이터 : [1 2 3 4 5 6 7 8], 검증 데이터 : [ 9 10] 훈련 데이터 : [ 2 3 4 6 7 8 9 10], 검증 데이터 : [1 5] 교차 검증 함수 1234from sklearn.model_selection import cross_validatescores = cross_validate(dt, train_input, train_target)print(scores)print(&quot;평균 : &quot;, np.mean(scores[&#x27;test_score&#x27;])) &#123;&#39;fit_time&#39;: array([0.00848246, 0.00733709, 0.00798798, 0.00785208, 0.00716829]), &#39;score_time&#39;: array([0.00093985, 0.00078893, 0.00088668, 0.0008297 , 0.00073981]), &#39;test_score&#39;: array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])&#125; 평균 : 0.855300214703487 StratifiedKFold 사용 1234from sklearn.model_selection import StratifiedKFold scores = cross_validate(dt, train_input, train_target, cv = StratifiedKFold())print(scores)print(&quot;평균 : &quot;, np.mean(scores[&#x27;test_score&#x27;])) &#123;&#39;fit_time&#39;: array([0.00848508, 0.00715542, 0.00766325, 0.00738764, 0.00697041]), &#39;score_time&#39;: array([0.00083804, 0.00075769, 0.00085258, 0.00069857, 0.00066876]), &#39;test_score&#39;: array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])&#125; 평균 : 0.855300214703487 10 폴드 교차검증을 수행 12345from sklearn.model_selection import StratifiedKFold splitter = StratifiedKFold(n_splits = 10, shuffle = True, random_state=42)scores = cross_validate(dt, train_input, train_target, cv = splitter)print(scores)print(&quot;평균 : &quot;, np.mean(scores[&#x27;test_score&#x27;])) &#123;&#39;fit_time&#39;: array([0.01321006, 0.00938487, 0.00905538, 0.0082438 , 0.00809932, 0.01311088, 0.00815201, 0.00798512, 0.00820947, 0.00827479]), &#39;score_time&#39;: array([0.00104856, 0.00078392, 0.0007627 , 0.00069618, 0.00068617, 0.00076795, 0.00069237, 0.00065351, 0.00070119, 0.00103307]), &#39;test_score&#39;: array([0.83461538, 0.87884615, 0.85384615, 0.85384615, 0.84615385, 0.87307692, 0.85961538, 0.85549133, 0.85163776, 0.86705202])&#125; 평균 : 0.8574181117533719 하이퍼파라미터 튜닝 그리드 서치 사람이 수동적으로 입력 max_depth : [1, 3, 7] 랜덤 서치 사람이 범위만 지정 max_depth : 1 ~ 10 &#x2F; by random 베이지안 옵티마이제이션 사람의 개입 없이 하이퍼파라미터 튜닝을 자동으로 수행하는 기술을 AutoML이라고 함. 예) PyCaret 각 모델마다 적게는 1-2개에서, 많게는 5-6개의 매개변수를 제공한다. XGBoost 100개…!? 하이퍼파라미터와 동시에 교차검증을 수행. 미친짓!? 교차검증 5번교차검증 1번 돌 때, Max Depth 3번 적용 총 결괏값 3 x 5 x 2 나옴 Max Depth &#x3D; 1, 3, 7 Criterion &#x3D; gini, entropy 123456789from sklearn.model_selection import GridSearchCVparams = &#123; &#x27;criterion&#x27; : [&#x27;gini&#x27;, &#x27;entropy&#x27;], &#x27;max_depth&#x27; : [1, 3, 7], &#x27;min_impurity_decrease&#x27; : [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]&#125;gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs = -1)gs.fit(train_input, train_target) GridSearchCV(estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1, param_grid=&#123;&#39;criterion&#39;: [&#39;gini&#39;, &#39;entropy&#39;], &#39;max_depth&#39;: [1, 3, 7], &#39;min_impurity_decrease&#39;: [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]&#125;) 12print(&quot;best :&quot; , gs.best_estimator_)dt = gs.best_estimator_ best : DecisionTreeClassifier(max_depth=7, min_impurity_decrease=0.0005, random_state=42)","categories":[],"tags":[]},{"title":"Python 기초문법","slug":"day_0630","date":"2022-06-30T00:00:00.000Z","updated":"2022-06-30T08:31:06.969Z","comments":true,"path":"2022/06/30/day_0630/","link":"","permalink":"https://park128.github.io/2022/06/30/day_0630/","excerpt":"","text":"파이썬 주요 라이브러리 Machine Learning 정형데이터 사이킷런 (Scikit-Learn) Deep Learning 비정형데이터 Tensorflow(구글) vs Pytorch(페이스북) 혼공머 : Tensorflow 실제 상용서비스 - Tensorflow vs R&amp;D - Pytorch 생선분류 p.45 도미, 곤들매기, 농어, 등등 이 생선들을 프로그램으로 분류한다. 30cm 도미라고 알려줘라 123fish_length = 31if fish_length &gt;= 30: print(&quot;도미&quot;) 도미 p.47 도미데이터 데이터 수집12345# 도미의 길이bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0]# 도미의 무게bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0] 데이터 가공 여기서는 생략 데이터 시각화 여러 인사이트 확인 위해 시각화, 통계 수치 계산 탐색적 자료 분석(EDA : Exploratory Data Analysis) 얘는 참고만 한다. 123456import matplotlib.pyplot as pltplt.scatter(bream_length, bream_weight)plt.xlabel(&#x27;length&#x27;)plt.ylabel(&#x27;weight&#x27;)plt.show() 파이썬 시각화는 객체지향으로 한다. 이유 : 좀 더 이쁘고, 아름답게 다듬으려면… 캐글 시각화, 참고할 때, 아래와 같이 하는 분들이 많음 1234567import matplotlib.pyplot as pltfig, ax = plt.subplots()ax.scatter(bream_length, bream_weight)ax.set_xlabel(&#x27;length&#x27;)ax.set_ylabel(&#x27;weight&#x27;)plt.show() 빙어 데이터 준비하기 12smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] 시각화 p.50 시각화 123456fig, ax = plt.subplots()ax.scatter(bream_length, bream_weight)ax.scatter(smelt_length, smelt_weight)ax.set_xlabel(&#x27;length&#x27;)ax.set_ylabel(&#x27;weight&#x27;)plt.show() 두개의 리스트 합치기 12length = bream_length + smelt_length weight = bream_weight + smelt_weight 2차원 리스트로 만든다. 12fish_data = [[l, w] for l, w in zip(length, weight)]fish_data[0:5] [[25.4, 242.0], [26.3, 290.0], [26.5, 340.0], [29.0, 363.0], [29.0, 430.0]] 라벨링을 해준다 &#x3D; 지도 해준다 &#x3D; 지도학습 12fish_target = [1] * 35 + [0] * 14print(fish_target) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 모델링12345678from sklearn.neighbors import KNeighborsClassifier# 클래스 인스턴스화kn = KNeighborsClassifier()# 모형 학습# 독립변수, 종속변수kn.fit(fish_data, fish_target) KNeighborsClassifier() 12# 예측 정확도kn.score(fish_data, fish_target) 1.0 실제 예측을 해보자 새로운 물고기 도착했습니다. 길이 : 30, 몸무게 : 600 1234567891011ac_length = int(input(&quot;물고기 길이를 입력하세요...&quot;))ac_weight = int(input(&quot;물고기 무게를 입력하세요...&quot;))preds = int(kn.predict([[ac_length, ac_weight]]))print(preds)if preds == 1: print(&quot;도미&quot;)else: print(&quot;빙어&quot;) 물고기 길이를 입력하세요...20 물고기 무게를 입력하세요...20 0 빙어 새로운 모델 제안 Default : 정확도 100% 제안 : 정확도 71% —&gt; 실험 단계 123def add(a = 1, b = 0): return a + b add() 1 하이퍼 파라미터 세팅 n_neighbors &#x3D; 49 default : 100% 머신러닝 알고리즘 두개의 흐름 선형 모델 : 선형회귀, 로지스틱 회귀,서포트 벡터 머신 의사결정트리 모델 : 1975년 의사결정트리 모델, KNN, 랜덤포레스트 부스팅계열 : LightGBM(2017), XGBoost(2016) 선형회귀, 로지스틱회귀, 랜덤포레스트, LightGBM(&#x3D;XGBoost) 123kn49 = KNeighborsClassifier(n_neighbors=49)kn49.fit(fish_data, fish_target)kn49.score(fish_data, fish_target) 0.7142857142857143 훈련 세트와 테스트 세트12345678fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] 2차원 파이썬 리스트 라벨링 1234fish_data = [[l, w] for l, w in zip(fish_length, fish_weight)]fish_target = [1] * 35 + [0] * 14print(fish_target[0:40:5])print(fish_data[0:40:5]) [1, 1, 1, 1, 1, 1, 1, 0] [[25.4, 242.0], [29.7, 450.0], [31.0, 475.0], [32.0, 600.0], [34.0, 575.0], [35.0, 725.0], [38.5, 920.0], [9.8, 6.7]] Sample 도미 35마리, 빙어 14마리 49개의 샘플 존재 처음 35개를 훈련 &#x2F; 나머지 14개를 테스트 12345678910111213141516from sklearn.neighbors import KNeighborsClassifier# 클래스 인스턴스화kn = KNeighborsClassifier()# 훈련 세트로 0:34 인덱스 활용train_input = fish_data[:35]train_target = fish_target[:35]# 테스 세트로 35:마지막 인덱스 활용test_input = fish_data[35:]test_target = fish_target[35:]# 모형 학습kn = kn.fit(train_input, train_target)print(kn.score(test_input, test_target)) 0.0 샘플링 편향 훈련 세트와 테스트 세트가 골고루 섞이지 않음 샘플링 작업123456import numpy as np input_arr = np.array(fish_data)target_arr = np.array(fish_target)print(input_arr[0:49:7])print(input_arr.shape, target_arr.shape) [[ 25.4 242. ] [ 30. 390. ] [ 32. 600. ] [ 34. 685. ] [ 36. 850. ] [ 9.8 6.7] [ 11.8 9.9]] (49, 2) (49,) 12345# random으로 무작위 배열을 만들거나 설정... np.random.seed(42)index = np.arange(49)np.random.shuffle(index)print(index) [13 45 47 44 17 27 26 25 31 19 12 4 34 8 3 6 40 41 46 15 9 16 24 33 30 0 43 32 5 29 11 36 1 21 2 37 35 23 39 10 22 18 48 20 7 42 14 28 38] 1print(index) [13 45 47 44 17 27 26 25 31 19 12 4 34 8 3 6 40 41 46 15 9 16 24 33 30 0 43 32 5 29 11 36 1 21 2 37 35 23 39 10 22 18 48 20 7 42 14 28 38] 교재 77p 12345train_input = input_arr[index[:35]]train_target = target_arr[index[:35]]test_input = input_arr[index[35:]]test_target = target_arr[index[35:]] 시각화1train_input[:1] array([[ 32., 340.]]) 12train_input[:, 0] # 길이 리스트 array([32. , 12.4, 14.3, 12.2, 33. , 36. , 35. , 35. , 38.5, 33.5, 31.5, 29. , 41. , 30. , 29. , 29.7, 11.3, 11.8, 13. , 32. , 30.7, 33. , 35. , 41. , 38.5, 25.4, 12. , 39.5, 29.7, 37. , 31. , 10.5, 26.3, 34. , 26.5]) 1234567import matplotlib.pyplot as plt fig, ax = plt.subplots()ax.scatter(train_input[:, 0], train_input[:, 1])ax.scatter(test_input[:, 0], test_input[:, 1])ax.set_xlabel(&quot;length&quot;)ax.set_ylabel(&quot;weight&quot;)plt.show() 두번째 머신러닝 프로그램12kn.fit(train_input, train_target)kn.score(test_input, test_target) 1.0 1kn.predict(test_input) # 예측 데이터 array([0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0]) 1test_target # 실제 데이터 array([0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0]) 데이터 전처리 머신러닝 시, 데이터 전처리 결측치 처리, 이상치 처리 데이터 불러오기12345678fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] 12# column_stack() 활용np.column_stack(([1, 2, 3], [4, 5, 6])) array([[1, 4], [2, 5], [3, 6]]) 독립변수 12fish_data = np.column_stack((fish_length, fish_weight))print(fish_data[:5]) [[ 25.4 242. ] [ 26.3 290. ] [ 26.5 340. ] [ 29. 363. ] [ 29. 430. ]] 종속변수 &#x3D; Y &#x3D; 타깃 데이터 &#x3D; Target 12fish_target = np.concatenate((np.ones(35), np.zeros(14)))print(fish_target) [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] scikit-learn 훈련세트와 테스트 세트 나누기1234567from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( # 독립변수, 종속변수 fish_data, fish_target, random_state = 42)train_input.shape, test_input.shape, train_target.shape, test_target.shape ((36, 2), (13, 2), (36,), (13,)) p.92 도미와 빙어가 잘 섞여 있냐? 1print(test_target) [1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 35(도미) :14 (빙어) 2.5 : 1 테스트 셋 (비율) 3.3 : 1 층화샘플링 기초 통계, 설문조사 비율 여론조사 남성 속옷을 구매하는 비율 (남자 9, 여자 1) 신제품 (남자 5, 여자 5) 123456train_input, test_input, train_target, test_target = train_test_split( # 독립변수, 종속변수 fish_data, fish_target, stratify=fish_target, random_state = 42)train_input.shape, test_input.shape, train_target.shape, test_target.shape ((36, 2), (13, 2), (36,), (13,)) 1print(test_target) [0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.] 테스트 세트의 비율이 2.25:1 수상한 도미 한 마리- 1234from sklearn.neighbors import KNeighborsClassifierkn = KNeighborsClassifier()kn.fit(train_input, train_target)kn.score(test_input, test_target) 1.0 도미 사이즈 20cm 이상 &#x3D; 1 빙어 사이즈 10cm 이하 &#x3D; 0 1print(kn.predict([[25, 150]])) [0.] 123456import matplotlib.pyplot as plt fig, ax = plt.subplots()ax.scatter(train_input[:, 0], train_input[:, 1])ax.scatter(25, 150, marker = &#x27;^&#x27;)plt.show() 알고리즘 문제 1234567distances, indexes = kn.kneighbors([[25, 150]])plt.scatter(train_input[:,0], train_input[:,1])plt.scatter(25, 150, marker=&#x27;^&#x27;)plt.scatter(train_input[indexes,0], train_input[indexes,1], marker=&#x27;D&#x27;)plt.xlabel(&#x27;length&#x27;)plt.ylabel(&#x27;weight&#x27;)plt.show() 1234567plt.scatter(train_input[:,0], train_input[:,1])plt.scatter(25, 150, marker=&#x27;^&#x27;)plt.scatter(train_input[indexes,0], train_input[indexes,1], marker=&#x27;D&#x27;)plt.xlim((0, 1000))plt.xlabel(&#x27;length&#x27;)plt.ylabel(&#x27;weight&#x27;)plt.show() p.98 두 특성(길이와 무게)의 값이 놓인 범위가 매우 다름 두 특성의 스케일이 다름. 스케일이 같도록 통계 처리 필요 Feature Engineering (피처 엔지니어링) 머신러닝 전체 데이터 전처리 (결측치 처리, 이상치 처리) 데이터 분리 (임의 샘플링 &lt; 층화 샘플링) Feature Engineering 표준점수 z 점수 1234mean = np.mean(train_input, axis = 0)std = np.std(train_input, axis=0)print(mean, std) [ 27.29722222 454.09722222] [ 9.98244253 323.29893931] 표준 점수 구하기 1234# 브로드 캐스팅 서로다른 배열을 계산할 때 print(train_input.shape, mean.shape, std.shape)train_scaled = (train_input - mean) / std (36, 2) (2,) (2,) 1train_input[0:5] array([[ 29.7, 500. ], [ 12.2, 12.2], [ 33. , 700. ], [ 11.3, 8.7], [ 39.5, 925. ]]) 1train_scaled[0:5] array([[ 0.24070039, 0.14198246], [-1.51237757, -1.36683783], [ 0.5712808 , 0.76060496], [-1.60253587, -1.37766373], [ 1.22242404, 1.45655528]]) 12345plt.scatter(train_scaled[:,0], train_scaled[:,1])plt.scatter(25, 150, marker=&#x27;^&#x27;)plt.xlabel(&#x27;length&#x27;)plt.ylabel(&#x27;weight&#x27;)plt.show() 123456new = ([25, 150] - mean) / stdplt.scatter(train_scaled[:,0], train_scaled[:,1])plt.scatter(new[0], new[1], marker=&#x27;^&#x27;)plt.xlabel(&#x27;length&#x27;)plt.ylabel(&#x27;weight&#x27;)plt.show() 통계처리 전 : KNN –&gt; 예측이 틀림통계처리 후 : KNN –&gt; 예측이 정확하게 맞음– 통계처리 –&gt; Feature Engineering 모형학습 1kn.fit(train_scaled, train_target) KNeighborsClassifier() 123# kn.score(test_input, test_target)test_scaled = (test_input - mean) / stdkn.score(test_scaled, test_target) 1.0 예측 1print(kn.predict([new])) [1.] 1234567distances, indexes = kn.kneighbors([new])plt.scatter(train_scaled[:,0], train_scaled[:,1])plt.scatter(new[0], new[1], marker=&#x27;^&#x27;)plt.scatter(train_scaled[indexes,0], train_scaled[indexes,1], marker=&#x27;D&#x27;)plt.xlabel(&#x27;length&#x27;)plt.ylabel(&#x27;weight&#x27;)plt.show() K-최근접 이웃 회귀 지도 학습 알고리즘은 크게 분류와 회귀 지도 학습 : 종속변수 존재 분류 : 도미와 빙어 분류 회귀 : 통계 회귀분석 y &#x3D; ax + b &#x2F; 수치 예측 데이터 불러오기12import numpy as npprint(np.__version__) 1.21.6 1234567891011121314151617perch_length = np.array( [8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0, 21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7, 23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5, 27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5, 44.0] )perch_weight = np.array( [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0, 1000.0] ) 1234567import matplotlib.pyplot as pltfig, ax = plt.subplots() # 객체지향의 시작ax.scatter(perch_length, perch_weight)ax.set_xlabel(&#x27;length&#x27;)ax.set_ylabel(&#x27;weight&#x27;)plt.show &lt;function matplotlib.pyplot.show&gt; 1234567from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( perch_length, perch_weight, random_state = 42 )train_input.shape, test_input.shape, train_target, test_target.shapeprint(train_input.ndim) 1 1차원 배열..–&gt; 2차원배열 1234train_input = train_input.reshape(-1,1)test_input = test_input.reshape(-1,1)print(train_input.shape, test_input.shape)print(train_input.ndim) (42, 1) (14, 1) 2 결정계수 정확한 지표 0 ~ 1 사이의 지표 1에 가까울수록, 예측 모형이 잘 맞춘다. 123456789from sklearn.neighbors import KNeighborsRegressorknr = KNeighborsRegressor()# 모형 학습knr.fit(train_input, train_target)# 테스트 세트의 점수를 확인한다.print(knr.score(test_input, test_target)) 0.992809406101064 12345678from sklearn.metrics import mean_absolute_error# 예측 데이터test_prediction = knr.predict(test_input)# 테스트 세트에 대한 평균 절댓값 오차를mae = mean_absolute_error(test_target, test_prediction)print(mae) 19.157142857142862 1test_target[:5] array([ 5.9, 100. , 250. , 130. , 130. ]) 예측이 평균적으로 19g 정도 다르다. 확실한 건 오차가 존재한다. 19g 정도가 의미하는게 뭐냐? 개선 : 17g 개선 : 15g 개선 : 0이 될 때까지 1print(knr.score(train_input, train_target)) 0.9698823289099254 과대적합 vs 과소적합 매우 힘듦. 도망 가고 싶어짐.. 과대적합 : 훈련세트 점수 좋음, 테스트 점수 (매우) 안좋음 과소적합 : 테스트 세트의 점수가 매우 좋음 결론 : 제대로 모형이 훈련이 안된 겁니다. 모형 서비스에 탑재 시킬 수 없음. 12print(&quot;훈련평가:&quot;, knr.score(train_input, train_target))print(&quot;테스트 평가:&quot;, knr.score(test_input, test_target)) 훈련평가: 0.9698823289099254 테스트 평가: 0.992809406101064 모형 123456# 이웃의 개수를 3으로 재 지정knr.n_neighbors = 3# 모형 다시 훈련print(&quot;훈련평가:&quot;, knr.score(train_input, train_target))print(&quot;테스트 평가:&quot;, knr.score(test_input, test_target)) 훈련평가: 0.9804899950518966 테스트 평가: 0.9746459963987609","categories":[],"tags":[]},{"title":"Python 기초문법","slug":"day_0629","date":"2022-06-29T00:00:00.000Z","updated":"2022-06-29T08:22:33.174Z","comments":true,"path":"2022/06/29/day_0629/","link":"","permalink":"https://park128.github.io/2022/06/29/day_0629/","excerpt":"","text":"라이브러리 불러오기1234import pandas as pdimport numpy as npprint(&quot;pandas version:&quot;,pd.__version__)print(&quot;numpy version:&quot;,np.__version__) pandas version: 1.3.5 numpy version: 1.21.6 데이터 불러오기 구글 드라이브에 데이터 존재 12from google.colab import drivedrive.mount(&#x27;/content/drive&#x27;) Mounted at /content/drive 12345DATA_PATH = &#x27;/content/drive/MyDrive/Colab Notebooks/human_ai/Basic/Chapter 3. pandas/data/Lemonade2016.csv&#x27;lemonade = pd.read_csv(DATA_PATH)print(type(lemonade))lemonade.info() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 7 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Date 31 non-null object 1 Location 32 non-null object 2 Lemon 32 non-null int64 3 Orange 32 non-null int64 4 Temperature 32 non-null int64 5 Leaflets 31 non-null float64 6 Price 32 non-null float64 dtypes: float64(2), int64(3), object(2) memory usage: 1.9+ KB 데이터 맛보기 1print(lemonade.head()) # 맨 위부터 보여줌 Date Location Lemon Orange Temperature Leaflets Price 0 7/1/2016 Park 97 67 70 90.0 0.25 1 7/2/2016 Park 98 67 72 90.0 0.25 2 7/3/2016 Park 110 77 71 104.0 0.25 3 7/4/2016 Beach 134 99 76 98.0 0.25 4 7/5/2016 Beach 159 118 78 135.0 0.25 1print(lemonade.tail(10)) # 맨 아래부터 보여줌 Date Location Lemon Orange Temperature Leaflets Price 22 7/22/2016 Park 112 75 80 108.0 0.50 23 7/23/2016 Park 120 82 81 117.0 0.50 24 7/24/2016 Park 121 82 82 117.0 0.50 25 7/25/2016 Park 156 113 84 135.0 0.50 26 7/26/2016 Park 176 129 83 158.0 0.35 27 7/27/2016 Park 104 68 80 99.0 0.35 28 7/28/2016 Park 96 63 82 90.0 0.35 29 7/29/2016 Park 100 66 81 95.0 0.35 30 7/30/2016 Beach 88 57 82 81.0 0.35 31 7/31/2016 Beach 76 47 82 68.0 0.35 기술통계량 보는 함수 descrbe() 1print(lemonade.describe()) Lemon Orange Temperature Leaflets Price count 32.000000 32.000000 32.000000 31.000000 32.000000 mean 116.156250 80.000000 78.968750 108.548387 0.354688 std 25.823357 21.863211 4.067847 20.117718 0.113137 min 71.000000 42.000000 70.000000 68.000000 0.250000 25% 98.000000 66.750000 77.000000 90.000000 0.250000 50% 113.500000 76.500000 80.500000 108.000000 0.350000 75% 131.750000 95.000000 82.000000 124.000000 0.500000 max 176.000000 129.000000 84.000000 158.000000 0.500000 범주형 데이터 빈도수 구하 1print(type(lemonade[&#x27;Location&#x27;])) &lt;class &#39;pandas.core.series.Series&#39;&gt; 1lemonade[&#x27;Location&#x27;].value_counts() Beach 17 Park 15 Name: Location, dtype: int64 행과 열 다루기 Sold(판매량) 컬럼(&#x3D;피처&#x3D;feature)을 추가 12lemonade[&#x27;Sold&#x27;] = 0print(lemonade.head()) Date Location Lemon Orange Temperature Leaflets Price Sold \\ 0 7/1/2016 Park 97 67 70 90.0 0.25 0 1 7/2/2016 Park 98 67 72 90.0 0.25 0 2 7/3/2016 Park 110 77 71 104.0 0.25 0 3 7/4/2016 Beach 134 99 76 98.0 0.25 0 4 7/5/2016 Beach 159 118 78 135.0 0.25 0 Revenue 0 41.00 1 41.25 2 46.75 3 58.25 4 69.25 12lemonade[&#x27;Sold&#x27;] = lemonade[&#x27;Lemon&#x27;] + lemonade[&#x27;Orange&#x27;]print(lemonade.head()) Date Location Lemon Orange Temperature Leaflets Price Sold \\ 0 7/1/2016 Park 97 67 70 90.0 0.25 164 1 7/2/2016 Park 98 67 72 90.0 0.25 165 2 7/3/2016 Park 110 77 71 104.0 0.25 187 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 Revenue 0 41.00 1 41.25 2 46.75 3 58.25 4 69.25 Revenue(매출) &#x3D; 단가 x 판매량 12lemonade[&#x27;Revenue&#x27;] = lemonade[&#x27;Price&#x27;] * lemonade[&#x27;Sold&#x27;]print(lemonade.head()) Date Location Lemon Orange Temperature Leaflets Price Sold \\ 0 7/1/2016 Park 97 67 70 90.0 0.25 164 1 7/2/2016 Park 98 67 72 90.0 0.25 165 2 7/3/2016 Park 110 77 71 104.0 0.25 187 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 Revenue 0 41.00 1 41.25 2 46.75 3 58.25 4 69.25 drop() 함수 사용해서 열 제거 123# 컬럼 제거col_drop = lemonade.drop(&#x27;Sold&#x27;, axis=1)print(col_drop.head()) Date Location Lemon Orange Temperature Leaflets Price Revenue 0 7/1/2016 Park 97 67 70 90.0 0.25 41.00 1 7/2/2016 Park 98 67 72 90.0 0.25 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 46.75 3 7/4/2016 Beach 134 99 76 98.0 0.25 58.25 4 7/5/2016 Beach 159 118 78 135.0 0.25 69.25 123# 행 제거row_drop = lemonade.drop(2, axis =0)print(row_drop.head()) Date Location Lemon Orange Temperature Leaflets Price Sold \\ 0 7/1/2016 Park 97 67 70 90.0 0.25 164 1 7/2/2016 Park 98 67 72 90.0 0.25 165 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 5 7/6/2016 Beach 103 69 82 90.0 0.25 172 Revenue 0 41.00 1 41.25 3 58.25 4 69.25 5 43.00 데이터 인덱싱1print(lemonade[4:7]) Date Location Lemon Orange Temperature Leaflets Price Sold \\ 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 5 7/6/2016 Beach 103 69 82 90.0 0.25 172 6 7/6/2016 Beach 103 69 82 90.0 0.25 172 Revenue 4 69.25 5 43.00 6 43.00 특정 값만 추출 filter로 Beach만 출력하 12# 데이터[데이터 컬럼 == 특정값]lemonade[lemonade[&#x27;Location&#x27;] == &#x27;Beach&#x27;] 1[lemonade[&#x27;Location&#x27;] == &#x27;Beach&#x27;] 1[lemonade[&#x27;Temperature&#x27;] &gt;= 80] 1lemonade[(lemonade[&#x27;Temperature&#x27;] &gt;= 80) &amp; (lemonade[&#x27;Orange&#x27;] &gt;= 100) &amp; (lemonade[&#x27;Location&#x27;] == &quot;Beach&quot;)] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 7 7/7/2016 Beach 143 101 81 135.0 0.25 244 61.0 11 7/11/2016 Beach 162 120 83 135.0 0.25 282 70.5 &lt;svg xmlns&#x3D;”http://www.w3.org/2000/svg&quot; height&#x3D;”24px”viewBox&#x3D;”0 0 24 24” width&#x3D;”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-a7739896-665f-4535-964a-95bdca513e69 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-a7739896-665f-4535-964a-95bdca513e69&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 1lemonade.loc[lemonade[&#x27;Temperature&#x27;] &gt;= 80, [&#x27;Date&#x27; , &#x27;Sold&#x27; ,&#x27;Location&#x27;]] 1lemonade[(lemonade[&#x27;Sold&#x27;] &gt;= 100) &amp; (lemonade[&#x27;Date&#x27;] &gt;=&quot;7/7/2016&quot;) &amp; (lemonade[&#x27;Location&#x27;] == &quot;Beach&quot;)] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 7 7/7/2016 Beach 143 101 81 135.0 0.25 244 61.00 9 7/9/2016 Beach 134 95 80 126.0 0.25 229 57.25 &lt;svg xmlns&#x3D;”http://www.w3.org/2000/svg&quot; height&#x3D;”24px”viewBox&#x3D;”0 0 24 24” width&#x3D;”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-601b8b84-a6d9-46c5-a81e-fc3ea0e90b14 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-601b8b84-a6d9-46c5-a81e-fc3ea0e90b14&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; iloc vs loc 문법상의 차이 확인 1lemonade.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 0 7/1/2016 Park 97 67 70 90.0 0.25 164 41.00 1 7/2/2016 Park 98 67 72 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 187 46.75 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 58.25 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 69.25 &lt;svg xmlns&#x3D;”http://www.w3.org/2000/svg&quot; height&#x3D;”24px”viewBox&#x3D;”0 0 24 24” width&#x3D;”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-1a045e80-309a-4f44-8982-1e7191c9de4c button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-1a045e80-309a-4f44-8982-1e7191c9de4c&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; iloc—-&gt; 숫자만 들어 1print(lemonade.iloc[0:3, 0:2]) Date Location 0 7/1/2016 Park 1 7/2/2016 Park 2 7/3/2016 Park loc : 숫자 (x) 라벨 &#x3D; 글자(숫자, 문자 동시포함) 1print(lemonade.loc[0:2, [&#x27;Date&#x27;, &#x27;Location&#x27;]]) Date Location 0 7/1/2016 Park 1 7/2/2016 Park 2 7/3/2016 Park 데이터 덩령 sort_values() 12#lemonade.head()print(lemonade.sort_values(by=[&#x27;Revenue&#x27;]).head(10)) Date Location Lemon Orange Temperature Leaflets Price Sold \\ 0 7/1/2016 Park 97 67 70 90.0 0.25 164 1 7/2/2016 Park 98 67 72 90.0 0.25 165 6 7/6/2016 Beach 103 69 82 90.0 0.25 172 5 7/6/2016 Beach 103 69 82 90.0 0.25 172 31 7/31/2016 Beach 76 47 82 68.0 0.35 123 13 7/13/2016 Beach 109 75 77 99.0 0.25 184 2 7/3/2016 Park 110 77 71 104.0 0.25 187 30 7/30/2016 Beach 88 57 82 81.0 0.35 145 14 7/14/2016 Beach 122 85 78 113.0 0.25 207 8 NaN Beach 123 86 82 113.0 0.25 209 Revenue 0 41.00 1 41.25 6 43.00 5 43.00 31 43.05 13 46.00 2 46.75 30 50.75 14 51.75 8 52.25 1print(lemonade[[&#x27;Date&#x27;, &#x27;Temperature&#x27;, &#x27;Revenue&#x27;]].sort_values(by=[&#x27;Revenue&#x27;]).head(5)) Date Temperature Revenue 0 7/1/2016 70 41.00 1 7/2/2016 72 41.25 6 7/6/2016 82 43.00 5 7/6/2016 82 43.00 31 7/31/2016 82 43.05 1print(lemonade[[&#x27;Date&#x27;, &#x27;Temperature&#x27;, &#x27;Revenue&#x27;]].sort_values(by=[&#x27;Temperature&#x27;,&#x27;Revenue&#x27;]).head(5)) Date Temperature Revenue 0 7/1/2016 70 41.00 20 7/20/2016 70 56.50 2 7/3/2016 71 46.75 1 7/2/2016 72 41.25 16 7/16/2016 74 65.50 1print(lemonade[[&#x27;Date&#x27;, &#x27;Temperature&#x27;, &#x27;Revenue&#x27;]].sort_values(by=[&#x27;Temperature&#x27;, &#x27;Revenue&#x27;], ascending = [True, False]).head(5)) Date Temperature Revenue 20 7/20/2016 70 56.50 0 7/1/2016 70 41.00 2 7/3/2016 71 46.75 1 7/2/2016 72 41.25 16 7/16/2016 74 65.50 Group by1print(lemonade.head()) Date Location Lemon Orange Temperature Leaflets Price Sold \\ 0 7/1/2016 Park 97 67 70 90.0 0.25 164 1 7/2/2016 Park 98 67 72 90.0 0.25 165 2 7/3/2016 Park 110 77 71 104.0 0.25 187 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 Revenue 0 41.00 1 41.25 2 46.75 3 58.25 4 69.25 1234567df = lemonade.groupby(by=&#x27;Location&#x27;).count()print(df)print(type(df))df[[&#x27;Date&#x27;, &#x27;Lemon&#x27;]]print(df.iloc[0:1, 0:2])print(df.loc[&#x27;Park&#x27;, [&#x27;Date&#x27;, &#x27;Lemon&#x27;]]) 간단한 피벗 테이블 만들기 1lemonade.groupby(&#x27;Location&#x27;)[&#x27;Revenue&#x27;].agg([max, min, sum, np.mean]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; max min sum mean Location Beach 95.5 43.0 1002.8 58.988235 Park 134.5 41.0 1178.2 78.546667 &lt;svg xmlns&#x3D;”http://www.w3.org/2000/svg&quot; height&#x3D;”24px”viewBox&#x3D;”0 0 24 24” width&#x3D;”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-94877c17-9807-408f-b141-22c8c8b20eaf button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-94877c17-9807-408f-b141-22c8c8b20eaf&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 1lemonade.groupby(&#x27;Location&#x27;)[[&#x27;Revenue&#x27;, &#x27;Sold&#x27;, &#x27;Temperature&#x27;]].agg([max, min, sum, np.mean]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead tr th &#123; text-align: left; &#125; .dataframe thead tr:last-of-type th &#123; text-align: right; &#125; Revenue Sold Temperature max min sum mean max min sum mean max min sum mean Location Beach 95.5 43.0 1002.8 58.988235 282 123 3422 201.294118 84 74 1355 79.705882 Park 134.5 41.0 1178.2 78.546667 305 113 2855 190.333333 84 70 1172 78.133333 &lt;svg xmlns&#x3D;”http://www.w3.org/2000/svg&quot; height&#x3D;”24px”viewBox&#x3D;”0 0 24 24” width&#x3D;”24px”&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-e286c54d-7c89-4fb5-8187-d53827639975 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-e286c54d-7c89-4fb5-8187-d53827639975&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 1","categories":[],"tags":[]},{"title":"","slug":"day_0628","date":"2022-06-28T07:44:59.334Z","updated":"2022-06-28T07:44:29.339Z","comments":true,"path":"2022/06/28/day_0628/","link":"","permalink":"https://park128.github.io/2022/06/28/day_0628/","excerpt":"","text":"반복문 복습 for loop and while loop 123for i in range(3): print(&quot;Hello World&quot;) print(&quot;안녕하세요&quot;) Hello World 안녕하세요 Hello World 안녕하세요 Hello World 안녕하세요 123456# &quot;K&quot; in &quot;Kaggle&quot;if &quot;K&quot; == &quot;a&quot;: print(&quot;출력이 되나요?&quot;)else: print(&quot;출력이 안된듯&quot;) 출력이 안된듯 123456a = &quot;Kaggle&quot;for i in a: print(i) if i == &quot;a&quot;: break K a 리스트의 값이 존재 전체 총합 구하기 12345678910numbers = [1, 2, 3, 4, 5]sum = 0for num in numbers: print(&quot;numbers: &quot;, num) sum = sum + num print(&quot;total:&quot;, sum)print(&quot;----최종 결괏값----&quot;)print(sum) numbers: 1 total: 1 numbers: 2 total: 3 numbers: 3 total: 6 numbers: 4 total: 10 numbers: 5 total: 15 ----최종 결괏값---- 15 12345678910111213fruits = [&#x27;apple&#x27;, &#x27;kiwi&#x27;, &#x27;mango&#x27;]newlist = []# apple : a가 있나요? 있네요, newlist에 추가하세요. # kiwi : a가 있나요? 없네요. 그럼 넘어가요# mango : a가 있나요? 있네요. newlist에 추가하세요. for fruit in fruits: print(&quot;조건문 밖 : &quot;, fruit) if &quot;a&quot; in fruit: print(&quot;조건문 안쪽 : &quot;, fruit) newlist.append(fruit)print(newlist) 조건문 밖 : apple 조건문 안쪽 : apple 조건문 밖 : kiwi 조건문 밖 : mango 조건문 안쪽 : mango [&#39;apple&#39;, &#39;mango&#39;] While Loopwhile문 : 분석할 때? 거의 쓸일이 없음 123456i = 1while i &lt; 10: # 참일때만 반복문 코드가 돔 # 코드 print(i) i += 1 # 1씩 증감 # i -= 1 # 1씩 감소 1 2 3 4 5 6 7 8 9 사용자 정의 함수 내가 필요에 의해 직접 함수를 작성 123def 함수명(param1, param2): # 코드 return None 1234567def add(a = 0, b = 1): # c = a + b # return c return a + bprint(add(a = 5, b = 4))print(add()) 9 1 사칙연산 사용자 정의 함수 만들기 함수 문서화 키워드 : Docstring 123456789101112131415def subtract(a, b): &quot;&quot;&quot;a, b를 빼는 함수 Parameters: a (int): int형 숫자 a가 입력 b (int): int형 숫자 b가 입력 Returns: int : 반환값 &quot;&quot;&quot; return a-bprint(subtract(a = 5, b = 10))print(subtract.__doc__) -5 a, b를 빼는 함수 Parameters: a (int): int형 숫자 a가 입력 b (int): int형 숫자 b가 입력 Returns: int : 반환값 NumPy 내장 모듈(&#x3D;라이브러리&#x3D;패키지) (X) 별도 라이브러리 설치 필요 12import numpy as npprint(np.__version__) 1.21.6 12345temp = [1, 2, 3]temp_array = np.array(temp) # 리스트에서 배열로 변환print(type(temp))print(type(temp_array)) &lt;class &#39;list&#39;&gt; &lt;class &#39;numpy.ndarray&#39;&gt; 사칙연산12345678910math_score = [90, 80, 100, 60]eng_score = [80, 90, 100, 50]# math_score + eng_scoremath_array = np.array(math_score)eng_array = np.array(eng_score)total = math_array + eng_arrayprint(total)print(type(total)) [170 170 200 110] &lt;class &#39;numpy.ndarray&#39;&gt; 집계함수123print(np.min(total))print(np.max(total))print(np.sum(total)) 110 200 650 차원 확인 배열의 차원 확인 필요 12345# 1차원 배열 생성temp_arr = np.array([1, 2, 3])print(temp_arr.shape)print(temp_arr.ndim)print(temp_arr) (3,) 1 [1 2 3] 12345# 2차원 배열 생성temp_arr = np.array([[1, 2, 3], [4, 5, 6]])print(temp_arr.shape)print(temp_arr.ndim)print(temp_arr) (2, 3) 2 [[1 2 3] [4 5 6]] 12345# 3차원 배열 -&gt; 이미지temp_arr = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])print(temp_arr.shape)print(temp_arr.ndim)print(temp_arr) (2, 2, 3) 3 [[[ 1 2 3] [ 4 5 6]] [[ 7 8 9] [10 11 12]]] 1(255, 255, 3) 배열 생성의 다양한 방법들 모두 0으로 채운다. 12import numpy as np print(np.__version__) 1.21.6 12temp_arr = np.zeros((2, 3))temp_arr array([[0., 0., 0.], [0., 0., 0.]]) 모두 1로 채운다. 12temp_arr = np.ones((2, 3))temp_arr array([[1., 1., 1.], [1., 1., 1.]]) 임의의 상수값으로 채운다. 12temp_arr = np.full((3, 3), 100)temp_arr array([[100, 100, 100], [100, 100, 100], [100, 100, 100]]) 최소, 최대 숫자의 범위를 정해두고, 각 구간별로 값을 생성 12temp_arr = np.linspace(5, 10, 10)temp_arr array([ 5. , 5.55555556, 6.11111111, 6.66666667, 7.22222222, 7.77777778, 8.33333333, 8.88888889, 9.44444444, 10. ]) 반복문 시, 자주 등장하는 배열 12temp_arr = np.arange(1, 11, 1)temp_arr array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) 난수 생성123from numpy import randomx = random.rand()print(x) 0.11621638529248979 123import numpy x = numpy.random.rand()print(x) 0.3315584451465583 랜덤 정수값 추출 12345from numpy import random # x = random.randint(100, size = (5))x = random.randint(100, size = (3, 5))print(x)print(type(x)) [[88 2 19 78 13] [92 80 62 22 96] [66 71 89 62 76]] &lt;class &#39;numpy.ndarray&#39;&gt; 랜덤 배열, 실숫값 추출 1234from numpy import random x = random.rand(2, 5)print(x)print(type(x)) [[0.06336531 0.34486775 0.66923826 0.31566607 0.84566463] [0.61713876 0.67541796 0.65161201 0.04912466 0.45433901]] &lt;class &#39;numpy.ndarray&#39;&gt; NumPy 사칙 연산123import numpy as nparray_01 = np.array([1, 2, 3])array_02 = np.array([10, 20, 30]) 123456789101112131415161718192021# 덧셈newArr = np.add(array_01, array_02)print(newArr)# 뺄셈newArr = np.subtract(array_01, array_02)print(newArr)# 곱셈newArr = np.multiply(array_01, array_02)print(newArr)# 나누기newArr = np.divide(array_01, array_02)print(newArr)# 거듭제곱array_01 = np.array([1, 2, 3])array_02 = np.array([2, 4, 2])newArr = np.power(array_01, array_02)print(newArr) [3 5 5] [-1 -1 1] [2 6 6] [0.5 0.66666667 1.5 ] [ 1 16 9] 소숫점 정렬 소숫점을 정렬하는 다양한 방법 1234567# 소숫점 제거 import numpy as nptemp_arr = np.trunc([-1.23, 1.23])print(temp_arr)temp_arr = np.fix([-1.23, 1.23])print(temp_arr) [-1. 1.] [-1. 1.] 123# 임의의 소숫점 자리에서 반올림temp_arr = np.around([-1.234546123, 1.238791631], 5)print(temp_arr) [-1.23455 1.23879] 123# 소숫점 모두 내림temp_arr = np.floor([-1.234546123, 1.238791631])print(temp_arr) [-2. 1.] 123# 소숫점 모두 올림temp_arr = np.ceil([-1.234546123, 1.238791631])print(temp_arr) [-1. 2.] 조건식 pandas 가공 numpy 조건식 하나의 조건식 (&#x3D; np.where) 다중 조건식 12temp_arr = np.arange(10)temp_arr array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 12# 5보다 작으면 원 값 유지# 5보다 크면 곱하기 10을 해줌 12# np.where(조건식, 참일 때, 거짓일 때)np.where(temp_arr &lt; 5, temp_arr, temp_arr * 10) array([ 0, 1, 2, 3, 4, 50, 60, 70, 80, 90]) 1234567temp_arr = np.arange(10)# temp_arrcond_list = [temp_arr &gt; 5 , temp_arr &lt; 2]choice_list = [temp_arr * 2, temp_arr + 100]# np.select(조건식 리스트, 결괏값 리스트, default = )np.select(cond_list, choice_list, default = temp_arr) array([100, 101, 2, 3, 4, 5, 12, 14, 16, 18]) Reshape 배열의 차원 또는 크기를 바꾼다. 곱셈만 할줄 알면 끝. 1234import numpy as np temp_array = np.ones((3, 4))print(temp_array.shape)print(temp_array) (3, 4) [[1. 1. 1. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.]] 123after_reshape = temp_array.reshape(2, 2, 5)print(after_reshape.shape)print(after_reshape) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-50-d57dd065a075&gt; in &lt;module&gt;() ----&gt; 1 after_reshape = temp_array.reshape(2, 2, 5) 2 print(after_reshape.shape) 3 print(after_reshape) ValueError: cannot reshape array of size 12 into shape (2,2,5) 123after_reshape = temp_array.reshape(7, -1)print(after_reshape.shape)print(after_reshape) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-53-00ad0ee6a004&gt; in &lt;module&gt;() ----&gt; 1 after_reshape = temp_array.reshape(7, -1) 2 print(after_reshape.shape) 3 print(after_reshape) ValueError: cannot reshape array of size 12 into shape (7,newaxis) 브로드 캐스팅pandas 튜토리얼12import pandas as pd print(pd.__version__) 1.3.5 12345678temp_dict = &#123; &#x27;col1&#x27; : [1, 2], &#x27;col2&#x27; : [3, 4]&#125;df = pd.DataFrame(temp_dict)print(df)print(type(df)) col1 col2 0 1 3 1 2 4 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; 구글 드라이브 연동12from google.colab import drive drive.mount(&#x27;/content/drive&#x27;) Mounted at /content/drive 1234567DATA_PATH = &#x27;/content/drive/MyDrive/Colab Notebooks/human_AI/Basic/Chapter 3. pandas/data/&#x27;print(DATA_PATH + &#x27;Lemonade2016.csv&#x27;)lemonade = pd.read_csv(DATA_PATH + &#x27;Lemonade2016.csv&#x27;)# covid_df = pd.read_csv(DATA_PATH + &#x27;owid-covid-data.csv&#x27;)lemonade.info() # str() /content/drive/MyDrive/Colab Notebooks/human_AI/Basic/Chapter 3. pandas/data/Lemonade2016.csv &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 7 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Date 31 non-null object 1 Location 32 non-null object 2 Lemon 32 non-null int64 3 Orange 32 non-null int64 4 Temperature 32 non-null int64 5 Leaflets 31 non-null float64 6 Price 32 non-null float64 dtypes: float64(2), int64(3), object(2) memory usage: 1.9+ KB","categories":[],"tags":[]},{"title":"Python 기초문법","slug":"day_0627","date":"2022-06-27T00:00:00.000Z","updated":"2022-06-28T07:44:01.985Z","comments":true,"path":"2022/06/27/day_0627/","link":"","permalink":"https://park128.github.io/2022/06/27/day_0627/","excerpt":"","text":"Hello World 1print(&quot;Hello World&quot;) Hello World 주석처리 1줄 주석, 여러 줄 주석 처리 여러 줄 주석 처리 함수 또는 클래스를 문서화 할 때 주로 사용 프로젝트 할 때 전체 공정 100 코드 &#x2F; 코드 문서화 &#x2F; 한글작업 문서화 12345678910# print() 함수 사용print(&quot;1줄 주석&quot;)&quot;&quot;&quot;여러 줄 주석쌍따옴표 3개를 입력해주세요앞과 뒤로 &quot;&quot;&quot;print(&quot;여러줄 주석&quot;) 1줄 주석 여러줄 주석 변수 (Scalar) 자료형 Scalar형 Non-Scalar형 수치형 자료형 int, float 123num_int = 1print(num_int)print(type(num_int)) 1 &lt;class &#39;int&#39;&gt; 123num_float = 0.1print(num_float)print(type(num_float)) 0.1 &lt;class &#39;float&#39;&gt; Bool형 True, False R : TRUE, FALSE 123bool_true = Trueprint(bool_true)print(type(bool_true)) True &lt;class &#39;bool&#39;&gt; None 자료형 Null값, 값이 정해지지 않은 자료형 123none_x = Noneprint(none_x)print(type(none_x)) None &lt;class &#39;NoneType&#39;&gt; 사칙연산 정수형 사칙연산, 실수형 사칙연산 결괏값의 자료형 정수형 사칙 연산+, -, *, &#x2F; 123456a = 3b = 2 print(&#x27;a + b = &#x27;, a+b)print(&#x27;a - b = &#x27;, a-b)print(&#x27;a * b = &#x27;, a*b)print(&#x27;a / b = &#x27;, a/b) a + b = 5 a - b = 1 a * b = 6 a / b = 1.5 실수형 사칙 연산123456a = 1.5b = 2.5print(&#x27;a + b = &#x27;, a+b)print(&#x27;a - b = &#x27;, a-b)print(&#x27;a * b = &#x27;, a*b)print(&#x27;a / b = &#x27;, a/b) a + b = 4.0 a - b = -1.0 a * b = 3.75 a / b = 0.6 논리형 연산자 Bool형 True와 False 값으로 정의 조건식 교집합(&#x3D;and), 합집합(&#x3D;or) 1234print(True and True)print(True and False)print(False and True)print(False and False) True False False False 1234print(True or True)print(True or False)print(False or True)print(False or False) True True True False 비교 연산자 비교 연산자는 부등호를 의미한다. 1234print(4 &gt; 3) # 참 = True print(4 &lt; 3) # 거짓 = Falseprint(4 &gt; 3 or 4 &lt; 3) # False True False True 논리형 &amp; 비교 연산자 응용 input() 형변환 데이터 타입을 바꾸는 것 123var = int(input(&quot;숫자를 입력하세요..!&quot;))print(var)print(type(var)) 숫자를 입력하세요..!1 1 &lt;class &#39;int&#39;&gt; 1234num1 = int(input(&quot;첫번째 숫자를 입력하세요..!&quot;))num2 = int(input(&quot;두번째 숫자를 입력하세요..!&quot;))num3 = int(input(&quot;세번째 숫자를 입력하세요..!&quot;))num4 = int(input(&quot;네번째 숫자를 입력하세요..!&quot;)) 첫번째 숫자를 입력하세요..!10 두번째 숫자를 입력하세요..!20 세번째 숫자를 입력하세요..!30 네번째 숫자를 입력하세요..!40 12var1 = num1 &gt;= num2 # Falsevar2 = num3 &lt; num4 # True 1234print(var1 and var2) # True# 1 True# 2 False True String Non Scalar 12345print(&#x27;Hello World&#x27;)print(&quot;Hello World&quot;)print(&quot;&#x27;Hello World&#x27;&quot;)print(&#x27;&quot;Hello World&quot;&#x27;) Hello World Hello World &#39;Hello World&#39; &quot;Hello World&quot; String Operators 문자열 연산자 +, * 가능 123str1 = &quot;Hello &quot;str2 = &quot;World&quot;print(str1 + str2) Hello World 12greet = str1 + str2print(greet * 2) Hello WorldHello World 문자열 인덱싱 인덱싱은 0번째 부터 시작 1234greeting = &quot;Hello Kaggle&quot;i = 7print(greeting[i])print(greeting[7]) a 123greeting = &quot;Hello Kaggle&quot;i = int(input(&quot;숫자를 입력하세요...!&quot;))print(greeting[i]) 숫자를 입력하세요...!7 a 슬라이싱12345678greeting = &quot;Hello Kaggle&quot;# print(greeting[시작인덱스:끝인덱스-1])print(greeting[0:8])print(greeting[:8])print(greeting[6:])print(greeting[0:10:2])print(greeting[0:10:3])print(greeting[0:10:4]) Hello Ka Hello Ka Kaggle HloKg HlKg Hog 12alphabet_letter = &quot;0123456789&quot;print(alphabet_letter[0:5:2]) ace 12greeting = &quot;Hello Kaggle&quot;print(greeting[11]) e 문자열 관련 메서드 split() sort() etc 리스트 []로 표시, [item1, item2, item3] 123456a = [] # 빈 리스트a_func = list() # 빈 리스트 생성b = [1] # 숫자 요소c = [&#x27;apple&#x27;] # 문자 요소d = [1, 2, [&#x27;apple&#x27;], &#x27;apple&#x27;]print(d) [1, 2, [&#39;apple&#39;], &#39;apple&#39;] 리스트 값 수정하기 리스트 값 수정 123a = [0, 1, 2]a[0] = &quot;아무값&quot;print(a) [&#39;아무값&#39;, 1, 2] 리스트 값 추가하기 메서드 사용 123456a = [100, 200, 300]a.append(400)print(a)a.append([500, 600])print(a) [100, 200, 300, 400] [100, 200, 300, 400, [500, 600]] 123456a = [100, 200, 300]a.append(400)print(a)a.extend([400, 500])print(a) [100, 200, 300, 400] [100, 200, 300, 400, 400, 500] insert(인덱스 위치, 값) 123a = [100, 200, 300]a.insert(1, 1000)print(a) [100, 1000, 200, 300] 리스트 값 삭제하기 remove(), del 123456a = [1, 2, 1, 2, 10]a.remove(1)print(a)a.remove(10)print(a) [2, 1, 2, 10] [2, 1, 2] del 123456a = [0, 0, 1, 2, 3, 4]del a[1]print(a)del a[0:2]print(a) [0, 1, 2, 3, 4] [2, 3, 4] pop() 1234567a = [1, 2, 3, 4, 5]rem = a.pop(1)print(a)print(rem)x = a.pop()print(a)print(x) [1, 3, 4, 5] 2 [1, 3, 4] 5 clear() : 리스트 내 모든 값 삭제 index(“값”) : 값의 위치를 불러옴 1234a = [1, 4, 5, 2, 3]b = [&quot;철수&quot;, &quot;영희&quot;, &quot;길동&quot;]print(a.index(4))print(b.index(&quot;길동&quot;)) 1 2 sort : 리스트의 정렬 123456a = [1, 4, 5, 2, 3]a.sort(reverse=True)print(a)# help(list.sort)help(list.index) [5, 4, 3, 2, 1] Help on method_descriptor: index(self, value, start=0, stop=9223372036854775807, /) Return first index of value. Raises ValueError if the value is not present. 튜플 면접질문 : 리스트와 튜플의 차이가 뭐에요? 리스트 : [] 수정, 삭제, 추가 튜플 : () 다 안됨 1234567891011tuple1 = (0)tuple2 = (0, )tuple3 = 0, 1, 2print(type(tuple1))print(type(tuple2))print(type(tuple3))print(tuple1)print(tuple2)print(tuple3) &lt;class &#39;int&#39;&gt; &lt;class &#39;tuple&#39;&gt; &lt;class &#39;tuple&#39;&gt; 0 (0,) (0, 1, 2) 12a = (0, 1, 2, 3, &#x27;a&#x27;)del a[4] --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-58-3c8e6a62588a&gt; in &lt;module&gt;() 1 a = (0, 1, 2, 3, &#39;a&#39;) ----&gt; 2 del a[4] TypeError: &#39;tuple&#39; object doesn&#39;t support item deletion 123a = (0, 1, 2, 3, &#x27;a&#x27;)a[4] = 4print(a) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-61-fdbbdf9f616e&gt; in &lt;module&gt;() 1 a = (0, 1, 2, 3, &#39;a&#39;) ----&gt; 2 a[4] = 4 3 print(a) TypeError: &#39;tuple&#39; object does not support item assignment 튜플(&#x3D;리스트) 연산자 문자열 연산자 +, * 123t1 = [0, 1, 2]t2 = [3, 4, 5]print(t1 + t2) [0, 1, 2, 3, 4, 5] 딕셔너리 Key(키)와 Value(값)으로 구성됨 슬라이싱! &#x3D; (값의 순서가 존재해야 함) 순서라는 개념 자체가 존재 하지 않음 123456789temp_dict = &#123; &#x27;teacher&#x27; : &#x27;evan&#x27;, &#x27;class&#x27; : 15, &#x27;students&#x27; : [&#x27;s1&#x27;, &#x27;s2&#x27;, &#x27;s3&#x27;]&#125;print(temp_dict[&quot;teacher&quot;])print(temp_dict[&#x27;class&#x27;])print(temp_dict[&#x27;students&#x27;]) evan 15 [&#39;s1&#39;, &#39;s2&#39;, &#39;s3&#39;] keys() 값만 출력 1list(temp_dict.keys()) [&#39;teacher&#39;, &#39;class&#39;, &#39;students&#39;] values() 값만 출력 1temp_dict.values() dict_values([&#39;evan&#39;, 15, [&#39;s1&#39;, &#39;s2&#39;, &#39;s3&#39;]]) items() key-value 쌍으로, list와 tuple 형태로 반환 1temp_dict.items() dict_items([(&#39;teacher&#39;, &#39;evan&#39;), (&#39;class&#39;, 15), (&#39;students&#39;, [&#39;s1&#39;, &#39;s2&#39;, &#39;s3&#39;])]) 조건문- 123456789a = int(input(&quot;숫자를 입력하세요..!&quot;))if a &gt; 5: print(&quot;a는 5보다 크다&quot;)elif a &gt; 0: print(&quot;a는 0보다 크다&quot;)elif a &gt; -5: print(&quot;a는 -5보다 크다&quot;)else: print(&quot;a는 매우 작다&quot;) 숫자를 입력하세요..!8 a는 5보다 크다 1234# Hello World 1000000번 출력하세요for idx in range(3): # print(idx+1) print(&quot;Hello World&quot;) Hello World Hello World Hello World for loop if 조건문 사용 문자열, 리스트 등 –&gt; 시퀀스 데이터 1234567a = &quot;Kaggle&quot;# g가 시작하면 반복문을 멈추세요for x in a: print(x) if x == &#x27;g&#x27;: break # print(x) K a g enumerate() 123alphabets = [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;]for index, value in enumerate(alphabets): print(index, value) 0 A 1 B 2 C 리스트 컴프리헨션list comprehension 1&quot;a&quot; in &quot;kiwi&quot; False 123456789fruits = [&#x27;apple&#x27;, &#x27;kiwi&#x27;, &#x27;mango&#x27;]newlists = []# 알파벳 a가 있는 과일만 추출 후, 새로운 리스트에 담기for fruit in fruits: # print(fruit) if &quot;a&quot; in fruit: newlists.append(fruit)print(newlists) [&#39;apple&#39;, &#39;mango&#39;] 123# 리스트 컴프리헨션newlist = [fruit for fruit in fruits if &#x27;a&#x27; in fruit]print(newlist) [&#39;apple&#39;, &#39;mango&#39;]","categories":[],"tags":[]},{"title":"Untitled","slug":"day_0624","date":"2022-06-24T01:00:00.000Z","updated":"2022-06-24T07:09:15.036Z","comments":true,"path":"2022/06/24/day_0624/","link":"","permalink":"https://park128.github.io/2022/06/24/day_0624/","excerpt":"","text":"복습 통계 검정 평균 차이 검정 : 수치 데이터 + 범주 데이터(두 그룹) 중급 이상 : 세 그룹 이상 평균 차이 검정 비율 차이 검정 : 범주 데이터 상관 관계 : 수치 데이터 회귀 통계 검정 사전 준비 분석을 위한 데이터가 적절한지 검정 등분산 검정, 수치 데이터가 정규분포를 이루는가 (정규성 검정) 귀무가설, 대립가설 설정 서울의 평균 임금과 부산의 평균 임금이 차이가 있을 것이다. 선행연구 (논문 찾아서 응용) 테스트 t.test, chisq.test, cor.test p.value p.value &gt; 0.05 –&gt; 귀무가설 지지 p.value &lt; 0.05 –&gt; 대립가설 지지 회귀의 중요성 기초통계 : 특정한 결과에 영향을 주는 요인이 뭐냐? 이걸 찾는 것이 회귀 회귀분석과 종류 1세대 회귀 방법론 : 다항회귀분석, 다중회귀분석, 포아송 회귀분석, etc 2세대 회귀 방법론 : 구조방정식 기무가설 대립가설 존재 귀무가설 : x(&#x3D;독립변수)가 y(&#x3D;종속변수)에 영향을 주지 않는다. 대립가설 : x(&#x3D;독립변수)가 y(&#x3D;종속변수)에 영향을 준다 1m(종속변수 ~ 독립변수, data) p.value 123RA &lt;- lm(data=mtcars, mpg ~ disp)summary(RA) 123456789101112131415161718## ## Call:## lm(formula = mpg ~ disp, data = mtcars)## ## Residuals:## Min 1Q Median 3Q Max ## -4.8922 -2.2022 -0.9631 1.6272 7.2305 ## ## Coefficients:## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 29.599855 1.229720 24.070 &lt; 2e-16 ***## disp -0.041215 0.004712 -8.747 9.38e-10 ***## ---## Signif. codes: 0 &#x27;***&#x27; 0.001 &#x27;**&#x27; 0.01 &#x27;*&#x27; 0.05 &#x27;.&#x27; 0.1 &#x27; &#x27; 1## ## Residual standard error: 3.251 on 30 degrees of freedom## Multiple R-squared: 0.7183, Adjusted R-squared: 0.709 ## F-statistic: 76.51 on 1 and 30 DF, p-value: 9.38e-10 머신러닝, 인공지능 주 목적은 예측 y &#x3D; ax + b 데이터 전처리 하기.분석 파일을 R로 불러온다. 한국행정연구원_사회통합실태조사.2019년 1library(dplyr) 12## ## 다음의 패키지를 부착합니다: &#x27;dplyr&#x27; 123## The following objects are masked from &#x27;package:stats&#x27;:## ## filter, lag 123## The following objects are masked from &#x27;package:base&#x27;:## ## intersect, setdiff, setequal, union 123library(ggplot2)library(foreign)mental &lt;- read.spss(&quot;한국행정연구원_사회통합실태조사_데이터_2019.sav&quot;) 1## re-encoding from CP51949 1mental1 &lt;- read.spss(&quot;한국행정연구원_사회통합실태조사_데이터_2019.sav&quot;) 1## re-encoding from CP51949 예제파일에서 불러올때 ‘to.data.fram&#x3D;T’를 써도 된다. R로 spss데이터를 불러오면 리스트 형태로 입력되기 때문에 데이터 프레임 형태로 mental &lt;- as.data.frame(mental) 만들어준다. 1class(mental) 1## [1] &quot;list&quot; 1mental &lt;- as.data.frame(mental) 분석 변수 추출하고 이름 변경하기. str()합수로 mental의 구조를 보면 276개의 변수에 8000개의 데이터가 있다. 연구문제에 맞는 분석 변수만 추출하고 변수 이름을 영어로 변경했다. 1str(mental) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101## &#x27;data.frame&#x27;: 8000 obs. of 276 variables:## $ id : num 1 2 3 4 5 6 7 8 9 10 ...## $ ara : Factor w/ 17 levels &quot;서울&quot;,&quot;부산&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...## $ wt1 : num 12216 12216 8455 7421 6474 ...## $ wt2 : num 2.58 2.58 1.79 1.57 1.37 ...## $ q1_1 : Factor w/ 12 levels &quot;0점 전혀 행복하지 않았다&quot;,..: 8 6 7 5 7 8 8 8 7 5 ...## $ q1_2 : Factor w/ 12 levels &quot;0점 전혀 하지 않았다&quot;,..: 5 5 5 4 4 4 6 6 4 6 ...## $ q1_3 : Factor w/ 12 levels &quot;0점 전혀 우울하지 않았다&quot;,..: 6 4 6 5 4 5 5 7 5 5 ...## $ q1_4 : Factor w/ 12 levels &quot;0점 전혀 만족하지 않는다&quot;,..: 5 5 5 4 7 5 6 6 5 5 ...## $ q1_5 : Factor w/ 12 levels &quot;0점 전혀 가치 없다&quot;,..: 6 4 5 4 8 7 7 6 5 4 ...## $ q2_1 : Factor w/ 11 levels &quot;0점 전혀 안전하지 않다&quot;,..: 5 6 7 5 7 8 6 7 6 6 ...## $ q2_2 : Factor w/ 11 levels &quot;0점 전혀 안전하지 않다&quot;,..: 4 7 6 4 7 7 7 5 4 5 ...## $ q2_3 : Factor w/ 11 levels &quot;0점 전혀 안전하지 않다&quot;,..: 4 7 6 5 7 5 6 4 4 6 ...## $ q3 : Factor w/ 11 levels &quot;0점 전혀 자유롭지 않다&quot;,..: 4 6 4 3 8 6 6 5 4 5 ...## $ q4 : Factor w/ 12 levels &quot;0점 매우 낮다&quot;,..: 4 6 5 4 6 7 6 4 4 6 ...## $ q5_1 : Factor w/ 5 levels &quot;전혀 그렇지 않다&quot;,..: 3 3 2 3 3 3 2 2 2 2 ...## $ q5_2 : Factor w/ 5 levels &quot;전혀 그렇지 않다&quot;,..: 2 3 3 2 2 3 3 2 1 2 ...## $ q5_2_1 : Factor w/ 5 levels &quot;전혀 그렇지 않다&quot;,..: 2 3 2 3 2 3 2 2 2 2 ...## $ q5_2_2 : Factor w/ 5 levels &quot;전혀 그렇지 않다&quot;,..: 2 4 2 2 2 2 2 2 1 2 ...## $ q5_3 : Factor w/ 5 levels &quot;전혀 그렇지 않다&quot;,..: 3 3 3 3 3 3 2 2 1 2 ...## $ q5_4 : Factor w/ 5 levels &quot;전혀 그렇지 않다&quot;,..: 2 3 2 2 3 2 2 1 1 1 ...## $ q6 : Factor w/ 11 levels &quot;0점 전혀 만족하지 않는다&quot;,..: 7 7 6 6 7 8 7 5 7 4 ...## $ q7 : Factor w/ 11 levels &quot;0점 매우 나빠질 것이다&quot;,..: 7 6 6 5 6 7 8 6 5 4 ...## $ q8 : Factor w/ 11 levels &quot;0점 전혀 만족하지 않는다&quot;,..: 6 6 6 7 6 6 7 5 5 3 ...## $ q9 : Factor w/ 11 levels &quot;0점 매우 나빠질 것이다&quot;,..: 5 6 5 7 6 6 7 5 5 3 ...## $ q10 : Factor w/ 11 levels &quot;0점 전혀 만족하지 않는다&quot;,..: 6 9 7 8 7 9 7 6 5 6 ...## $ q11 : Factor w/ 11 levels &quot;0점 매우 나빠질 것이다&quot;,..: 4 9 6 5 5 7 6 6 5 8 ...## $ q12 : Factor w/ 11 levels &quot;북한은 우리의 적이다&quot;,..: 4 4 7 6 6 7 7 7 3 7 ...## $ q13 : Factor w/ 11 levels &quot;성장이 더 중요하다&quot;,..: 4 5 6 5 7 6 6 6 3 5 ...## $ q14 : Factor w/ 11 levels &quot;공동체의 이익이 더 중요하다&quot;,..: 4 4 6 4 7 7 7 6 3 5 ...## $ q15_1 : Factor w/ 4 levels &quot;고도의 경제성장&quot;,..: 1 1 1 1 3 2 2 2 4 3 ...## $ q15_2 : Factor w/ 4 levels &quot;고도의 경제성장&quot;,..: 2 3 4 4 2 1 1 4 1 4 ...## $ q16_1 : Factor w/ 4 levels &quot;국가의 질서 유지&quot;,..: 2 2 2 2 1 2 2 2 4 2 ...## $ q16_2 : Factor w/ 4 levels &quot;국가의 질서 유지&quot;,..: 3 4 4 3 4 3 3 4 1 3 ...## $ q17_1 : Factor w/ 4 levels &quot;경제 안정&quot;,&quot;범죄와의 전쟁&quot;,..: 2 3 3 2 2 1 2 2 4 1 ...## $ q17_2 : Factor w/ 4 levels &quot;경제 안정&quot;,&quot;범죄와의 전쟁&quot;,..: 4 2 1 3 3 4 3 3 2 4 ...## $ q18_1 : Factor w/ 4 levels &quot;전혀 동의하지 않는다&quot;,..: 2 2 2 3 2 3 3 2 3 2 ...## $ q18_2 : Factor w/ 4 levels &quot;전혀 동의하지 않는다&quot;,..: 2 3 3 2 3 2 3 3 2 3 ...## $ q18_3 : Factor w/ 4 levels &quot;전혀 동의하지 않는다&quot;,..: 2 2 3 2 2 2 3 2 2 2 ...## $ q19_1 : Factor w/ 6 levels &quot;소속된 적이 없다&quot;,..: 1 2 1 1 1 1 1 1 3 1 ...## $ q19_2 : Factor w/ 6 levels &quot;소속된 적이 없다&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...## $ q19_3 : Factor w/ 6 levels &quot;소속된 적이 없다&quot;,..: 1 1 1 3 1 1 1 1 1 1 ...## $ q19_4 : Factor w/ 6 levels &quot;소속된 적이 없다&quot;,..: 3 1 1 3 2 3 3 3 3 1 ...## $ q19_5 : Factor w/ 6 levels &quot;소속된 적이 없다&quot;,..: 1 2 1 1 1 2 1 1 1 1 ...## $ q19_6 : Factor w/ 6 levels &quot;소속된 적이 없다&quot;,..: 3 1 1 1 1 1 2 1 1 1 ...## $ q19_7 : Factor w/ 6 levels &quot;소속된 적이 없다&quot;,..: 3 1 1 1 3 1 2 3 2 1 ...## $ q19_8 : Factor w/ 6 levels &quot;소속된 적이 없다&quot;,..: 1 1 2 1 2 1 1 1 1 1 ...## $ q19_9 : Factor w/ 6 levels &quot;소속된 적이 없다&quot;,..: 1 1 1 1 2 1 1 2 1 1 ...## $ q20_1 : Factor w/ 8 levels &quot;1점 전혀 중요하지 않다&quot;,..: 4 4 2 4 6 2 5 4 6 5 ...## $ q20_2 : Factor w/ 8 levels &quot;1점 전혀 중요하지 않다&quot;,..: 5 3 3 5 6 3 4 5 6 4 ...## $ q20_3 : Factor w/ 8 levels &quot;1점 전혀 중요하지 않다&quot;,..: 6 3 4 4 5 2 4 4 5 5 ...## $ q20_4 : Factor w/ 8 levels &quot;1점 전혀 중요하지 않다&quot;,..: 5 4 5 3 6 2 4 5 5 4 ...## $ q20_5 : Factor w/ 8 levels &quot;1점 전혀 중요하지 않다&quot;,..: 5 2 4 4 6 2 5 5 5 4 ...## $ q20_6 : Factor w/ 8 levels &quot;1점 전혀 중요하지 않다&quot;,..: 5 2 5 3 6 3 3 5 7 4 ...## $ q20_7 : Factor w/ 8 levels &quot;1점 전혀 중요하지 않다&quot;,..: 5 3 5 3 6 2 3 5 6 3 ...## $ q20_8 : Factor w/ 8 levels &quot;1점 전혀 중요하지 않다&quot;,..: 5 3 5 3 7 2 3 5 6 3 ...## $ q21_1 : Factor w/ 5 levels &quot;전혀 동의하지 않는다&quot;,..: 4 3 3 3 4 4 4 3 4 3 ...## $ q21_2 : Factor w/ 5 levels &quot;전혀 동의하지 않는다&quot;,..: 3 3 2 3 3 4 4 4 3 2 ...## $ q21_3 : Factor w/ 5 levels &quot;전혀 동의하지 않는다&quot;,..: 3 4 3 4 3 5 4 3 4 2 ...## $ q21_4 : Factor w/ 5 levels &quot;전혀 동의하지 않는다&quot;,..: 3 3 2 3 3 4 4 3 3 2 ...## $ q22_1 : Factor w/ 4 levels &quot;지난 1년 동안 한 적이 있다&quot;,..: 4 3 1 3 1 3 1 3 4 2 ...## $ q22_2 : Factor w/ 4 levels &quot;지난 1년 동안 한 적이 있다&quot;,..: 4 2 2 3 1 3 1 2 4 2 ...## $ q22_3 : Factor w/ 4 levels &quot;지난 1년 동안 한 적이 있다&quot;,..: 4 3 2 3 3 3 3 3 4 3 ...## $ q22_4 : Factor w/ 4 levels &quot;지난 1년 동안 한 적이 있다&quot;,..: 4 3 1 2 1 3 3 3 4 2 ...## $ q22_5 : Factor w/ 4 levels &quot;지난 1년 동안 한 적이 있다&quot;,..: 4 3 3 3 1 3 3 3 4 2 ...## $ q22_6 : Factor w/ 4 levels &quot;지난 1년 동안 한 적이 있다&quot;,..: 4 4 3 3 1 3 3 4 4 3 ...## $ q22_7 : Factor w/ 4 levels &quot;지난 1년 동안 한 적이 있다&quot;,..: 4 2 3 3 1 3 2 3 4 2 ...## $ q22_8 : Factor w/ 4 levels &quot;지난 1년 동안 한 적이 있다&quot;,..: 4 2 3 3 1 1 2 3 1 2 ...## $ q23 : Factor w/ 2 levels &quot;참여했다&quot;,&quot;참여하지 않았다&quot;: 1 1 1 1 1 1 2 1 1 1 ...## $ q24 : Factor w/ 2 levels &quot;참여했다&quot;,&quot;참여하지 않았다&quot;: 1 1 1 1 1 1 2 1 1 1 ...## $ q25 : Factor w/ 2 levels &quot;참여했다&quot;,&quot;참여하지 않았다&quot;: 1 1 1 2 1 1 2 1 1 1 ...## $ q26 : Factor w/ 2 levels &quot;있다&quot;,&quot;없다&quot;: 1 1 1 1 2 1 2 1 1 2 ...## $ q27 : Factor w/ 6 levels &quot;매우 보수적&quot;,..: 1 2 2 3 4 4 3 1 2 3 ...## $ q28_1 : Factor w/ 4 levels &quot;전혀 이루어지지 않고 있다&quot;,..: 2 3 2 1 3 3 3 3 3 1 ...## $ q28_2 : Factor w/ 4 levels &quot;전혀 이루어지지 않고 있다&quot;,..: 2 3 3 2 2 3 3 3 2 1 ...## $ q28_3 : Factor w/ 4 levels &quot;전혀 이루어지지 않고 있다&quot;,..: 2 3 2 2 3 2 4 2 2 1 ...## $ q28_4 : Factor w/ 4 levels &quot;전혀 이루어지지 않고 있다&quot;,..: 2 3 2 2 2 1 3 2 2 1 ...## $ q29_1 : Factor w/ 4 levels &quot;전혀 이루어지지 않고 있다&quot;,..: 3 2 2 3 2 2 2 1 4 3 ...## $ q29_2 : Factor w/ 4 levels &quot;전혀 이루어지지 않고 있다&quot;,..: 3 3 3 2 2 1 2 1 3 2 ...## $ q29_3 : Factor w/ 4 levels &quot;전혀 이루어지지 않고 있다&quot;,..: 3 3 2 2 3 1 2 1 3 2 ...## $ q29_4 : Factor w/ 4 levels &quot;전혀 이루어지지 않고 있다&quot;,..: 3 3 2 2 3 1 2 1 3 2 ...## $ q30_1 : Factor w/ 5 levels &quot;없다&quot;,&quot;1~2명&quot;,..: 2 3 2 3 2 2 2 2 2 1 ...## $ q30_1_1 : Factor w/ 7 levels &quot;전화&quot;,&quot;우편&quot;,..: 4 4 4 4 4 4 4 4 4 NA ...## $ q30_1_2 : Factor w/ 6 levels &quot;이메일&quot;,&quot;SNS(페이스북, 트위터, 인스타그램 등)&quot;,..: NA NA NA NA NA NA NA NA NA NA ...## $ q30_2 : Factor w/ 7 levels &quot;없다&quot;,&quot;1~2명&quot;,..: 3 4 3 3 4 2 2 3 4 2 ...## $ q30_2_1 : Factor w/ 7 levels &quot;전화&quot;,&quot;우편&quot;,..: 1 4 4 4 3 4 1 4 1 5 ...## $ q30_2_2 : Factor w/ 6 levels &quot;이메일&quot;,&quot;SNS(페이스북, 트위터, 인스타그램 등)&quot;,..: NA NA NA NA 1 NA NA NA NA NA ...## $ q31_1 : Factor w/ 5 levels &quot;없다&quot;,&quot;1~2명&quot;,..: 4 3 1 3 3 2 1 4 3 3 ...## $ q31_2 : Factor w/ 5 levels &quot;없다&quot;,&quot;1~2명&quot;,..: 3 2 1 2 3 2 1 3 2 2 ...## $ q31_3 : Factor w/ 5 levels &quot;없다&quot;,&quot;1~2명&quot;,..: 4 3 1 2 3 2 1 4 2 2 ...## $ q32_1 : Factor w/ 4 levels &quot;전혀 그렇지 않다&quot;,..: 2 2 2 2 1 2 3 3 1 2 ...## $ q32_2 : Factor w/ 4 levels &quot;전혀 그렇지 않다&quot;,..: 2 2 2 1 1 2 3 3 1 2 ...## $ q32_3 : Factor w/ 4 levels &quot;전혀 그렇지 않다&quot;,..: 2 2 2 2 1 2 3 3 1 2 ...## $ q33 : Factor w/ 5 levels &quot;전혀 믿을 수 없다&quot;,..: 2 3 2 2 3 2 2 3 3 3 ...## $ q34_1 : Factor w/ 4 levels &quot;전혀 신뢰하지 않는다&quot;,..: 3 3 2 2 4 2 2 2 4 3 ...## $ q34_2 : Factor w/ 4 levels &quot;전혀 신뢰하지 않는다&quot;,..: 2 3 2 3 3 2 2 3 3 2 ...## $ q34_3 : Factor w/ 4 levels &quot;전혀 신뢰하지 않는다&quot;,..: 2 2 2 3 2 2 1 2 3 3 ...## $ q34_4 : Factor w/ 4 levels &quot;전혀 신뢰하지 않는다&quot;,..: 2 2 2 2 1 1 2 2 2 2 ...## $ q34_5 : Factor w/ 4 levels &quot;전혀 신뢰하지 않는다&quot;,..: 2 2 2 2 2 1 2 2 2 2 ...## $ q35_1 : Factor w/ 4 levels &quot;전혀 믿지 않는다&quot;,..: 3 3 2 2 2 2 1 2 3 3 ...## [list output truncated] 1234567891011mental &lt;- mental %&gt;% select(q32_2, q1_4, q32_1, q34_1, q52, d17, d1, d2, ara) %&gt;% rename(suicide=q32_2, satisfaction=q1_4, loneliness=q32_1, family_belief=q34_1, wealth=q52, health=d17, sex=d1, age=d2, area=ara) 4점, 5점, 11점 척도별 응담 빈도 확인 1table(mental$suicide) # suicide 빈도 확인 123## ## 전혀 그렇지 않다 별로 그렇지 않다 약간 그렇다 매우 그렇다 ## 5592 1862 479 67 1table(mental$health) # health 빈도 확인 123## ## 매우 나쁘다 나쁜 편이다 보통이다 좋은 편이다 매우 좋다 ## 87 509 2413 3730 1261 1table(mental$satisfaction) # satisfaction 빈도 확인 123456789## ## 0점 전혀 만족하지 않는다 1점 2점 ## 49 79 170 ## 3점 4점 5점 보통 ## 302 440 2053 ## 6점 7점 8점 ## 1611 1761 1040 ## 9점 10점 매우 만족한다 모름/무응답 ## 321 174 0 12345678mental$suicide &lt;- as.integer(mental$suicide)mental$satisfaction &lt;- as.integer(mental$satisfaction)mental$loneliness &lt;- as.integer(mental$loneliness)mental$family_belief &lt;- as.integer(mental$family_belief)mental$wealth &lt;- as.integer(mental$wealth)mental$health &lt;- as.integer(mental$health)table(mental$suicide) 123## ## 1 2 3 4 ## 5592 1862 479 67 1table(mental$health) 123## ## 1 2 3 4 5 ## 87 509 2413 3730 1261 1table(mental$satisfaction) 123## ## 1 2 3 4 5 6 7 8 9 10 11 ## 49 79 170 302 440 2053 1611 1761 1040 321 174 숫자 1씩 빼는 보정 작업1234mental$satisfaction &lt;- mental$satisfaction-1mental$wealth &lt;- mental$wealth-1table(mental$satisfaction) 123## ## 0 1 2 3 4 5 6 7 8 9 10 ## 49 79 170 302 440 2053 1611 1761 1040 321 174 sex,age,area의 유형을 범주형에서 문자형으로 변경하기123mental$age&lt;-as.character(mental$age)mental$sex&lt;-as.character(mental$sex)mental$area&lt;-as.character(mental$area) 변형된 문자형에 범주와 빈도를 알아보기1table(mental$sex) 123## ## 남성 여성 ## 4011 3989 1table(mental$age) 123## ## 19~29세 30대 40대 50대 60~69세 ## 1542 1516 1769 1821 1352 1table(mental$area) 12345## ## 강원 경기 경남 경북 광주 대구 대전 부산 서울 세종 울산 인천 전남 전북 제주 충남 ## 388 1103 527 466 353 464 356 539 965 162 324 522 395 381 267 425 ## 충북 ## 363 가시성을 위해 19세29세를 20대로 6069세를 60대로 수정12mental$age &lt;- ifelse(mental$age==&quot;19~29세&quot;,&quot;20대&quot;, ifelse(mental$age==&quot;60~69세&quot;,&quot;60대&quot;,mental$age)) 결측치 이상치 확인하기.1summary(mental) 123456789101112131415161718192021## suicide satisfaction loneliness family_belief ## Min. :1.000 Min. : 0.000 Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.: 5.000 1st Qu.:1.000 1st Qu.:3.000 ## Median :1.000 Median : 6.000 Median :2.000 Median :4.000 ## Mean :1.378 Mean : 6.037 Mean :1.795 Mean :3.576 ## 3rd Qu.:2.000 3rd Qu.: 7.000 3rd Qu.:2.000 3rd Qu.:4.000 ## Max. :4.000 Max. :10.000 Max. :4.000 Max. :4.000 ## wealth health sex age ## Min. : 0.000 Min. :1.000 Length:8000 Length:8000 ## 1st Qu.: 4.000 1st Qu.:3.000 Class :character Class :character ## Median : 5.000 Median :4.000 Mode :character Mode :character ## Mean : 4.985 Mean :3.696 ## 3rd Qu.: 6.000 3rd Qu.:4.000 ## Max. :10.000 Max. :5.000 ## area ## Length:8000 ## Class :character ## Mode :character ## ## ## 데이터 분석빈도분석성과 연령대의 빈도와 비율을 알바보겠다. 통상 비율은 백분율로 소수점 한자리까지 구함. 12345mental %&gt;% group_by(sex) %&gt;% summarise(n=n()) %&gt;% mutate(total=sum(n), pct=round(n/total*100,1)) 12345## # A tibble: 2 × 4## sex n total pct## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;## 1 남성 4011 8000 50.1## 2 여성 3989 8000 49.9 연령대별 빈도분석12345mental %&gt;% group_by(age) %&gt;% summarise(n=n()) %&gt;% mutate(total=sum(n), pct=round(n/total*100,1)) 12345678## # A tibble: 5 × 4## age n total pct## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;## 1 20대 1542 8000 19.3## 2 30대 1516 8000 19 ## 3 40대 1769 8000 22.1## 4 50대 1821 8000 22.8## 5 60대 1352 8000 16.9 성과 연령대의 교차 빈도 구하기1table(mental$sex, mental$age) 1234## ## 20대 30대 40대 50대 60대## 남성 822 745 900 891 653## 여성 720 771 869 930 699 성과 연령대의 교차 백분율 구하기. 행별로 100%기준.소수점 한자리1round(prop.table(table(mental$sex,mental$age),1)*100,1) 1234## ## 20대 30대 40대 50대 60대## 남성 20.5 18.6 22.4 22.2 16.3## 여성 18.0 19.3 21.8 23.3 17.5 앞의 숫자 1은 행별로 비율의 총합이 1이 되도록 계산하라는 명령이다. 뒤의 숫자 1은 소수점 한자리까지 구하라는 명령이다. 교차분석 검정1chisq.test(mental$sex,mental$age) 12345## ## Pearson&#x27;s Chi-squared test## ## data: mental$sex and mental$age## X-squared = 10.076, df = 4, p-value = 0.03916 1을 보면 유의수준이 0.03916으로 p&lt;.05이다. 남성과 여성의 연령대 분포 비율은 다소 차이가 있다고 할 수 있음 평균 분석12mental %&gt;% summarise(m1=mean(suicide),m2=mean(satisfaction),m3=mean(loneliness),m4=mean(family_belief),m5=mean(wealth),m6=mean(health)) 12## m1 m2 m3 m4 m5 m6## 1 1.377625 6.0365 1.795 3.576375 4.985125 3.696125 자살충동 : 4점 척도에서 1.38점으로 ‘아니다~별로 아니다’에 있다. 삶의 만족도 : 0~10점 척도에서 6.04점이다. 외로움 : 4점 척도에서 1.8로 비교적 낮다 가족 신뢰도 : 4점 척도에서 3.58로 높다 경제안정도 : 0~10점 척도에서 4.99점으로 보통이다. 건강상태 : 5점 척도에서 3.7로 좋은 수준이다. 삶의 만족도와 외로움이 자살충동에 미치는 영향123RA &lt;- lm(data = mental, suicide~satisfaction+loneliness)summary(RA) 12345678910111213141516171819## ## Call:## lm(formula = suicide ~ satisfaction + loneliness, data = mental)## ## Residuals:## Min 1Q Median 3Q Max ## -1.50517 -0.40228 -0.03487 0.17773 3.07029 ## ## Coefficients:## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.035551 0.029823 34.72 &lt;2e-16 ***## satisfaction -0.052583 0.003614 -14.55 &lt;2e-16 ***## loneliness 0.367405 0.007987 46.00 &lt;2e-16 ***## ---## Signif. codes: 0 &#x27;***&#x27; 0.001 &#x27;**&#x27; 0.01 &#x27;*&#x27; 0.05 &#x27;.&#x27; 0.1 &#x27; &#x27; 1## ## Residual standard error: 0.5451 on 7997 degrees of freedom## Multiple R-squared: 0.2668, Adjusted R-squared: 0.2666 ## F-statistic: 1455 on 2 and 7997 DF, p-value: &lt; 2.2e-16 삶의 만족도와 외로움의 상관관계1cor.test(mental$satisfaction,mental$loneliness) 1234567891011## ## Pearson&#x27;s product-moment correlation## ## data: mental$satisfaction and mental$loneliness## t = -25.374, df = 7998, p-value &lt; 2.2e-16## alternative hypothesis: true correlation is not equal to 0## 95 percent confidence interval:## -0.2931116 -0.2525481## sample estimates:## cor ## -0.2729512 1을 보면 유의수준은 0.001보다 작기 때문에 통계적을 유의미함 삶의 만족도와 외로움은 약한 수준에서 부적인 상관관계에 있음 삶의 만족도가 높아지면 외로움이 약간 줄어드는 관계 가족신뢰도, 경제안정도, 건강상태가 삶의 만족도와 외로움에 미치는 영향123RA &lt;- lm(data=mental,satisfaction~family_belief+wealth+health)summary(RA) 123456789101112131415161718192021## ## Call:## lm(formula = satisfaction ~ family_belief + wealth + health, ## data = mental)## ## Residuals:## Min 1Q Median 3Q Max ## -6.8274 -0.9431 -0.0425 1.0569 6.1986 ## ## Coefficients:## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.07613 0.13765 15.08 &lt;2e-16 ***## family_belief 0.36851 0.03196 11.53 &lt;2e-16 ***## wealth 0.26016 0.01089 23.88 &lt;2e-16 ***## health 0.36403 0.02206 16.50 &lt;2e-16 ***## ---## Signif. codes: 0 &#x27;***&#x27; 0.001 &#x27;**&#x27; 0.01 &#x27;*&#x27; 0.05 &#x27;.&#x27; 0.1 &#x27; &#x27; 1## ## Residual standard error: 1.627 on 7996 degrees of freedom## Multiple R-squared: 0.1386, Adjusted R-squared: 0.1383 ## F-statistic: 428.8 on 3 and 7996 DF, p-value: &lt; 2.2e-16 삶의 만족도가 1단위 높아지면 자살충동이 -0.052583단위로 감소. 외로움이 1단위 높아지면 자살충동은 0.367405단위로 증가함. 삶의 만족도는 자살충동을 줄이는데 긍정적인 영향을 미치지만 외로움은 부정적인 영향이 훨씬 더 크게 미침을 알 수 있다. 삶의 만족도와 외로움의 상관관계1cor.test(mental$satisfaction,mental$loneliness) 1234567891011## ## Pearson&#x27;s product-moment correlation## ## data: mental$satisfaction and mental$loneliness## t = -25.374, df = 7998, p-value &lt; 2.2e-16## alternative hypothesis: true correlation is not equal to 0## 95 percent confidence interval:## -0.2931116 -0.2525481## sample estimates:## cor ## -0.2729512 유의수준은 0.001보다 작기 때문에 통계적으론 유의미하다 봄.-상관계수는 -0.27 따라서 삶의 만족도와 외로움은 약한 수준에서 부적인 상관관계에 있음 삶의 만족도가 높아지면 외로움이 약간 줄어드는 관계다. 3개 독립변수가 삶의 만족도에 미치는 영향12RA &lt;- lm(data = mental, satisfaction~family_belief+wealth+health)summary(RA) 123456789101112131415161718192021## ## Call:## lm(formula = satisfaction ~ family_belief + wealth + health, ## data = mental)## ## Residuals:## Min 1Q Median 3Q Max ## -6.8274 -0.9431 -0.0425 1.0569 6.1986 ## ## Coefficients:## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.07613 0.13765 15.08 &lt;2e-16 ***## family_belief 0.36851 0.03196 11.53 &lt;2e-16 ***## wealth 0.26016 0.01089 23.88 &lt;2e-16 ***## health 0.36403 0.02206 16.50 &lt;2e-16 ***## ---## Signif. codes: 0 &#x27;***&#x27; 0.001 &#x27;**&#x27; 0.01 &#x27;*&#x27; 0.05 &#x27;.&#x27; 0.1 &#x27; &#x27; 1## ## Residual standard error: 1.627 on 7996 degrees of freedom## Multiple R-squared: 0.1386, Adjusted R-squared: 0.1383 ## F-statistic: 428.8 on 3 and 7996 DF, p-value: &lt; 2.2e-16 3개다 통계적으로 유의미하다. 가족신뢰도&gt;건강상태&gt;경제안정도의 순으로 영향력이 큼. 3개 독립변수가 외로움에 미치는 영향123RA &lt;- lm(data = mental, loneliness~family_belief+wealth+health)summary(RA) 1234567891011121314151617181920## ## Call:## lm(formula = loneliness ~ family_belief + wealth + health, data = mental)## ## Residuals:## Min 1Q Median 3Q Max ## -2.24066 -0.64247 0.01863 0.43022 2.83959 ## ## Coefficients:## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.652247 0.063109 57.87 &lt;2e-16 ***## family_belief -0.220274 0.014654 -15.03 &lt;2e-16 ***## wealth -0.072686 0.004995 -14.55 &lt;2e-16 ***## health -0.191313 0.010116 -18.91 &lt;2e-16 ***## ---## Signif. codes: 0 &#x27;***&#x27; 0.001 &#x27;**&#x27; 0.01 &#x27;*&#x27; 0.05 &#x27;.&#x27; 0.1 &#x27; &#x27; 1## ## Residual standard error: 0.746 on 7996 degrees of freedom## Multiple R-squared: 0.1157, Adjusted R-squared: 0.1154 ## F-statistic: 348.9 on 3 and 7996 DF, p-value: &lt; 2.2e-16 가족신뢰도,경제안정도,건강상태가 나빠지면 외로움더 커짐 가족신뢰도&gt;건강상태&gt;경제안정도 순으로 영향력이 큼. 성, 연령, 지역별 삶의 만족도 차이1t.test(data=mental,satisfaction~sex) 1234567891011## ## Welch Two Sample t-test## ## data: satisfaction by sex## t = -3.7719, df = 7997.6, p-value = 0.0001632## alternative hypothesis: true difference in means between group 남성 and group 여성 is not equal to 0## 95 percent confidence interval:## -0.22446298 -0.07094075## sample estimates:## mean in group 남성 mean in group 여성 ## 5.962852 6.110554 유의수준이 0.001보다 작기 때문에 결과는 유의미하다. 여성의 만족도가 남성보다 높다고 할 수 있음 연령대별 삶의 만족도 차이1234mental %&gt;% group_by(age) %&gt;% summarise(m=mean(satisfaction)) %&gt;% arrange(desc(m)) 12345678## # A tibble: 5 × 2## age m## &lt;chr&gt; &lt;dbl&gt;## 1 30대 6.13## 2 50대 6.08## 3 40대 6.05## 4 20대 6.04## 5 60대 5.84 지역별 삶의 만족도 분석과 그래프 그리기1234567891011area_satisfaction &lt;- mental %&gt;% group_by(area) %&gt;% summarise(m=mean(satisfaction)) %&gt;% arrange(desc(m))ggplot(data=area_satisfaction, aes(x=reorder(area,m),y=m))+ geom_col()+ ggtitle(&quot;지역별만족도&quot;)+ xlab(&quot;지역&quot;)+ ylab(&quot;만족도&quot;)+ coord_flip()","categories":[],"tags":[]},{"title":"Untitled","slug":"day_0623","date":"2022-06-23T01:00:00.000Z","updated":"2022-06-23T07:37:34.177Z","comments":true,"path":"2022/06/23/day_0623/","link":"","permalink":"https://park128.github.io/2022/06/23/day_0623/","excerpt":"","text":"통계 기술통계 : 평균, 최솟값, 최댓값, 중간값 추론통계 : 변수 간의 관계를 파악 &#x2F; 새로운 사실을 발견(&#x3D;추정) 평균 차이 검정 수치 데이터 가설 검정 : 각 그룹간의 평균값의 차이를 검정 남자의 평균 키와 여자의 평균 키는 차이가 있을 것이다. 교차 분석 (&#x3D; 빈도 분석) 범주 데이터 가설 검정 : 각 범주별 빈도를 활용해서 관계성을 검정 상관관계분석 수치 데이터 단순회귀분석 y &#x3D; ax + b 온도, 판매량 가설검정 기온(독립변수)이 판매량(종속변수)에 긍정적인 혹은 부정적인 영향을 주고 있을 것이다. 통계 검정 p.176 가설 Hypothesis 연구 : 내가 궁금한 것을 찾는 것 남자와 여자가 키가 동일하다는 귀무가설 : 두 그룹간의 평균 차이가 없다. 대립가설 : 두 그룹간의 평균 차이가 있다. 가설검정에서 인정하는 유의수준 5%, 1%, 0.1%, 또는 10% 남자 평균 키와, 여자 평균 키 실험유의수준 &gt; 0.05 t.test 어떻게 데이터를 입력하는지 확인 p-value, 유의수준 0.05 이상 : 귀무가설, 0.05 이내 –&gt; 대립가설 12mpg1 &lt;- read.csv(&quot;mpg1.csv&quot;, stringsAsFactors = FALSE)str(mpg1) 123456## &#x27;data.frame&#x27;: 234 obs. of 5 variables:## $ manufacturer: chr &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; ...## $ trans : chr &quot;auto&quot; &quot;manual&quot; &quot;manual&quot; &quot;auto&quot; ...## $ drv : chr &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ...## $ cty : int 18 21 20 21 16 18 18 18 16 20 ...## $ hwy : int 29 29 31 30 26 26 27 26 25 28 ... 시각화 123library(ggplot2)ggplot(mpg1, aes(x = trans, y = cty)) + geom_boxplot() t.test 검정 귀무가설 : auto와 manual의 cty 평균은 차이가 없다. 대립가설 : auto와 manual의 cty 평균은 차이가 있다. 1t.test(data = mpg1, cty ~ trans) 1234567891011## ## Welch Two Sample t-test## ## data: cty by trans## t = -4.5375, df = 132.32, p-value = 1.263e-05## alternative hypothesis: true difference in means between group auto and group manual is not equal to 0## 95 percent confidence interval:## -3.887311 -1.527033## sample estimates:## mean in group auto mean in group manual ## 15.96815 18.67532 123# 종속변수 ~ 독립변수# 반응변수 ~ 설명변수# y x 두 그룹의 평균 차이 검정 사전 필수 검증 등분산 검정 두 그룹간의 분산이 비슷하면 –&gt; t.test (모수 검정) 두 그룹간의 분산이 다르면, –&gt; 비모수 검정 등분산 검정 귀무가설 : 두 그룹간의 분산이 비슷하다. p.value &gt; 0.05 대립가설 : 두 그룹간의 분산이 다르다. 1var.test(data = mpg1, cty~trans) 1234567891011## ## F test to compare two variances## ## data: cty by trans## F = 0.73539, num df = 156, denom df = 76, p-value = 0.1101## alternative hypothesis: true ratio of variances is not equal to 1## 95 percent confidence interval:## 0.4912917 1.0719468## sample estimates:## ratio of variances ## 0.7353887 123ggplot(mpg1, aes(x = cty, fill = trans)) + # geom_histogram() + geom_density(alpha = 0.1) 교차분석 범주형 변수들이 관계가 있다는 것을 검정 비율에 차이가 있는지 검정 교차분석 검정은 R의 chisq.test() 함수로 진행 귀무가설 : trans에 따라 drv(4, f, r)의 (비율)차이가 없다. 대립가설 : trans에 따라 drv의 차이가 있다. 빈도표 &#x2F; 비율 1table(mpg1$trans, mpg1$drv) #교차분석 1234## ## 4 f r## auto 75 65 17## manual 28 41 8 1prop.table(table(mpg1$trans, mpg1$drv), 1) 1234## ## 4 f r## auto 0.4777070 0.4140127 0.1082803## manual 0.3636364 0.5324675 0.1038961 auto 4륜 구동(4)인 47.8% manual 전륜구동(f) 53.2% 가장 많음 실제로 통계적으로 봤을 때, 차이가 있는지 검정 귀무가설 : trans에 따라 drv(4 , f, r)의 (비율)차이가 없다. 대립가설 : trans에 따라 drv의 차이가 있다. chisq.test(), summary(),table() 함수로 교차분석하기.1chisq.test(mpg1$trans, mpg1$drv) 12345## ## Pearson&#x27;s Chi-squared test## ## data: mpg1$trans and mpg1$drv## X-squared = 3.1368, df = 2, p-value = 0.2084 1chisq.test(table(mpg1$trans, mpg1$drv)) 12345## ## Pearson&#x27;s Chi-squared test## ## data: table(mpg1$trans, mpg1$drv)## X-squared = 3.1368, df = 2, p-value = 0.2084 1summary(table(mpg1$trans,mpg1$drv)) 1234## Number of cases in table: 234 ## Number of factors: 2 ## Test for independence of all factors:## Chisq = 3.1368, df = 2, p-value = 0.2084 상관관계분석1cor.test(mpg1$cty, mpg1$hwy) 1234567891011## ## Pearson&#x27;s product-moment correlation## ## data: mpg1$cty and mpg1$hwy## t = 49.585, df = 232, p-value &lt; 2.2e-16## alternative hypothesis: true correlation is not equal to 0## 95 percent confidence interval:## 0.9433129 0.9657663## sample estimates:## cor ## 0.9559159","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2022-06-22T04:06:11.587Z","updated":"2022-06-17T02:56:52.823Z","comments":true,"path":"2022/06/22/hello-world/","link":"","permalink":"https://park128.github.io/2022/06/22/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"day0622","slug":"day_0622","date":"2022-06-22T00:00:00.000Z","updated":"2022-06-22T08:41:27.724Z","comments":true,"path":"2022/06/22/day_0622/","link":"","permalink":"https://park128.github.io/2022/06/22/day_0622/","excerpt":"","text":"라이브러리 불러오기1library(dplyr) 12## ## 다음의 패키지를 부착합니다: &#x27;dplyr&#x27; 123## The following objects are masked from &#x27;package:stats&#x27;:## ## filter, lag 123## The following objects are masked from &#x27;package:base&#x27;:## ## intersect, setdiff, setequal, union 1library(ggplot2) 데이터 불러오기-데이터를 불러온다. 12exam_na &lt;- read.csv(&quot;exam_na.csv&quot;)str(exam_na) 123456## &#x27;data.frame&#x27;: 5 obs. of 5 variables:## $ id : int 1 2 3 4 5## $ sex : chr &quot;M&quot; &quot;F&quot; &quot;F&quot; &quot;M&quot; ...## $ korean : int 87 92 95 NA 87## $ english: int NA 95 92 84 NA## $ math : int 82 93 90 80 88 is.na()()안에 검증하려는 ~ (2) 결측치 빈도 구하기 table() : 빈도 구하기 1table(is.na(exam_na)) 123## ## FALSE TRUE ## 22 3 1table(is.na(exam_na$korean)) 123## ## FALSE TRUE ## 4 1 1summary(is.na(exam_na)) 12345678## id sex korean english ## Mode :logical Mode :logical Mode :logical Mode :logical ## FALSE:5 FALSE:5 FALSE:4 FALSE:3 ## TRUE :1 TRUE :2 ## math ## Mode :logical ## FALSE:5 ## 1summary(exam_na) 12345678## id sex korean english math ## Min. :1 Length:5 Min. :87.00 Min. :84.00 Min. :80.0 ## 1st Qu.:2 Class :character 1st Qu.:87.00 1st Qu.:88.00 1st Qu.:82.0 ## Median :3 Mode :character Median :89.50 Median :92.00 Median :88.0 ## Mean :3 Mean :90.25 Mean :90.33 Mean :86.6 ## 3rd Qu.:4 3rd Qu.:92.75 3rd Qu.:93.50 3rd Qu.:90.0 ## Max. :5 Max. :95.00 Max. :95.00 Max. :93.0 ## NA&#x27;s :1 NA&#x27;s :2 결측치 처리 방법-제거하고 처리하기-다른 값으로 대체하기 평균 입력 (1) 결측치를 제외하고 분석하기 p.160na.rm &#x3D; T 1mean(exam_na$korean, na.rm = TRUE) 1## [1] 90.25 na.omit() 결측치가 있는 행을 모두 제거. 가급적 쓰지 말것 filter() 활용 is.na(korean) 1exam_na %&gt;% filter(is.na(korean)) 12## id sex korean english math## 1 4 M NA 84 80 이번에는 !is.na(korean)을 적용한다. 1exam_na %&gt;% filter(!is.na(korean)) 12345## id sex korean english math## 1 1 M 87 NA 82## 2 2 F 92 95 93## 3 3 F 95 92 90## 4 5 F 87 NA 88 (2) 결측치를 다른 값으로 대체하기 imputation 참고자료 A Solution to Missing Data: Imputation Using R R 결측값(NA) 제거, 대체 방법 이상치 데이터의 특정 값이 뭔가 ‘이상’이 있다. case 1 : 정해진 범주에서 벗어난 데이터 2000년 4월 30일 &#x2F; 2000년 40월 30일 –&gt;&gt; 9999 case 2 : 숫자 &#x2F; 아웃라이어(Outlier) &#x2F; 극단값 평균 : 평균임금 320만원 &#x2F; 손흥민 몇십억원 이상치 처리 하는 방법-table()로 이상치 확인-&gt;ifelse()로 이상치를 결측치로 변환-&gt;결측치 제거 후 분석 데이터 불러오기12mpg1_out &lt;- read.csv(&quot;mpg1_out.csv&quot;)str(mpg1_out) 1234## &#x27;data.frame&#x27;: 234 obs. of 3 variables:## $ trans: int 1 2 2 1 1 2 1 2 1 2 ...## $ drv : chr &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ...## $ cty : int 18 21 20 21 16 18 18 18 16 20 ... 1glimpse(mpg1_out) 12345## Rows: 234## Columns: 3## $ trans &lt;int&gt; 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 3, 1, 1…## $ drv &lt;chr&gt; &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;4&quot;, &quot;4&quot;, &quot;4&quot;, &quot;4&quot;, &quot;4&quot;, &quot;5&quot;,…## $ cty &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17, 15, 15, … trans의 갯수를 구하자.-ifelse-만약 trans의 값이 3이라면, 결측치로 바꿔주세요. 나머지는 그래도 유지하세요 1table(mpg1_out$trans) #3이 4개 있다. 123## ## 1 2 3 ## 154 76 4 12mpg1_out$trans&lt;-ifelse(mpg1_out$trans==3, NA, mpg1_out$trans) #3을 결측치 처리 하였다.table(is.na(mpg1_out$trans)) # 결측치 숫자 확인 123## ## FALSE TRUE ## 230 4 결측치 제거 12result &lt;- mpg1_out %&gt;% filter(!is.na(trans))table(is.na(result$trans)) 123## ## FALSE ## 230 극단치 처리 숫자 데이터 boxplot() boxplot() 함수를 통해서 극단치가 있는지 없는지 확인 가능 IQR : 3사분위 - 1사분위 경계값 : IQR + IQR * 1.5 상한 &#x2F; IQR - IQR * 1.5 123mpg1 &lt;- read.csv(&quot;mpg1.csv&quot;)boxplot(mpg1$cty)boxplot(mpg1$cty)$stats 123456## [,1]## [1,] 9## [2,] 14## [3,] 17## [4,] 19## [5,] 26 1개 변수의 통계값 : boxplot(데이터세트$변수)$stats 복수별수의 통계값 : boxplot(데이터 세트$변수1, 데이터세트$변수2, …)$stats 변수의 범주별 통계값: boxplot(데이터세트$종속변수~데이터세트$범주변수)$stats cty 변수의 통계값 구해보자 1boxplot(mpg1$cty)$stats 123456## [,1]## [1,] 9## [2,] 14## [3,] 17## [4,] 19## [5,] 26 cty와 hwy의 통계값 구해보자 1boxplot(mpg1$cty,mpg1$hwy)$stats 123456## [,1] [,2]## [1,] 9 12## [2,] 14 18## [3,] 17 24## [4,] 19 27## [5,] 26 37 drv의 3개 범주별 cty 통계값과 그래프를 구해보자 1boxplot(mpg1$cty~mpg1$drv)$stats 123456## [,1] [,2] [,3]## [1,] 9 15 11## [2,] 13 18 12## [3,] 14 19 15## [4,] 16 21 15## [5,] 20 25 18 ggplot2 강의 데이터 불러오기 12345library(readxl)library(ggplot2)who_disease &lt;- read_xlsx(&quot;who_disease.xlsx&quot;)ggplot(who_disease, aes(x = year, y = cases)) + geom_point() 1234# 그래프의 종류# 옵션 1. 투명도 주기ggplot(who_disease, aes(x = year, y = cases)) + geom_point(alpha = 0.1) 123# 옵션 2. 색상 변화ggplot(who_disease, aes(x = year, y = cases)) + geom_point(alpha = 0.1, colour = &quot;#FFA07A&quot;) colours 입력 위치 geom_point(colour&#x3D;”red”) aes(x, y, colour &#x3D; 컬럼명) 1str(iris) 123456## &#x27;data.frame&#x27;: 150 obs. of 5 variables:## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... 1234ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, colour = Species)) + geom_point() 1 산점도 : x축 수치형 연속형 데이터, y축 수치형 연속형 데이터 히스토 그램 질병 데이터 region &#x3D; AMR, year &#x3D; 1980, disease, 백일해(pertussis) cases &gt; 0 12library(dplyr)str(who_disease) 1234567## tibble [43,262 × 6] (S3: tbl_df/tbl/data.frame)## $ region : chr [1:43262] &quot;EMR&quot; &quot;EUR&quot; &quot;AFR&quot; &quot;EUR&quot; ...## $ countryCode: chr [1:43262] &quot;AFG&quot; &quot;ALB&quot; &quot;DZA&quot; &quot;AND&quot; ...## $ country : chr [1:43262] &quot;Afghanistan&quot; &quot;Albania&quot; &quot;Algeria&quot; &quot;Andorra&quot; ...## $ disease : chr [1:43262] &quot;measles&quot; &quot;measles&quot; &quot;measles&quot; &quot;measles&quot; ...## $ year : num [1:43262] 2016 2016 2016 2016 2016 ...## $ cases : num [1:43262] 638 17 41 0 53 0 0 2 99 27 ... 123456789data2 &lt;- who_diseasewho_disease %&gt;% filter(region == &#x27;AMR&#x27;, year == 1980, disease == &#x27;pertussis&#x27;, cases &gt; 0) -&gt; data2ggplot(data2, aes(x = cases)) + geom_histogram() 1## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 123ggplot(data2, aes(x = country, y = cases)) + geom_col(fill = &quot;#FFA07A&quot;) + coord_flip() 1# 옵션 ggplot(data &#x3D; ,aes(x&#x3D;y&#x3D;))+geom_계열()+…+…추가 12library(&quot;ggplot2&quot;)diamonds &lt;- ggplot2::diamonds 막대 그래프 그리기 table() 함수로 cut별 빈도수를 보면 다음과 같다. 1table(diamonds$cut) 123## ## Fair Good Very Good Premium Ideal ## 1610 4906 12082 13791 21551 1ggplot(diamonds, aes(x=cut))+geom_bar() 히스토그램 그리기1ggplot(data=diamonds, aes(x=carat))+geom_histogram() 1## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. -geom_histogram(binwidth&#x3D;x) 괄호 안에 숫자 값에 따라 그래프의 굵기가 조정된다. 밀도 조정하기 12ggplot(data=diamonds,aes(x=carat))+geom_density() 123ggplot()+ geom_line(data=economics,aes(x=date, y=uempmed, color=&quot;red&quot;))+ geom_line(data=economics,aes(x=date,y=psavert)) 실업자 수와 개인저축률 변화 비교 그래프 ggplot() 정교하게 그리기 산점도 그리기 12ggplot(data=diamonds, aes(x=carat, y=price)) + geom_point() 1234ggplot(data = diamonds, aes(x = carat, y = price, col = cut)) + geom_point() 막대그래프에 2개 범부 내용 반영하기 12ggplot(diamonds, aes(x = color, fill = cut)) + geom_bar() 12leisure &lt;- read.csv(&quot;leisure.csv&quot;)str(leisure) 1234## &#x27;data.frame&#x27;: 200 obs. of 3 variables:## $ age : int 2 2 3 3 4 4 5 5 6 6 ...## $ sex : chr &quot;female&quot; &quot;male&quot; &quot;female&quot; &quot;male&quot; ...## $ expense: num 25.8 21 30 16.3 25.7 ... 1ggplot(data = leisure, aes(x = age, y = expense, col= sex))+geom_line(size = 1.5, linetype = 3) 막대 그래프의 순서 변경 reorder() 123456789mpg1 &lt;- read.csv(&quot;mpg1.csv&quot;, stringsAsFactors = FALSE)# 데이터 가공drv_hwy &lt;- mpg1 %&gt;% group_by(drv) %&gt;% summarise(mean_hwy = mean(hwy))drv_hwy 123456## # A tibble: 3 × 2## drv mean_hwy## &lt;chr&gt; &lt;dbl&gt;## 1 4 19.2## 2 f 28.2## 3 r 21 1234# 기본 그래프ggplot(data = drv_hwy, aes(x = drv, y = mean_hwy)) + geom_col() 123ggplot(data = drv_hwy, aes(x = reorder(drv,mean_hwy),# 오름차순 y = mean_hwy)) + geom_col() 12345678910ggplot(data = drv_hwy, aes(x = reorder(drv,-mean_hwy),# 내림차순 y = mean_hwy)) + geom_col() + labs( title = &quot;그래프 제목을 입력하세요!&quot;, subtitle = &quot;그래프 소 제목을 입력하세요&quot;, x = &quot;x변수명을 입력하세요&quot;, y = &quot;y변수명을 입력하세요&quot;, caption = &quot;데이터 출처를 입력하세요&quot; )","categories":[],"tags":[]},{"title":"day0621","slug":"day_0621","date":"2022-06-21T00:00:00.000Z","updated":"2022-06-22T00:04:37.044Z","comments":true,"path":"2022/06/21/day_0621/","link":"","permalink":"https://park128.github.io/2022/06/21/day_0621/","excerpt":"","text":"123456## &#x27;data.frame&#x27;: 234 obs. of 5 variables:## $ manufacturer: chr &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; ...## $ trans : chr &quot;auto&quot; &quot;manual&quot; &quot;manual&quot; &quot;auto&quot; ...## $ drv : chr &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ...## $ cty : int 18 21 20 21 16 18 18 18 16 20 ...## $ hwy : int 29 29 31 30 26 26 27 26 25 28 ... 금일 배운 명령어 모음.1234567# 평균mean(mtcars$mpg) # 평균## [1] 20.09062var(mtcars$mpg) # 분산## [1] 36.3241sd(mtcars$mpg) # 표준편차## [1] 6.026948 1sd(mtcars$mpg) # 6.026948 12## 0% 25% 50% 75% 100% ## 10.400 15.425 19.200 22.800 33.900 통계 요약 구하기 중간값 : 100명, 50번째 키순에 해당하는 값을 말한다. 평균 : 전체 키의 합 &#x2F; 100123summary(iris$Sepal.Length)## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 4.300 5.100 5.800 5.843 6.400 7.900 123# 빈도 분석# 범주별 빈도 --&gt; 문자str(mpg1) 123456## &#x27;data.frame&#x27;: 234 obs. of 5 variables:## $ manufacturer: chr &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; ...## $ trans : chr &quot;auto&quot; &quot;manual&quot; &quot;manual&quot; &quot;auto&quot; ...## $ drv : chr &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ...## $ cty : int 18 21 20 21 16 18 18 18 16 20 ...## $ hwy : int 29 29 31 30 26 26 27 26 25 28 ... 12#table(mpg1$trans) 123## ## auto manual ## 157 77 1table(mpg1$manufacturer) 1234567## ## audi chevrolet dodge ford honda hyundai jeep ## 18 19 37 25 9 14 8 ## land rover lincoln mercury nissan pontiac subaru toyota ## 4 3 4 13 5 14 34 ## volkswagen ## 27 1table(mpg1$trans, mpg1$manufacturer) 12345678## ## audi chevrolet dodge ford honda hyundai jeep land rover lincoln## auto 11 16 30 17 4 7 8 4 3## manual 7 3 7 8 5 7 0 0 0## ## mercury nissan pontiac subaru toyota volkswagen## auto 4 8 5 7 20 13## manual 0 5 0 7 14 14 12a &lt;- table(mpg1$trans)prop.table(a) 123## ## auto manual ## 0.6709402 0.3290598 12b &lt;- table(mpg1$trans, mpg1$drv)prop.table(b) 1234## ## 4 f r## auto 0.32051282 0.27777778 0.07264957## manual 0.11965812 0.17521368 0.03418803 1prop.table(table(mpg1$manufacturer)) 1234567## ## audi chevrolet dodge ford honda hyundai jeep ## 0.07692308 0.08119658 0.15811966 0.10683761 0.03846154 0.05982906 0.03418803 ## land rover lincoln mercury nissan pontiac subaru toyota ## 0.01709402 0.01282051 0.01709402 0.05555556 0.02136752 0.05982906 0.14529915 ## volkswagen ## 0.11538462 123# 행과 열의 비율 형식 맞춘다prop.table(b, margin = 1) 1234## ## 4 f r## auto 0.4777070 0.4140127 0.1082803## manual 0.3636364 0.5324675 0.1038961 1prop.table(b, margin = 2) 1234## ## 4 f r## auto 0.7281553 0.6132075 0.6800000## manual 0.2718447 0.3867925 0.3200000 12# 소숫점 아래 자리 지정round(0.32523141, 2) 1## [1] 0.33 123a = table(mpg1$trans)b = prop.table(a)b 123## ## auto manual ## 0.6709402 0.3290598 1round(b, 2) 123## ## auto manual ## 0.67 0.33 1round(prop.table(table(mpg1$trans)), 2) 123## ## auto manual ## 0.67 0.33","categories":[],"tags":[]},{"title":"test","slug":"test","date":"2022-06-20T00:00:00.000Z","updated":"2022-06-20T08:35:49.180Z","comments":true,"path":"2022/06/20/test/","link":"","permalink":"https://park128.github.io/2022/06/20/test/","excerpt":"","text":"csv 파일 불러오기 csv파일을 불러옵니다. 12mpg1 &lt;- read.csv(&quot;mpg1.csv&quot;)str(mpg1) 123456## &#x27;data.frame&#x27;: 234 obs. of 5 variables:## $ manufacturer: chr &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; ...## $ trans : chr &quot;auto&quot; &quot;manual&quot; &quot;manual&quot; &quot;auto&quot; ...## $ drv : chr &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ...## $ cty : int 18 21 20 21 16 18 18 18 16 20 ...## $ hwy : int 29 29 31 30 26 26 27 26 25 28 ... 데이터 시각화 하기 cty, hwy 산점도를 그려본다. 1234library(ggplot2)ggplot(mpg1, aes(x = cty, y = hwy)) + geom_point()","categories":[],"tags":[]},{"title":"Day-1 Visualization","slug":"day_0617","date":"2022-06-17T00:00:00.000Z","updated":"2022-06-17T08:09:22.585Z","comments":true,"path":"2022/06/17/day_0617/","link":"","permalink":"https://park128.github.io/2022/06/17/day_0617/","excerpt":"","text":"R MarkdownThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com. When you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this: 1summary(cars) 1234567## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 Including PlotsYou can also embed plots, for example: Note that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot. ggplot2 시각화 다음과 같이 시각화를 작성한다. 1234library(ggplot2)ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width)) + geom_point()","categories":[],"tags":[]}],"categories":[],"tags":[]}